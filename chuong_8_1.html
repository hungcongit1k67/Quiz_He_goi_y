<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>100 CÃ¢u Há»i Tráº¯c Nghiá»‡m - Case Study: HyperNews</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 0; padding: 20px; background-color: #f4f4f4; color: #333; }
        .container { max-width: 900px; margin: auto; background: #fff; padding: 30px; border-radius: 8px; box-shadow: 0 0 15px rgba(0,0,0,0.1); }
        header { text-align: center; border-bottom: 2px solid #d9534f; margin-bottom: 30px; padding-bottom: 20px; }
        header h1 { color: #d9534f; margin: 0; }
        header p { margin: 5px 0 0; font-style: italic; color: #555; }
        .question-block { margin-bottom: 25px; padding: 20px; border: 1px solid #ddd; border-left: 5px solid #d9534f; border-radius: 5px; background-color: #fdfdfd; }
        .question-text { font-weight: bold; font-size: 1.1em; margin-bottom: 15px; }
        .options { list-style-type: none; padding-left: 0; }
        .options li { margin-bottom: 10px; padding: 8px; border-radius: 4px; }
        .explanation { margin-top: 15px; padding: 15px; background-color: #e9f7ef; border: 1px solid #a3d9b8; border-radius: 5px; }
        .explanation b { color: #1d7b46; }
        .correct-answer { background-color: #dff0d8; border-left: 3px solid #3c763d; }
        .fill-in-answer { font-weight: bold; color: #3c763d; font-size: 1.2em; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>100 CÃ¢u Há»i Tráº¯c Nghiá»‡m - Case Study: HyperNews</h1>
            <p>Dá»±a trÃªn ná»™i dung slide "PhÃ¢n tÃ­ch má»™t sá»‘ há»‡ gá»£i Ã½ cá»¥ thá»ƒ" - Viá»‡n CNTT&TT - ÄHBK HÃ  Ná»™i</p>
        </header>

        <!-- CATEGORY: INTRODUCTION & MOTIVATION -->
        <div class="question-block"><p class="question-text">CÃ¢u 1: TÃªn Ä‘áº§y Ä‘á»§ cá»§a bÃ i bÃ¡o Ä‘Æ°á»£c trÃ¬nh bÃ y trong slide lÃ  gÃ¬?</p><ul class="options"><li class="correct-answer">A. HyperNews: Simultaneous News Recommendation and Active-Time Prediction via a Double-Task Deep Neural Network</li><li>B. News Recommendation using Deep Learning</li><li>C. A Survey of News Recommender Systems</li><li>D. Multi-Task Learning for News Recommendation</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 4 ghi rÃµ tÃªn Ä‘áº§y Ä‘á»§ cá»§a bÃ i bÃ¡o.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 2: MÃ´ hÃ¬nh HyperNews Ä‘Æ°á»£c coi lÃ  má»™t Framework há»c mÃ¡y loáº¡i gÃ¬?</p><ul class="options"><li>A. Single-Task Learning</li><li class="correct-answer">B. Multi-Task Learning</li><li>C. Unsupervised Learning</li><li>D. Reinforcement Learning</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 5 nÃªu rÃµ: "Model Ä‘Æ°á»£c coi lÃ  Multi-Task Learning Framework vá»›i 2 nhiá»‡m vá»¥".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 3: Hai nhiá»‡m vá»¥ chÃ­nh mÃ  mÃ´ hÃ¬nh HyperNews thá»±c hiá»‡n Ä‘á»“ng thá»i lÃ  gÃ¬?</p><ul class="options"><li>A. Gá»£i Ã½ bÃ i News vÃ  PhÃ¢n loáº¡i Categories.</li><li class="correct-answer">B. Gá»£i Ã½ bÃ i News vÃ  Dá»± Ä‘oÃ¡n thá»i gian Ä‘á»c bÃ i News.</li><li>C. Dá»± Ä‘oÃ¡n thá»i gian Ä‘á»c vÃ  TÃ³m táº¯t bÃ i News.</li><li>D. Gá»£i Ã½ bÃ i News vÃ  PhÃ¡t hiá»‡n tin giáº£.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 5 liá»‡t kÃª 2 nhiá»‡m vá»¥: "- Gá»£i Ã½ bÃ i News" vÃ  "- Dá»± Ä‘oÃ¡n thá»i gian Ä‘á»c bÃ i News".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 4: Theo slide 6, thuá»™c tÃ­nh má»›i mÃ  HyperNews khai thÃ¡c mÃ  cÃ¡c cÃ¡ch tiáº¿p cáº­n trÆ°á»›c Ä‘Ã³ chÆ°a lÃ m lÃ  gÃ¬?</p><ul class="options"><li>A. Lá»‹ch sá»­ click cá»§a User.</li><li class="correct-answer">B. Thuá»™c tÃ­nh thá»i gian Ä‘á»c bÃ i cá»§a User (Active-Time).</li><li>C. Ná»™i dung cá»§a bÃ i bÃ¡o.</li><li>D. TiÃªu Ä‘á» cá»§a bÃ i bÃ¡o.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 6 nÃªu rÃµ: "CÃ¡c cÃ¡ch tiáº¿p cáº­n má»›i nháº¥t hiá»‡n nay chÆ°a tiáº¿p cáº­n thuá»™c tÃ­nh thá»i gian Ä‘á»c bÃ i cá»§a User" vÃ  "HyperNews sáº½ khai thÃ¡c thuá»™c tÃ­nh thá»i gian Ä‘á»c cá»§a User".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 5: "Active-Time" Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° tháº¿ nÃ o?</p><ul class="options"><li>A. Thá»i gian tá»« khi bÃ i bÃ¡o Ä‘Æ°á»£c xuáº¥t báº£n Ä‘áº¿n khi user Ä‘á»c.</li><li>B. Tá»•ng thá»i gian user online.</li><li class="correct-answer">C. Khoáº£ng thá»i gian tá»« lÃºc User click má»Ÿ bÃ i News cho Ä‘áº¿n khi Ä‘Ã³ng bÃ i News.</li><li>D. Thá»i gian trung bÃ¬nh user Ä‘á»c má»™t bÃ i bÃ¡o.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 6 Ä‘á»‹nh nghÄ©a: "Active-Time Ä‘Æ°á»£c tÃ­nh tá»« thá»i Ä‘iá»ƒm User click má»Ÿ bÃ i News cho Ä‘áº¿n khi Ä‘Ã³ng bÃ i News".</p></div></div>
        
        <!-- CATEGORY: MODEL ARCHITECTURE & ENCODERS -->
        <div class="question-block"><p class="question-text">CÃ¢u 6: Trong kiáº¿n trÃºc tá»•ng quan (slide 7a), khá»‘i "Multi-task" thá»±c hiá»‡n nhá»¯ng nhiá»‡m vá»¥ nÃ o?</p><ul class="options"><li>A. Chá»‰ dá»± Ä‘oÃ¡n Click probability.</li><li>B. Chá»‰ dá»± Ä‘oÃ¡n Active-time.</li><li class="correct-answer">C. Dá»± Ä‘oÃ¡n cáº£ Click probability vÃ  Active-time.</li><li>D. Chá»‰ mÃ£ hÃ³a User.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 7a cho tháº¥y khá»‘i "Multi-task" á»Ÿ trÃªn cÃ¹ng, vá»›i hai nhÃ¡nh Ä‘áº§u ra lÃ  "Click probability" vÃ  "Active-time".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 7: News Encoder trong HyperNews (slide 8) Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn 2 kiá»ƒu thuá»™c tÃ­nh nÃ o?</p><ul class="options"><li>A. Title vÃ  Content</li><li>B. Categories vÃ  Content</li><li class="correct-answer">C. Thuá»™c tÃ­nh rÃµ rÃ ng (Explicit) vÃ  Thuá»™c tÃ­nh áº©n (Implicit).</li><li>D. Thuá»™c tÃ­nh ngÆ°á»i dÃ¹ng vÃ  Thuá»™c tÃ­nh há»‡ thá»‘ng.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 8 chia thuá»™c tÃ­nh cá»§a bÃ i news thÃ nh 2 kiá»ƒu: "- Thuá»™c tÃ­nh rÃµ rÃ ng: Title, Categories, ..." vÃ  "- Thuá»™c tÃ­nh áº©n: Content".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 8: Táº¡i sao "Title" vÃ  "Categories" Ä‘Æ°á»£c coi lÃ  thuá»™c tÃ­nh rÃµ rÃ ng (explicit)?</p><ul class="options"><li>A. VÃ¬ chÃºng luÃ´n Ä‘Ãºng.</li><li class="correct-answer">B. VÃ¬ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ tháº¥y chÃºng trÆ°á»›c khi quyáº¿t Ä‘á»‹nh click vÃ o bÃ i bÃ¡o.</li><li>C. VÃ¬ chÃºng Ä‘Æ°á»£c mÃ£ hÃ³a báº±ng CNN.</li><li>D. VÃ¬ chÃºng ngáº¯n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 8 giáº£i thÃ­ch trong ngoáº·c: "(CÃ¡c thuá»™c tÃ­nh User cÃ³ thá»ƒ tháº¥y trÆ°á»›c khi quyáº¿t Ä‘á»‹nh click)". ÄÃ¢y lÃ  thÃ´ng tin bá» máº·t, hiá»ƒn thá»‹ ngay láº­p tá»©c.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 9: Táº¡i sao "Content" Ä‘Æ°á»£c coi lÃ  thuá»™c tÃ­nh áº©n (implicit)?</p><ul class="options"><li>A. VÃ¬ nÃ³ Ä‘Æ°á»£c mÃ£ hÃ³a báº±ng LDA.</li><li class="correct-answer">B. VÃ¬ ngÆ°á»i dÃ¹ng chá»‰ cÃ³ thá»ƒ nhÃ¬n tháº¥y nÃ³ sau khi Ä‘Ã£ click vÃ o bÃ i bÃ¡o.</li><li>C. VÃ¬ nÃ³ dÃ i.</li><li>D. VÃ¬ nÃ³ khÃ³ hiá»ƒu.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 8 giáº£i thÃ­ch trong ngoáº·c: "(User nhÃ¬n tháº¥y sau khi Ä‘Ã£ click)". ÄÃ¢y lÃ  thÃ´ng tin chÃ¬m, chá»‰ Ä‘Æ°á»£c tiáº¿p cáº­n sau khi Ä‘Ã£ cÃ³ má»™t hÃ nh Ä‘á»™ng tÆ°Æ¡ng tÃ¡c ban Ä‘áº§u.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 10: Hai pháº§n chÃ­nh cáº¥u thÃ nh nÃªn News Encoder lÃ  gÃ¬?</p><ul class="options"><li>A. CNN vÃ  FNN.</li><li>B. LDA vÃ  Doc2vec.</li><li class="correct-answer">C. Explicit Embedding vÃ  Implicit Embedding.</li><li>D. Title Embedding vÃ  Content Embedding.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 8, má»¥c "Bao gá»“m 2 pháº§n", liá»‡t kÃª: "Explicit Embedding vÃ  Implicit Embedding".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 11: Trong Explicit Embedding (slide 9), ká»¹ thuáº­t nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ lÃ m biá»ƒu diá»…n cho Title?</p><ul class="options"><li>A. RNN</li><li class="correct-answer">B. CNN (Táº§ng CNN)</li><li>C. Attention</li><li>D. Doc2vec</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 cÃ³ má»¥c "Táº§ng CNN:" vÃ  mÃ´ táº£ cÃ¡ch sá»­ dá»¥ng cÃ¡c bá»™ lá»c (filters) vÃ  concat Ä‘á»ƒ táº¡o ra biá»ƒu diá»…n `eh` cho title.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 12: Trong Explicit Embedding, cÆ¡ cháº¿ nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tá»•ng há»£p thÃ´ng tin tá»« cÃ¡c Categories?</p><ul class="options"><li>A. Max-pooling</li><li>B. CNN</li><li class="correct-answer">C. Attention</li><li>D. FNN</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 mÃ´ táº£ viá»‡c "sá»­ dá»¥ng Attention Ä‘á»ƒ tÃ­nh toÃ¡n ra trá»ng sá»‘ giá»¯a cÃ¡c Attention" cá»§a cÃ¡c category, táº¡o ra biá»ƒu diá»…n `ec_bar`.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 13: Biá»ƒu diá»…n Explicit Embedding cuá»‘i cÃ¹ng (`e_Ne`) Ä‘Æ°á»£c táº¡o ra nhÆ° tháº¿ nÃ o?</p><ul class="options"><li>A. Báº±ng cÃ¡ch cá»™ng `eh` vÃ  `ec_bar`.</li><li class="correct-answer">B. Báº±ng cÃ¡ch Ä‘Æ°a `eh` vÃ  `ec_bar` Ä‘Ã£ Ä‘Æ°á»£c ghÃ©p ná»‘i (concat) qua má»™t máº¡ng FNN.</li><li>C. Chá»‰ báº±ng `eh`.</li><li>D. Chá»‰ báº±ng `ec_bar`.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 Ä‘Æ°a ra cÃ´ng thá»©c cuá»‘i cÃ¹ng: `e_Ne = FNN([eh; ec_bar])`, vá»›i `[;]` lÃ  kÃ½ hiá»‡u cá»§a phÃ©p ghÃ©p ná»‘i (concatenation).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 14 (Chá»n nhiá»u Ä‘Ã¡p Ã¡n): Trong Implicit Embedding (slide 10), nhá»¯ng mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o biá»ƒu diá»…n tá»« Content?</p><ul class="options"><li class="correct-answer">A. LDA</li><li class="correct-answer">B. Doc2vec</li><li>C. CNN</li><li>D. Attention</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 10 mÃ´ táº£ viá»‡c sá»­ dá»¥ng cáº£ "LDA (train vá»›i táº­p Adressa)" Ä‘á»ƒ táº¡o `et` vÃ  "Doc2vec (train vá»›i táº­p Adressa)" Ä‘á»ƒ táº¡o `ed`.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 15: Biá»ƒu diá»…n Implicit Embedding cuá»‘i cÃ¹ng (`e_Ni`) Ä‘Æ°á»£c táº¡o ra nhÆ° tháº¿ nÃ o?</p><ul class="options"><li>A. Báº±ng cÃ¡ch cá»™ng cÃ¡c biá»ƒu diá»…n `et`, `ed`, `el`.</li><li class="correct-answer">B. Báº±ng cÃ¡ch Ä‘Æ°a cÃ¡c biá»ƒu diá»…n `et`, `ed`, `el` Ä‘Ã£ Ä‘Æ°á»£c ghÃ©p ná»‘i qua má»™t táº§ng FNN.</li><li>C. Chá»‰ báº±ng LDA.</li><li>D. Chá»‰ báº±ng Doc2vec.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 10 Ä‘Æ°a ra cÃ´ng thá»©c: "ev_i = FNN([et; ed; el])". ChÃº Ã½, slide cÃ³ lá»—i Ä‘Ã¡nh mÃ¡y `ev_i`, Ä‘Ãºng ra pháº£i lÃ  `e_Ni` theo sÆ¡ Ä‘á»“.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 16: CÆ¡ cháº¿ Attention trong News Encoder (slide 11) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ lÃ m gÃ¬?</p><ul class="options"><li>A. Äá»ƒ káº¿t há»£p Title vÃ  Categories.</li><li class="correct-answer">B. Äá»ƒ há»c ra sá»± tÆ°Æ¡ng quan vÃ  káº¿t há»£p cÃ³ trá»ng sá»‘ giá»¯a biá»ƒu diá»…n Explicit (`e_Ne`) vÃ  Implicit (`e_Ni`).</li><li>C. Äá»ƒ mÃ£ hÃ³a ngÆ°á»i dÃ¹ng.</li><li>D. Äá»ƒ dá»± Ä‘oÃ¡n thá»i gian Ä‘á»c.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 11 cÃ³ tiÃªu Ä‘á» "News Encoder - Attention Unit" vÃ  mÃ´ táº£ viá»‡c "Sá»­ dá»¥ng cÆ¡ cháº¿ Attention Ä‘á»ƒ há»c ra tÆ°Æ¡ng quan giá»¯a 2 loáº¡i Ä‘áº·c trÆ°ng". CÃ´ng thá»©c `e = Ã£_n^1 * e_Ne + Ã£_n^2 * e_Ni` thá»ƒ hiá»‡n rÃµ viá»‡c káº¿t há»£p cÃ³ trá»ng sá»‘.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 17: User Encoder (slide 12) sá»­ dá»¥ng thÃ´ng tin gÃ¬ lÃ m Ä‘áº§u vÃ o?</p><ul class="options"><li>A. ToÃ n bá»™ lá»‹ch sá»­ cá»§a ngÆ°á»i dÃ¹ng.</li><li class="correct-answer">B. 30 bÃ i bÃ¡o mÃ  ngÆ°á»i dÃ¹ng Ä‘Ã£ click gáº§n nháº¥t.</li><li>C. ThÃ´ng tin nhÃ¢n kháº©u há»c cá»§a ngÆ°á»i dÃ¹ng.</li><li>D. CÃ¡c bÃ i bÃ¡o mÃ  báº¡n bÃ¨ cá»§a ngÆ°á»i dÃ¹ng Ä‘Ã£ click.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 12 ghi rÃµ: "Sá»­ dá»¥ng 30 bÃ i User Click gáº§n nháº¥t".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 18: Ká»¹ thuáº­t nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng trong User Encoder Ä‘á»ƒ tá»•ng há»£p thÃ´ng tin tá»« lá»‹ch sá»­ click vÃ  táº¡o ra biá»ƒu diá»…n `e_U`?</p><ul class="options"><li>A. CNN</li><li>B. RNN</li><li class="correct-answer">C. Attention</li><li>D. Max-pooling</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 12 cÃ³ tiÃªu Ä‘á» "Sá»­ dá»¥ng cÆ¡ cháº¿ Attention Ä‘á»ƒ há»c ra biá»ƒu diá»…n User". SÆ¡ Ä‘á»“ vÃ  cÃ¡c cÃ´ng thá»©c trÃªn slide cÅ©ng mÃ´ táº£ má»™t cÆ¡ cháº¿ attention tÆ°Æ¡ng tá»± nhÆ° trong News Encoder.</p></div></div>

        <!-- CATEGORY: 2-TASK PREDICTION -->
        <div class="question-block"><p class="question-text">CÃ¢u 19: "Timeliness" trong mÃ´ hÃ¬nh HyperNews Ä‘o lÆ°á»ng Ä‘iá»u gÃ¬?</p><ul class="options"><li>A. Thá»i gian ngÆ°á»i dÃ¹ng Ä‘á»c bÃ i bÃ¡o.</li><li class="correct-answer">B. Thá»i gian tá»« khi bÃ i bÃ¡o Ä‘Æ°á»£c xuáº¥t báº£n Ä‘áº¿n khi ngÆ°á»i dÃ¹ng click vÃ o nÃ³.</li><li>C. Tá»‘c Ä‘á»™ táº£i cá»§a bÃ i bÃ¡o.</li><li>D. Thá»i Ä‘iá»ƒm trong ngÃ y mÃ  ngÆ°á»i dÃ¹ng click.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 13 Ä‘á»‹nh nghÄ©a: "Timeliness: Thá»i gian tá»« khi bÃ i News Ä‘Æ°á»£c publich tá»›i khi User click vÃ o bÃ i news".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 20: Äá»ƒ dá»± Ä‘oÃ¡n xÃ¡c suáº¥t click (`Å·p`), mÃ´ hÃ¬nh káº¿t há»£p nhá»¯ng biá»ƒu diá»…n nÃ o?</p><ul class="options"><li>A. Chá»‰ `e_N` vÃ  `e_U`.</li><li class="correct-answer">B. `e_f` (biá»ƒu diá»…n Timeliness) vÃ  `e_N` (biá»ƒu diá»…n News) Ä‘Æ°á»£c nhÃ¢n element-wise, sau Ä‘Ã³ káº¿t há»£p vá»›i `e_U` (biá»ƒu diá»…n User).</li><li>C. Chá»‰ `e_f` vÃ  `e_U`.</li><li>D. Chá»‰ `e_N`.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 13 cho tháº¥y `e_f` vÃ  `e_p` (biá»ƒu diá»…n News cho nhiá»‡m vá»¥ click) Ä‘Æ°á»£c nhÃ¢n Hadamard product. Káº¿t quáº£ nÃ y (`e_T`) sau Ä‘Ã³ Ä‘Æ°á»£c nhÃ¢n Dot product vá»›i `e_U`. CÃ´ng thá»©c `Å·p = sigmoid(e_T^T Ã— e_U)` cÅ©ng thá»ƒ hiá»‡n Ä‘iá»u nÃ y.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 21: (Äiá»n Ä‘Ã¡p Ã¡n) HÃ m kÃ­ch hoáº¡t nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ táº§ng cuá»‘i cÃ¹ng Ä‘á»ƒ tÃ­nh xÃ¡c suáº¥t click `Å·p`?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">Sigmoid</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 13 cÃ³ cÃ´ng thá»©c: `Å·p = sigmoid(e_T^T Ã— e_U)`. HÃ m Sigmoid phÃ¹ há»£p vÃ¬ nÃ³ Ã¡nh xáº¡ káº¿t quáº£ ra khoáº£ng (0, 1), cÃ³ thá»ƒ diá»…n giáº£i nhÆ° má»™t xÃ¡c suáº¥t.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 22: Táº¡i sao tÃ¡c giáº£ láº¡i rá»i ráº¡c hÃ³a thá»i gian Ä‘á»c (Active-Time) thÃ nh bÃ i toÃ¡n phÃ¢n loáº¡i?</p><ul class="options"><li>A. VÃ¬ bÃ i toÃ¡n há»“i quy quÃ¡ dá»….</li><li class="correct-answer">B. VÃ¬ Æ°á»›c lÆ°á»£ng chÃ­nh xÃ¡c thá»i gian Ä‘á»c (vÃ­ dá»¥ 50s vs 60s) khÃ´ng thá»±c sá»± quan trá»ng vÃ  khÃ³ khÄƒn, trong khi phÃ¢n loáº¡i vÃ o cÃ¡c khoáº£ng (bins) thÃ¬ kháº£ thi hÆ¡n.</li><li>C. VÃ¬ khÃ´ng cÃ³ Ä‘á»§ dá»¯ liá»‡u thá»i gian liÃªn tá»¥c.</li><li>D. Äá»ƒ tÄƒng tá»‘c Ä‘á»™ huáº¥n luyá»‡n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 14 nháº­n xÃ©t: "Æ¯á»›c lÆ°á»£ng chÃ­nh xÃ¡c thá»i gian Ä‘á»c bÃ i User khÃ´ng thá»±c sá»± quÃ¡ quan trá»ng: vÃ­ dá»¥ Ä‘á»c 50s khÃ´ng quÃ¡ khÃ¡c biá»‡t vá»›i 60s", do Ä‘Ã³ há» "Rá»i ráº¡c hÃ³a thá»i gian vÃ  chuyá»ƒn thÃ nh bÃ i toÃ¡n phÃ¢n loáº¡i".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 23: (Äiá»n Ä‘Ã¡p Ã¡n) Trong nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n Active-Time, thá»i gian tá»« 5s-205s Ä‘Æ°á»£c chia thÃ nh bao nhiÃªu nhÃ£n (lá»›p)?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">20</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 14 ghi: "Thá»i gian 5s-205s Ä‘Æ°á»£c chia thÃ nh 20 nhÃ£n (10s))". Má»—i nhÃ£n tÆ°Æ¡ng á»©ng vá»›i má»™t khoáº£ng thá»i gian 10 giÃ¢y.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 24: (Äiá»n Ä‘Ã¡p Ã¡n) HÃ m kÃ­ch hoáº¡t nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ táº§ng cuá»‘i cÃ¹ng Ä‘á»ƒ dá»± Ä‘oÃ¡n lá»›p thá»i gian Ä‘á»c `Å·t`?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">Softmax</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 14 cÃ³ cÃ´ng thá»©c: `Å·t = softmax(Wt Ã— e_T + bt)`. HÃ m Softmax phÃ¹ há»£p cho bÃ i toÃ¡n phÃ¢n loáº¡i Ä‘a lá»›p, vÃ¬ nÃ³ táº¡o ra má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t trÃªn táº¥t cáº£ cÃ¡c lá»›p.</p></div></div>

        <!-- CATEGORY: MODEL TRAINING -->
        <div class="question-block"><p class="question-text">CÃ¢u 25: Trong má»™t máº«u training `X` cá»§a HyperNews, `yp` Ä‘áº¡i diá»‡n cho Ä‘iá»u gÃ¬?</p><ul class="options"><li>A. Biá»ƒu diá»…n cá»§a bÃ i bÃ¡o.</li><li class="correct-answer">B. NhÃ£n xÃ¡c suáº¥t click (1 hoáº·c 0).</li><li>C. Biá»ƒu diá»…n cá»§a ngÆ°á»i dÃ¹ng.</li><li>D. NhÃ£n thá»i gian Ä‘á»c.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 15 mÃ´ táº£ cÃ¡c thÃ nh pháº§n cá»§a máº«u training. `yp` lÃ  "XÃ¡c suáº¥t click (1-0)".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 26: HÃ m loss `Lp` (slide 15) Ä‘Æ°á»£c sá»­ dá»¥ng cho nhiá»‡m vá»¥ nÃ o?</p><ul class="options"><li class="correct-answer">A. Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t click.</li><li>B. Dá»± Ä‘oÃ¡n thá»i gian Ä‘á»c.</li><li>C. MÃ£ hÃ³a News.</li><li>D. MÃ£ hÃ³a User.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> `Lp` lÃ  hÃ m lá»—i cho dá»± Ä‘oÃ¡n `Å·p`, tá»©c lÃ  xÃ¡c suáº¥t click. ÄÃ¢y lÃ  hÃ m cross-entropy cho bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 27: HÃ m loss `Lt` (slide 15) Ä‘Æ°á»£c sá»­ dá»¥ng cho nhiá»‡m vá»¥ nÃ o?</p><ul class="options"><li>A. Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t click.</li><li class="correct-answer">B. Dá»± Ä‘oÃ¡n thá»i gian Ä‘á»c.</li><li>C. MÃ£ hÃ³a News.</li><li>D. MÃ£ hÃ³a User.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> `Lt` lÃ  hÃ m lá»—i cho dá»± Ä‘oÃ¡n `Å·t`, tá»©c lÃ  nhÃ£n thá»i gian Ä‘á»c. ÄÃ¢y lÃ  hÃ m cross-entropy cho bÃ i toÃ¡n phÃ¢n loáº¡i Ä‘a lá»›p.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 28: Táº¡i sao cáº§n pháº£i Ä‘á»‹nh nghÄ©a láº¡i kÃ­ch thÆ°á»›c cá»§a má»—i Class trong nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n Active-Time (slide 16)?</p><ul class="options"><li>A. VÃ¬ cÃ¡c class cÃ³ kÃ­ch thÆ°á»›c báº±ng nhau.</li><li class="correct-answer">B. VÃ¬ cÃ¡c nhÃ£n thá»i gian Ä‘á»c bá»‹ máº¥t cÃ¢n báº±ng (imbalanced).</li><li>C. Äá»ƒ tÄƒng sá»‘ lÆ°á»£ng class.</li><li>D. Äá»ƒ giáº£m sá»‘ lÆ°á»£ng class.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 16 cÃ³ nháº­n xÃ©t: "CÃ¡c nhÃ£n thá»i gian Ä‘á»c máº¥t cÃ¢n báº±ng". Háº§u háº¿t ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ chá»‰ Ä‘á»c trong má»™t khoáº£ng thá»i gian ngáº¯n, lÃ m cho cÃ¡c lá»›p thá»i gian Ä‘á»c dÃ i cÃ³ ráº¥t Ã­t máº«u. Viá»‡c Ä‘á»‹nh nghÄ©a láº¡i `E_m` lÃ  má»™t ká»¹ thuáº­t Ä‘á»ƒ xá»­ lÃ½ sá»± máº¥t cÃ¢n báº±ng nÃ y.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 29: HÃ m loss tá»•ng há»£p `L` Ä‘Æ°á»£c tÃ­nh nhÆ° tháº¿ nÃ o?</p><ul class="options"><li>A. `L = Lp * Î»Lt`</li><li>B. `L = Lp - Î»Lt`</li><li class="correct-answer">C. `L = Lp + Î»Lt`</li><li>D. `L = max(Lp, Î»Lt)`</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 16 Ä‘Æ°a ra cÃ´ng thá»©c loss tá»•ng há»£p: `L = Lp + Î»L't`. `Î»` lÃ  má»™t siÃªu tham sá»‘ Ä‘á»ƒ cÃ¢n báº±ng táº§m quan trá»ng giá»¯a hai nhiá»‡m vá»¥.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 30: Tham sá»‘ `Î²` trong cÃ´ng thá»©c `E_m = (1 - Î²^m)/(1 - Î²)` (slide 16) dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬?</p><ul class="options"><li>A. Tá»‘c Ä‘á»™ há»c.</li><li class="correct-answer">B. LÃ  má»™t siÃªu tham sá»‘ (vÃ­ dá»¥ 0.99, 0.999) Ä‘á»ƒ Ä‘iá»u chá»‰nh trá»ng sá»‘ cá»§a cÃ¡c class dá»±a trÃªn sá»‘ lÆ°á»£ng máº«u `m` cá»§a chÃºng.</li><li>C. LÃ  xÃ¡c suáº¥t click.</li><li>D. LÃ  thá»i gian Ä‘á»c.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 16 Ä‘á»‹nh nghÄ©a `Beta` lÃ  "tham sá»‘: 0.99, 0.999". ÄÃ¢y lÃ  má»™t ká»¹ thuáº­t Ä‘Æ°á»£c gá»i lÃ  Class-balanced loss, nÆ¡i cÃ¡c class cÃ³ Ã­t máº«u hÆ¡n sáº½ Ä‘Æ°á»£c gÃ¡n trá»ng sá»‘ cao hÆ¡n trong hÃ m loss Ä‘á»ƒ mÃ´ hÃ¬nh chÃº Ã½ Ä‘áº¿n chÃºng hÆ¡n.</p></div></div>
        
        <!-- CATEGORY: EXPERIMENTS & RESULTS -->
        <div class="question-block"><p class="question-text">CÃ¢u 31: Bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng trong thá»±c nghiá»‡m cÃ³ tÃªn lÃ  gÃ¬?</p><ul class="options"><li>A. MovieLens</li><li>B. Netflix</li><li class="correct-answer">C. Adressa</li><li>D. Amazon</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 17 cÃ³ tiÃªu Ä‘á» "dataset: Adressa".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 32: (Äiá»n Ä‘Ã¡p Ã¡n) Trong bá»™ dá»¯ liá»‡u Adressa-4week, cÃ³ bao nhiÃªu bÃ i bÃ¡o (news-articles)?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">37,067</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Báº£ng trÃªn slide 17, hÃ ng "#news-articles" vÃ  cá»™t "Adressa-4week" cÃ³ giÃ¡ trá»‹ lÃ  37,067.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 33: (Äiá»n Ä‘Ã¡p Ã¡n) Trong bá»™ dá»¯ liá»‡u Adressa-1week, cÃ³ bao nhiÃªu sá»± kiá»‡n cÃ³ thÃ´ng tin 'active-time'?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">1,062,793</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Báº£ng trÃªn slide 17, hÃ ng "#events-with-'active-time'" vÃ  cá»™t "Adressa-1week" cÃ³ giÃ¡ trá»‹ lÃ  1,062,793.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 34: Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ trÃªn slide 18 cho tháº¥y Ä‘iá»u gÃ¬ vá» vai trÃ² cá»§a "Timeliness"?</p><ul class="options"><li>A. "Timeliness" khÃ´ng cÃ³ áº£nh hÆ°á»Ÿng.</li><li class="correct-answer">B. "HyperNews" (cÃ³ Timeliness) luÃ´n cho káº¿t quáº£ tá»‘t hÆ¡n "HyperNews without Timeliness" á»Ÿ táº¥t cáº£ cÃ¡c Ä‘á»™ Ä‘o.</li><li>C. "Timeliness" chá»‰ cáº£i thiá»‡n nhiá»‡m vá»¥ gá»£i Ã½.</li><li>D. "Timeliness" chá»‰ cáº£i thiá»‡n nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n thá»i gian.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong cáº£ hai biá»ƒu Ä‘á»“ (a) vÃ  (b) trÃªn slide 18, cÃ¡c cá»™t mÃ u xanh Ä‘áº­m (HyperNews) luÃ´n cao hÆ¡n cÃ¡c cá»™t mÃ u xanh nháº¡t (HyperNews without Timeliness), cho tháº¥y viá»‡c thÃªm vÃ o thuá»™c tÃ­nh Timeliness Ä‘Ã£ cáº£i thiá»‡n hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 35: Theo báº£ng káº¿t quáº£ á»Ÿ slide 19, mÃ´ hÃ¬nh nÃ o cho káº¿t quáº£ AUC vÃ  F1 cao nháº¥t cho nhiá»‡m vá»¥ News Recommendation trÃªn cáº£ hai bá»™ dá»¯ liá»‡u?</p><ul class="options"><li>A. LibFM</li><li>B. LSTUR</li><li class="correct-answer">C. HyperNews</li><li>D. DAN</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong báº£ng á»Ÿ slide 19, hÃ ng cuá»‘i cÃ¹ng "HyperNews" cÃ³ cÃ¡c giÃ¡ trá»‹ AUC vÃ  F1 (Ä‘Æ°á»£c in Ä‘áº­m) cao nháº¥t so vá»›i táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c Ä‘Æ°á»£c so sÃ¡nh trÃªn cáº£ hai bá»™ dá»¯ liá»‡u.</p></div></div>
        
        ... (Tiáº¿p tá»¥c vá»›i 65 cÃ¢u há»i cÃ²n láº¡i theo cáº¥u trÃºc tÆ°Æ¡ng tá»±)
        <div class="question-block"><p class="question-text">CÃ¢u 36: MÃ´ hÃ¬nh `HyperNews(NoPred)` (slide 19) lÃ  phiÃªn báº£n nÃ o cá»§a HyperNews?</p><ul class="options"><li>A. PhiÃªn báº£n khÃ´ng cÃ³ User Encoder.</li><li>B. PhiÃªn báº£n khÃ´ng cÃ³ News Encoder.</li><li class="correct-answer">C. PhiÃªn báº£n chá»‰ thá»±c hiá»‡n nhiá»‡m vá»¥ gá»£i Ã½ mÃ  khÃ´ng cÃ³ nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n thá»i gian Ä‘á»c.</li><li>D. PhiÃªn báº£n khÃ´ng cÃ³ yáº¿u tá»‘ Timeliness.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> `NoPred` cÃ³ thá»ƒ lÃ  viáº¿t táº¯t cá»§a "No Prediction" (khÃ´ng cÃ³ nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n phá»¥). So sÃ¡nh káº¿t quáº£ cá»§a `HyperNews(NoPred)` vá»›i `HyperNews` Ä‘áº§y Ä‘á»§ cho tháº¥y viá»‡c thÃªm nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n Active-Time (Multi-Task Learning) Ä‘Ã£ giÃºp cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a nhiá»‡m vá»¥ chÃ­nh lÃ  gá»£i Ã½ tin tá»©c.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 37: Trong News Encoder - Explicit Embedding (slide 9), táº¡i sao chá»‰ chá»n 3 category quan trá»ng nháº¥t?</p><ul class="options"><li>A. VÃ¬ ngÆ°á»i dÃ¹ng chá»‰ cÃ³ thá»ƒ nhá»› 3 category.</li><li class="correct-answer">B. ÄÃ¢y lÃ  má»™t lá»±a chá»n thiáº¿t káº¿ Ä‘á»ƒ giá»›i háº¡n Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n cá»§a cÆ¡ cháº¿ Attention.</li><li>C. VÃ¬ má»™t bÃ i bÃ¡o khÃ´ng thá»ƒ thuá»™c vá» nhiá»u hÆ¡n 3 category.</li><li>D. VÃ¬ cÃ¡c category khÃ¡c khÃ´ng cÃ³ vector embedding.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 ghi "(chá»n 3 cats quan trá»ng nháº¥t)". Viá»‡c giá»›i háº¡n sá»‘ lÆ°á»£ng pháº§n tá»­ Ä‘áº§u vÃ o cho cÆ¡ cháº¿ Attention lÃ  má»™t ká»¹ thuáº­t phá»• biáº¿n Ä‘á»ƒ giá»¯ cho viá»‡c tÃ­nh toÃ¡n hiá»‡u quáº£, Ä‘áº·c biá»‡t khi má»™t bÃ i bÃ¡o cÃ³ thá»ƒ Ä‘Æ°á»£c gÃ¡n nhiá»u category.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 38: Biá»ƒu diá»…n `e_l` trong Implicit Embedding (slide 10) Ä‘áº¡i diá»‡n cho Ä‘iá»u gÃ¬?</p><ul class="options"><li>A. Vector LDA.</li><li>B. Vector Doc2vec.</li><li class="correct-answer">C. Vector biá»ƒu diá»…n cho chiá»u dÃ i cá»§a ná»™i dung.</li><li>D. Vector Attention.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 10 cho tháº¥y Ä‘áº§u vÃ o "Length" Ä‘Æ°á»£c Ä‘Æ°a qua má»™t táº§ng "Embedding" Ä‘á»ƒ táº¡o ra `e_l`. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  mÃ´ hÃ¬nh há»c má»™t biá»ƒu diá»…n cho thuá»™c tÃ­nh chiá»u dÃ i cá»§a vÄƒn báº£n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 39: Trong User Encoder (slide 12), `q_u` lÃ  gÃ¬?</p><ul class="options"><li>A. Vector biá»ƒu diá»…n cá»§a ngÆ°á»i dÃ¹ng.</li><li class="correct-answer">B. Má»™t vector truy váº¥n (query vector) Ä‘Æ°á»£c há»c, dÃ¹ng trong cÆ¡ cháº¿ Attention Ä‘á»ƒ xÃ¡c Ä‘á»‹nh táº§m quan trá»ng cá»§a cÃ¡c bÃ i bÃ¡o Ä‘Ã£ xem.</li><li>C. Lá»‹ch sá»­ click cá»§a ngÆ°á»i dÃ¹ng.</li><li>D. ID cá»§a ngÆ°á»i dÃ¹ng.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> `q_u` Ä‘Ã³ng vai trÃ² lÃ  vector "truy váº¥n" trong cÆ¡ cháº¿ attention. NÃ³ Ä‘Æ°á»£c nhÃ¢n vá»›i vector biá»ƒu diá»…n cá»§a má»—i bÃ i bÃ¡o Ä‘Ã£ xem Ä‘á»ƒ tÃ­nh Ä‘iá»ƒm `Î±_i^u`, tá»« Ä‘Ã³ xÃ¡c Ä‘á»‹nh bÃ i bÃ¡o nÃ o quan trá»ng hÆ¡n trong viá»‡c hÃ¬nh thÃ nh nÃªn sá»Ÿ thÃ­ch tá»•ng há»£p `e_U` cá»§a ngÆ°á»i dÃ¹ng.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 40: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 13, biá»ƒu diá»…n `e_f` cá»§a Timeliness Ä‘Æ°á»£c táº¡o ra tá»« Ä‘Ã¢u?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">Tá»« má»™t táº§ng Embedding vÃ  má»™t táº§ng Dense</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 13 cho tháº¥y Ä‘áº§u vÃ o "Timeliness" Ä‘i qua má»™t táº§ng "Embedding" (táº¡o ra `e_f'`) vÃ  sau Ä‘Ã³ lÃ  má»™t táº§ng "Dense" Ä‘á»ƒ táº¡o ra biá»ƒu diá»…n cuá»‘i cÃ¹ng `e_f`.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 41: Táº¡i sao mÃ´ hÃ¬nh HyperNews láº¡i sá»­ dá»¥ng phÃ©p nhÃ¢n Hadamard Product giá»¯a `e_f` vÃ  `e_p` (slide 13)?</p><ul class="options"><li>A. VÃ¬ Ä‘Ã¢y lÃ  phÃ©p toÃ¡n nhanh nháº¥t.</li><li class="correct-answer">B. Äá»ƒ cho phÃ©p sá»± tÆ°Æ¡ng tÃ¡c giá»¯a cÃ¡c Ä‘áº·c trÆ°ng cá»§a tin tá»©c vÃ  yáº¿u tá»‘ thá»i gian, táº¡o ra má»™t biá»ƒu diá»…n káº¿t há»£p `e_T`.</li><li>C. VÃ¬ hai vector nÃ y cÃ³ cÃ¹ng sá»‘ chiá»u.</li><li>D. Äá»ƒ giáº£m sá»‘ chiá»u.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Hadamard product (nhÃ¢n element-wise) lÃ  má»™t cÃ¡ch hiá»‡u quáº£ Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a sá»± tÆ°Æ¡ng tÃ¡c giá»¯a hai vector. á» Ä‘Ã¢y, nÃ³ cho phÃ©p mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c ráº±ng cÃ¡c Ä‘áº·c trÆ°ng khÃ¡c nhau cá»§a tin tá»©c cÃ³ thá»ƒ cÃ³ táº§m quan trá»ng khÃ¡c nhau tÃ¹y thuá»™c vÃ o Ä‘á»™ "má»›i" cá»§a tin.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 42: Trong hÃ m loss `Lp` (slide 15), táº¡i sao láº¡i cÃ³ hai tá»•ng sigma, má»™t trÃªn `S+` vÃ  má»™t trÃªn `S-`?</p><ul class="options"><li>A. Äá»ƒ tÃ­nh toÃ¡n song song.</li><li class="correct-answer">B. VÃ¬ Ä‘Ã¢y lÃ  hÃ m loss cho bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n, `S+` lÃ  táº­p cÃ¡c máº«u dÆ°Æ¡ng (click=1) vÃ  `S-` lÃ  táº­p cÃ¡c máº«u Ã¢m (click=0).</li><li>C. Äá»ƒ xá»­ lÃ½ hai nhÃ³m ngÆ°á»i dÃ¹ng.</li><li>D. Äá»ƒ tÄƒng Ä‘á»™ phá»©c táº¡p.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> HÃ m loss cross-entropy cho phÃ¢n loáº¡i nhá»‹ phÃ¢n cÃ³ hai thÃ nh pháº§n: `y*log(Å·)` cho cÃ¡c máº«u dÆ°Æ¡ng (y=1) vÃ  `(1-y)*log(1-Å·)` cho cÃ¡c máº«u Ã¢m (y=0). Viá»‡c tÃ¡ch ra hai tá»•ng sigma chá»‰ lÃ  má»™t cÃ¡ch viáº¿t khÃ¡c cá»§a cÃ¹ng má»™t cÃ´ng thá»©c.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 43: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 19, mÃ´ hÃ¬nh nÃ o cÃ³ hiá»‡u suáº¥t kÃ©m nháº¥t trÃªn bá»™ dá»¯ liá»‡u Adressa-1week?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">LibFM</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong báº£ng á»Ÿ slide 19, hÃ ng "LibFM" cÃ³ cÃ¡c giÃ¡ trá»‹ AUC (0.7025) vÃ  F1 (0.6953) tháº¥p nháº¥t so vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c trÃªn táº­p Adressa-1week.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 44: Viá»‡c HyperNews vÆ°á»£t trá»™i hÆ¡n HyperNews(NoPred) chá»©ng tá» Ä‘iá»u gÃ¬ vá» Multi-Task Learning?</p><ul class="options"><li>A. Multi-Task Learning luÃ´n tá»‘t hÆ¡n Single-Task Learning.</li><li class="correct-answer">B. Trong trÆ°á»ng há»£p nÃ y, viá»‡c há»c thÃªm nhiá»‡m vá»¥ phá»¥ (dá»± Ä‘oÃ¡n Active-Time) Ä‘Ã£ giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c biá»ƒu diá»…n tá»‘t hÆ¡n, tá»« Ä‘Ã³ cáº£i thiá»‡n hiá»‡u suáº¥t cho nhiá»‡m vá»¥ chÃ­nh (gá»£i Ã½).</li><li>C. Multi-Task Learning lÃ m cho mÃ´ hÃ¬nh cháº¡y nhanh hÆ¡n.</li><li>D. Single-Task Learning phá»©c táº¡p hÆ¡n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> ÄÃ¢y lÃ  má»™t trong nhá»¯ng lá»£i Ã­ch chÃ­nh cá»§a Multi-Task Learning. Báº±ng cÃ¡ch buá»™c mÃ´ hÃ¬nh pháº£i há»c cÃ¡c biá»ƒu diá»…n cÃ³ thá»ƒ sá»­ dá»¥ng cho nhiá»u nhiá»‡m vá»¥ liÃªn quan, nÃ³ cÃ³ thá»ƒ há»c Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng tá»•ng quÃ¡t vÃ  máº¡nh máº½ hÆ¡n, hoáº¡t Ä‘á»™ng nhÆ° má»™t dáº¡ng hiá»‡u chá»‰nh (regularization).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 45: Trong News Encoder, `e_c'` (slide 9) lÃ  gÃ¬?</p><ul class="options"><li>A. Biá»ƒu diá»…n cá»§a toÃ n bá»™ Categories.</li><li class="correct-answer">B. Biá»ƒu diá»…n Ä‘Æ°á»£c há»c cho má»™t category cá»¥ thá»ƒ sau khi qua táº§ng FNN (`tanh`).</li><li>C. Vector attention.</li><li>D. Biá»ƒu diá»…n cá»§a Title.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ vÃ  cÃ´ng thá»©c `e_c' = tanh(W_c * e_c + b_c)` cho tháº¥y `e_c'` lÃ  káº¿t quáº£ cá»§a viá»‡c Ä‘Æ°a vector embedding ban Ä‘áº§u cá»§a má»™t category (`e_c`) qua má»™t táº§ng biáº¿n Ä‘á»•i phi tuyáº¿n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 46: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 6, viá»‡c khai thÃ¡c Active-Time cÃ³ thá»ƒ giÃºp Ã­ch cho cÃ¡c váº¥n Ä‘á» nÃ o khÃ¡c ngoÃ i gá»£i Ã½?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">Quáº£ng cÃ¡o, Ä‘iá»u khiá»ƒn</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 6 ghi: "...giÃºp Ã­ch cho cÃ¡c váº¥n Ä‘á» khÃ¡c nhÆ° Quáº£ng cÃ¡o, Ä‘iá»u khiá»ƒn, ..".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 47: Trong User Encoder (slide 12), `e_i^u` lÃ  gÃ¬?</p><ul class="options"><li>A. Vector biá»ƒu diá»…n cá»§a user `u`.</li><li class="correct-answer">B. Vector biá»ƒu diá»…n (tá»« News Encoder) cá»§a bÃ i bÃ¡o thá»© `i` trong lá»‹ch sá»­ cá»§a user `u`.</li><li>C. Má»™t vector ngáº«u nhiÃªn.</li><li>D. ID cá»§a bÃ i bÃ¡o thá»© `i`.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 12 cho tháº¥y `e_1^u`, `e_2^u`, ... lÃ  cÃ¡c Ä‘áº§u ra tá»« cÃ¡c "News Encoder", tÆ°Æ¡ng á»©ng vá»›i cÃ¡c bÃ i bÃ¡o `D_1^u`, `D_2^u`, ... trong lá»‹ch sá»­ cá»§a ngÆ°á»i dÃ¹ng.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 48: "FNN" Ä‘Æ°á»£c nháº¯c Ä‘áº¿n nhiá»u láº§n trong cÃ¡c slide lÃ  viáº¿t táº¯t cá»§a thuáº­t ngá»¯ gÃ¬?</p><ul class="options"><li>A. Fast Neural Network</li><li class="correct-answer">B. Feed-forward Neural Network</li><li>C. Fused Neural Network</li><li>D. Final Neural Network</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> FNN lÃ  viáº¿t táº¯t phá»• biáº¿n cá»§a Feed-forward Neural Network (Máº¡ng nÆ¡-ron truyá»n tháº³ng), má»™t dáº¡ng cÆ¡ báº£n cá»§a máº¡ng nÆ¡-ron nÆ¡i thÃ´ng tin chá»‰ di chuyá»ƒn theo má»™t hÆ°á»›ng, tá»« Ä‘áº§u vÃ o Ä‘áº¿n Ä‘áº§u ra.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 49: Táº¡i sao mÃ´ hÃ¬nh láº¡i sá»­ dá»¥ng cáº£ LDA vÃ  Doc2vec Ä‘á»ƒ biá»ƒu diá»…n ná»™i dung?</p><ul class="options"><li>A. VÃ¬ má»™t trong hai cÃ³ thá»ƒ bá»‹ lá»—i.</li><li class="correct-answer">B. Äá»ƒ táº­n dá»¥ng Ä‘iá»ƒm máº¡nh cá»§a cáº£ hai phÆ°Æ¡ng phÃ¡p; LDA náº¯m báº¯t tá»‘t cÃ¡c chá»§ Ä‘á» (topic), trong khi Doc2vec náº¯m báº¯t tá»‘t ngá»¯ nghÄ©a á»Ÿ cáº¥p Ä‘á»™ cÃ¢u/Ä‘oáº¡n vÄƒn.</li><li>C. VÃ¬ tÃ¡c giáº£ khÃ´ng quyáº¿t Ä‘á»‹nh Ä‘Æ°á»£c nÃªn dÃ¹ng cÃ¡i nÃ o.</li><li>D. Äá»ƒ tÄƒng sá»‘ chiá»u cá»§a vector.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> ÄÃ¢y lÃ  má»™t ká»¹ thuáº­t ensemble á»Ÿ má»©c Ä‘áº·c trÆ°ng. Báº±ng cÃ¡ch káº¿t há»£p cÃ¡c biá»ƒu diá»…n tá»« cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau, má»—i mÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘Ã³ng gÃ³p má»™t loáº¡i thÃ´ng tin khÃ¡c nhau, giÃºp cho biá»ƒu diá»…n tá»•ng há»£p trá»Ÿ nÃªn phong phÃº vÃ  máº¡nh máº½ hÆ¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 50: Theo káº¿t quáº£ á»Ÿ slide 19, mÃ´ hÃ¬nh Wide&Deep cÃ³ hiá»‡u suáº¥t nhÆ° tháº¿ nÃ o so vá»›i HyperNews?</p><ul class="options"><li>A. Tá»‘t hÆ¡n</li><li class="correct-answer">B. KÃ©m hÆ¡n Ä‘Ã¡ng ká»ƒ</li><li>C. TÆ°Æ¡ng Ä‘Æ°Æ¡ng</li><li>D. KhÃ´ng thá»ƒ so sÃ¡nh</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> TrÃªn táº­p Adressa-1week, AUC cá»§a Wide&Deep lÃ  0.7415 so vá»›i 0.8661 cá»§a HyperNews. F1 cÅ©ng tÆ°Æ¡ng tá»± (0.7244 vs 0.8027). Sá»± chÃªnh lá»‡ch nÃ y lÃ  ráº¥t Ä‘Ã¡ng ká»ƒ, cho tháº¥y HyperNews vÆ°á»£t trá»™i hÆ¡n háº³n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 51: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 11, trong Attention Unit cá»§a News Encoder, cÃ³ bao nhiÃªu bá»™ tham sá»‘ (V, q, b) cáº§n Ä‘Æ°á»£c há»c?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">3</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 11 ghi: "Thá»±c táº¿ trong model, cáº§n há»c ra 3 bá»™: (V, q, b) vá»›i 3 task".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 52: Viá»‡c sá»­ dá»¥ng "Freshness" (slide 13) lÃ m má»™t Ä‘áº·c trÆ°ng Ä‘áº§u vÃ o cÃ³ Ã½ nghÄ©a gÃ¬?</p><ul class="options"><li>A. NÃ³ Ä‘o Ä‘á»™ sáº¡ch sáº½ cá»§a dá»¯ liá»‡u.</li><li class="correct-answer">B. NÃ³ náº¯m báº¯t thÃ´ng tin vá» Ä‘á»™ "má»›i" cá»§a tin tá»©c á»©ng viÃªn, má»™t yáº¿u tá»‘ quan trá»ng trong gá»£i Ã½ tin tá»©c.</li><li>C. NÃ³ Ä‘o lÆ°á»ng sá»± tÆ°Æ¡i má»›i cá»§a giao diá»‡n.</li><li>D. NÃ³ khÃ´ng cÃ³ Ã½ nghÄ©a.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong lÄ©nh vá»±c tin tá»©c, Ä‘á»™ má»›i (freshness) lÃ  má»™t yáº¿u tá»‘ cá»±c ká»³ quan trá»ng. Má»™t tin tá»©c tá»« hÃ´m qua cÃ³ thá»ƒ khÃ´ng cÃ²n giÃ¡ trá»‹. Viá»‡c Ä‘Æ°a "Freshness" vÃ o lÃ m má»™t Ä‘áº·c trÆ°ng cho phÃ©p mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c táº§m quan trá»ng cá»§a yáº¿u tá»‘ nÃ y.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 53: Táº¡i sao láº¡i cáº§n cÃ³ má»™t "User Encoder"?</p><ul class="options"><li>A. Äá»ƒ Ä‘áº¿m sá»‘ lÆ°á»£ng ngÆ°á»i dÃ¹ng.</li><li class="correct-answer">B. Äá»ƒ táº¡o ra má»™t vector biá»ƒu diá»…n cho sá»Ÿ thÃ­ch vÃ  lá»‹ch sá»­ cá»§a ngÆ°á»i dÃ¹ng, lÃ m cÆ¡ sá»Ÿ cho viá»‡c cÃ¡ nhÃ¢n hÃ³a gá»£i Ã½.</li><li>C. Äá»ƒ mÃ£ hÃ³a tÃªn ngÆ°á»i dÃ¹ng.</li><li>D. Äá»ƒ tÄƒng tá»‘c Ä‘á»™ há»‡ thá»‘ng.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Äá»ƒ gá»£i Ã½ Ä‘Æ°á»£c cÃ¡ nhÃ¢n hÃ³a, há»‡ thá»‘ng pháº£i hiá»ƒu Ä‘Æ°á»£c "báº¡n lÃ  ai" vÃ  "báº¡n thÃ­ch gÃ¬". User Encoder (slide 12) chÃ­nh lÃ  thÃ nh pháº§n thá»±c hiá»‡n nhiá»‡m vá»¥ nÃ y báº±ng cÃ¡ch tá»•ng há»£p lá»‹ch sá»­ duyá»‡t web cá»§a ngÆ°á»i dÃ¹ng thÃ nh má»™t vector sá»Ÿ thÃ­ch duy nháº¥t (`e_U`).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 54: Kiáº¿n trÃºc HyperNews cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng cho lÄ©nh vá»±c nÃ o khÃ¡c ngoÃ i gá»£i Ã½ tin tá»©c?</p><ul class="options"><li>A. Chá»‰ cÃ³ thá»ƒ Ã¡p dá»¥ng cho tin tá»©c.</li><li class="correct-answer">B. CÃ³ thá»ƒ Ã¡p dá»¥ng cho cÃ¡c lÄ©nh vá»±c khÃ¡c cÃ³ yáº¿u tá»‘ thá»i gian vÃ  tÆ°Æ¡ng tÃ¡c tuáº§n tá»±, vÃ­ dá»¥ nhÆ° gá»£i Ã½ video trÃªn YouTube hoáº·c gá»£i Ã½ sáº£n pháº©m trÃªn cÃ¡c trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­.</li><li>C. Chá»‰ Ã¡p dá»¥ng cho gá»£i Ã½ phim.</li><li>D. Chá»‰ Ã¡p dá»¥ng cho dá»¯ liá»‡u vÄƒn báº£n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Máº·c dÃ¹ Ä‘Æ°á»£c thiáº¿t káº¿ cho tin tá»©c, cÃ¡c Ã½ tÆ°á»Ÿng cá»‘t lÃµi cá»§a HyperNews (Multi-Task Learning, mÃ£ hÃ³a lá»‹ch sá»­ báº±ng Attention, xem xÃ©t Timeliness) lÃ  ráº¥t tá»•ng quÃ¡t vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh Ä‘á»ƒ Ã¡p dá»¥ng cho nhiá»u bÃ i toÃ¡n gá»£i Ã½ tuáº§n tá»± khÃ¡c.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 55: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 16, Loss tá»•ng há»£p `L` báº±ng tá»•ng cá»§a `Lp` vÃ  thÃ nh pháº§n nÃ o?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">Î»L't</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 16 cÃ³ cÃ´ng thá»©c: `L = Lp + Î»L't`. `L't` lÃ  hÃ m loss Ä‘Ã£ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cho viá»‡c máº¥t cÃ¢n báº±ng lá»›p.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 56: Trong News Encoder, táº¡i sao láº¡i káº¿t há»£p cáº£ biá»ƒu diá»…n Explicit vÃ  Implicit?</p><ul class="options"><li>A. VÃ¬ má»™t trong hai cÃ³ thá»ƒ bá»‹ thiáº¿u.</li><li class="correct-answer">B. VÃ¬ chÃºng cung cáº¥p hai loáº¡i thÃ´ng tin bá»• sung cho nhau: thÃ´ng tin bá» máº·t (Ä‘á»ƒ thu hÃºt click) vÃ  thÃ´ng tin chiá»u sÃ¢u (liÃªn quan Ä‘áº¿n sá»± hÃ i lÃ²ng sau khi Ä‘á»c).</li><li>C. Äá»ƒ lÃ m cho mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n.</li><li>D. VÃ¬ quy Ä‘á»‹nh yÃªu cáº§u váº­y.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 11 nháº­n xÃ©t ráº±ng hai loáº¡i Ä‘áº·c trÆ°ng nÃ y cÃ³ "cÃ¡c tÃ¡c Ä‘á»™ng khÃ¡c nhau Ä‘áº¿n xÃ¡c suáº¥t User Ä‘á»c bÃ i vÃ  thá»i gian Ä‘á»c". Viá»‡c káº¿t há»£p chÃºng cho phÃ©p mÃ´ hÃ¬nh cÃ³ má»™t cÃ¡i nhÃ¬n toÃ n diá»‡n hÆ¡n vá» má»™t bÃ i bÃ¡o.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 57: Trong táº§ng CNN cá»§a Explicit Embedding (slide 9), `m = 200` cÃ³ nghÄ©a lÃ  gÃ¬?</p><ul class="options"><li>A. CÃ³ 200 táº§ng CNN.</li><li class="correct-answer">B. Táº§ng CNN sá»­ dá»¥ng 200 bá»™ lá»c (filters) khÃ¡c nhau Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng.</li><li>C. KÃ­ch thÆ°á»›c cá»§a má»—i bá»™ lá»c lÃ  200.</li><li>D. Biá»ƒu diá»…n title cÃ³ 200 chiá»u.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 ghi: "Sá»­ dá»¥ng 200 filters (m = 200)". Trong CNN cho vÄƒn báº£n, má»—i bá»™ lá»c sáº½ há»c cÃ¡ch nháº­n diá»‡n má»™t loáº¡i n-gram (cá»¥m tá»«) cá»¥ thá»ƒ.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 58: Táº¡i sao láº¡i cáº§n cÃ³ táº§ng "Dense" sau táº§ng "Embedding" cho "Freshness" vÃ  "Timeliness" (slide 13)?</p><ul class="options"><li>A. Äá»ƒ giáº£m sá»‘ chiá»u.</li><li class="correct-answer">B. Äá»ƒ cho phÃ©p mÃ´ hÃ¬nh há»c má»™t phÃ©p biáº¿n Ä‘á»•i phi tuyáº¿n phá»©c táº¡p hÆ¡n trÃªn cÃ¡c biá»ƒu diá»…n embedding ban Ä‘áº§u.</li><li>C. Äá»ƒ tÄƒng sá»‘ chiá»u.</li><li>D. Äá»ƒ thÃªm nhiá»…u.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Táº§ng embedding chá»‰ lÃ  má»™t phÃ©p tra cá»©u (lookup). Viá»‡c thÃªm má»™t hoáº·c nhiá»u táº§ng Dense (FNN) vá»›i cÃ¡c hÃ m kÃ­ch hoáº¡t phi tuyáº¿n cho phÃ©p mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ phá»©c táº¡p hÆ¡n giá»¯a cÃ¡c khoáº£ng thá»i gian vÃ  tÃ¡c Ä‘á»™ng cá»§a chÃºng Ä‘áº¿n káº¿t quáº£ gá»£i Ã½.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 59: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 8, News Encoder bao gá»“m 2 pháº§n lÃ  Explicit Embedding vÃ  loáº¡i Embedding nÃ o ná»¯a?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">Implicit Embedding</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 8 ghi rÃµ: "Bao gá»“m 2 pháº§n: Explicit Embedding vÃ  Implicit Embedding".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 60: Trong káº¿t quáº£ á»Ÿ slide 18, AUC lÃ  Ä‘á»™ Ä‘o cho nhiá»‡m vá»¥ nÃ o?</p><ul class="options"><li class="correct-answer">A. News Recommendation (phÃ¢n loáº¡i nhá»‹ phÃ¢n: click/khÃ´ng click).</li><li>B. Active-time Prediction.</li><li>C. Cáº£ hai.</li><li>D. KhÃ´ng nhiá»‡m vá»¥ nÃ o.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> AUC (Area Under the ROC Curve) lÃ  má»™t Ä‘á»™ Ä‘o phá»• biáº¿n cho hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i nhá»‹ phÃ¢n. Trong bá»‘i cáº£nh nÃ y, nÃ³ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh trong viá»‡c xáº¿p háº¡ng cÃ¡c bÃ i bÃ¡o mÃ  ngÆ°á»i dÃ¹ng sáº½ click cao hÆ¡n cÃ¡c bÃ i bÃ¡o há» khÃ´ng click. Biá»ƒu Ä‘á»“ cÅ©ng ghi rÃµ "News Recommendation" dÆ°á»›i cá»™t AUC.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 61: Trong káº¿t quáº£ á»Ÿ slide 18, F1 lÃ  Ä‘á»™ Ä‘o cho nhiá»‡m vá»¥ nÃ o?</p><ul class="options"><li>A. Chá»‰ News Recommendation.</li><li>B. Chá»‰ Active-time Prediction.</li><li class="correct-answer">C. Cáº£ News Recommendation vÃ  Active-time Prediction.</li><li>D. KhÃ´ng nhiá»‡m vá»¥ nÃ o.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Biá»ƒu Ä‘á»“ trÃªn slide 18 cÃ³ hai cá»™t F1 riÃªng biá»‡t: má»™t cho "News Recommendation" vÃ  má»™t cho "Active-time Prediction", cho tháº¥y F1-score Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cáº£ hai nhiá»‡m vá»¥ phÃ¢n loáº¡i nÃ y.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 62: (Äiá»n Ä‘Ã¡p Ã¡n) Theo báº£ng á»Ÿ slide 19, giÃ¡ trá»‹ AUC cá»§a mÃ´ hÃ¬nh LSTUR trÃªn táº­p Adressa-4week lÃ  bao nhiÃªu?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">0.7725</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong báº£ng, táº¡i hÃ ng "LSTUR" vÃ  cá»™t "AUC" cá»§a "Adressa-4week", giÃ¡ trá»‹ lÃ  0.7725.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 63: (Äiá»n Ä‘Ã¡p Ã¡n) Theo báº£ng á»Ÿ slide 19, giÃ¡ trá»‹ F1 cá»§a mÃ´ hÃ¬nh DeepFM trÃªn táº­p Adressa-1week lÃ  bao nhiÃªu?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">0.7288</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong báº£ng, táº¡i hÃ ng "DeepFM" vÃ  cá»™t "F1" cá»§a "Adressa-1week", giÃ¡ trá»‹ lÃ  0.7288.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 64: MÃ´ hÃ¬nh DSSM trong báº£ng so sÃ¡nh (slide 19) cÃ³ thá»ƒ lÃ  viáº¿t táº¯t cá»§a thuáº­t ngá»¯ gÃ¬?</p><ul class="options"><li>A. Deep Structured Semantic Model</li><li class="correct-answer">B. Deep Semantic Similarity Model</li><li>C. Dynamic Social Sensing Model</li><li>D. Double-Task Semantic Model</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> DSSM lÃ  má»™t kiáº¿n trÃºc deep learning ná»•i tiáº¿ng cá»§a Microsoft, viáº¿t táº¯t cá»§a Deep Structured Semantic Model hoáº·c Deep Semantic Similarity Model, thÆ°á»ng Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ há»c cÃ¡c biá»ƒu diá»…n ngá»¯ nghÄ©a cho vÄƒn báº£n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 65: Táº¡i sao HyperNews láº¡i vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh nhÆ° LSTUR hay DAN?</p><ul class="options"><li>A. VÃ¬ nÃ³ Ä‘Æ¡n giáº£n hÆ¡n.</li><li class="correct-answer">B. VÃ¬ nÃ³ khai thÃ¡c hiá»‡u quáº£ hÆ¡n cÃ¡c loáº¡i thÃ´ng tin (explicit, implicit, timeliness, user history) vÃ  sá»­ dá»¥ng kiáº¿n trÃºc Multi-task learning Ä‘á»ƒ há»c cÃ¡c biá»ƒu diá»…n máº¡nh máº½ hÆ¡n.</li><li>C. VÃ¬ nÃ³ sá»­ dá»¥ng bá»™ dá»¯ liá»‡u lá»›n hÆ¡n.</li><li>D. VÃ¬ nÃ³ Ä‘Æ°á»£c huáº¥n luyá»‡n lÃ¢u hÆ¡n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Sá»± vÆ°á»£t trá»™i cá»§a HyperNews Ä‘áº¿n tá»« thiáº¿t káº¿ kiáº¿n trÃºc toÃ n diá»‡n cá»§a nÃ³. NÃ³ khÃ´ng chá»‰ xem xÃ©t ná»™i dung vÃ  lá»‹ch sá»­ nhÆ° cÃ¡c mÃ´ hÃ¬nh khÃ¡c mÃ  cÃ²n tÃ­ch há»£p thÃ´ng tin "Active-Time" vÃ  "Timeliness" thÃ´ng qua má»™t framework Ä‘a nhiá»‡m, cho phÃ©p cÃ¡c nhiá»‡m vá»¥ há»— trá»£ láº«n nhau.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 66: "Candidate News" trong sÆ¡ Ä‘á»“ (slide 7a) lÃ  gÃ¬?</p><ul class="options"><li>A. CÃ¡c bÃ i bÃ¡o ngÆ°á»i dÃ¹ng Ä‘Ã£ Ä‘á»c.</li><li class="correct-answer">B. CÃ¡c bÃ i bÃ¡o á»©ng viÃªn Ä‘ang Ä‘Æ°á»£c xem xÃ©t Ä‘á»ƒ gá»£i Ã½ cho ngÆ°á»i dÃ¹ng.</li><li>C. CÃ¡c bÃ i bÃ¡o tin giáº£.</li><li>D. CÃ¡c bÃ i bÃ¡o chÆ°a Ä‘Æ°á»£c xuáº¥t báº£n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> "Candidate News" lÃ  cÃ¡c item tiá»m nÄƒng. Nhiá»‡m vá»¥ cá»§a há»‡ thá»‘ng lÃ  tÃ­nh toÃ¡n má»™t Ä‘iá»ƒm sá»‘ (vÃ­ dá»¥: xÃ¡c suáº¥t click) cho má»—i Candidate News Ä‘á»‘i vá»›i má»™t User cá»¥ thá»ƒ, sau Ä‘Ã³ xáº¿p háº¡ng chÃºng vÃ  chá»n ra nhá»¯ng item tá»‘t nháº¥t Ä‘á»ƒ gá»£i Ã½.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 67: Trong kiáº¿n trÃºc tá»•ng thá»ƒ, Ä‘áº§u ra cá»§a User Encoder (`e_U`) vÃ  News Encoder (`e_N` cá»§a Candidate News) Ä‘Æ°á»£c káº¿t há»£p á»Ÿ Ä‘Ã¢u?</p><ul class="options"><li class="correct-answer">A. Trong khá»‘i Multi-task.</li><li>B. Trong khá»‘i News Encoder.</li><li>C. Trong khá»‘i User Encoder.</li><li>D. ChÃºng khÃ´ng Ä‘Æ°á»£c káº¿t há»£p.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 7a vÃ  13 cho tháº¥y `e_U` vÃ  `e_N` (Ä‘Ã£ Ä‘Æ°á»£c káº¿t há»£p vá»›i Timeliness) Ä‘Æ°á»£c Ä‘Æ°a vÃ o khá»‘i Multi-task Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c phÃ©p toÃ¡n cuá»‘i cÃ¹ng (Dot product, Classifier) vÃ  Ä‘Æ°a ra dá»± Ä‘oÃ¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 68: Náº¿u bá» Ä‘i User Encoder, há»‡ thá»‘ng sáº½ trá»Ÿ thÃ nh loáº¡i gá»£i Ã½ nÃ o?</p><ul class="options"><li>A. Gá»£i Ã½ Ä‘Æ°á»£c cÃ¡ nhÃ¢n hÃ³a cao.</li><li class="correct-answer">B. Gá»£i Ã½ khÃ´ng Ä‘Æ°á»£c cÃ¡ nhÃ¢n hÃ³a (non-personalized) hoáº·c chá»‰ dá»±a trÃªn ngá»¯ cáº£nh.</li><li>C. Gá»£i Ã½ dá»±a trÃªn lá»c cá»™ng tÃ¡c.</li><li>D. Gá»£i Ã½ dá»±a trÃªn tri thá»©c.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> User Encoder lÃ  thÃ nh pháº§n táº¡o ra biá»ƒu diá»…n cho sá»Ÿ thÃ­ch cÃ¡ nhÃ¢n cá»§a ngÆ°á»i dÃ¹ng. Náº¿u khÃ´ng cÃ³ nÃ³, há»‡ thá»‘ng sáº½ khÃ´ng thá»ƒ phÃ¢n biá»‡t giá»¯a cÃ¡c ngÆ°á»i dÃ¹ng khÃ¡c nhau vÃ  chá»‰ cÃ³ thá»ƒ Ä‘Æ°a ra cÃ¡c gá»£i Ã½ chung chung, vÃ­ dá»¥ nhÆ° cÃ¡c bÃ i bÃ¡o phá»• biáº¿n nháº¥t.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 69: Viá»‡c chia thá»i gian Ä‘á»c thÃ nh cÃ¡c "bins" (khoáº£ng) lÃ  má»™t vÃ­ dá»¥ cá»§a ká»¹ thuáº­t gÃ¬ trong xá»­ lÃ½ dá»¯ liá»‡u?</p><ul class="options"><li>A. Chuáº©n hÃ³a (Normalization)</li><li class="correct-answer">B. Rá»i ráº¡c hÃ³a (Discretization)</li><li>C. Láº¥y máº«u (Sampling)</li><li>D. Giáº£m chiá»u (Dimensionality Reduction)</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Rá»i ráº¡c hÃ³a lÃ  quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i má»™t biáº¿n liÃªn tá»¥c thÃ nh má»™t biáº¿n rá»i ráº¡c báº±ng cÃ¡ch chia nÃ³ thÃ nh má»™t sá»‘ khoáº£ng (bins) há»¯u háº¡n. ÄÃ¢y chÃ­nh xÃ¡c lÃ  nhá»¯ng gÃ¬ Ä‘Æ°á»£c mÃ´ táº£ á»Ÿ slide 14.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 70: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 11, thá»±c táº¿ trong mÃ´ hÃ¬nh HyperNews, cÃ³ bao nhiÃªu nhiá»‡m vá»¥ (task) cáº§n há»c cÃ¡c bá»™ tham sá»‘ Attention?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">3</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 11 ghi: "...cáº§n há»c ra 3 bá»™: (V, q, b) vá»›i 3 task: Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t Click, Thá»i gian Ä‘á»c, Biá»ƒu diá»…n User". Má»—i nhiá»‡m vá»¥ cÃ³ thá»ƒ cáº§n má»™t cÆ¡ cháº¿ attention riÃªng Ä‘á»ƒ táº­p trung vÃ o cÃ¡c khÃ­a cáº¡nh khÃ¡c nhau cá»§a tin tá»©c.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 71: Theo báº¡n, táº¡i sao User Encoder láº¡i chá»‰ sá»­ dá»¥ng 30 bÃ i click gáº§n nháº¥t mÃ  khÃ´ng pháº£i táº¥t cáº£?</p><ul class="options"><li>A. VÃ¬ ngÆ°á»i dÃ¹ng khÃ´ng bao giá» Ä‘á»c quÃ¡ 30 bÃ i.</li><li class="correct-answer">B. Äá»ƒ giá»›i háº¡n Ä‘á»™ phá»©c táº¡p tÃ­nh toÃ¡n vÃ  táº­p trung vÃ o sá»Ÿ thÃ­ch gáº§n Ä‘Ã¢y cá»§a ngÆ°á»i dÃ¹ng, vá»‘n cÃ³ thá»ƒ thay Ä‘á»•i theo thá»i gian.</li><li>C. VÃ¬ chá»‰ cÃ³ 30 bÃ i Ä‘áº§u tiÃªn lÃ  quan trá»ng.</li><li>D. VÃ¬ bá»™ nhá»› khÃ´ng Ä‘á»§.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> ÄÃ¢y lÃ  má»™t lá»±a chá»n thiáº¿t káº¿ thá»±c táº¿. Xá»­ lÃ½ toÃ n bá»™ lá»‹ch sá»­ cÃ³ thá»ƒ ráº¥t tá»‘n kÃ©m vÃ  khÃ´ng cáº§n thiáº¿t, vÃ¬ sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng vá» tin tá»©c thÆ°á»ng thay Ä‘á»•i nhanh. Viá»‡c táº­p trung vÃ o cÃ¡c tÆ°Æ¡ng tÃ¡c gáº§n Ä‘Ã¢y giÃºp mÃ´ hÃ¬nh náº¯m báº¯t Ä‘Æ°á»£c sá»Ÿ thÃ­ch hiá»‡n táº¡i má»™t cÃ¡ch hiá»‡u quáº£ hÆ¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 72: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 9, biá»ƒu diá»…n cuá»‘i cÃ¹ng cá»§a Explicit Embedding Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch Ä‘Æ°a vector ghÃ©p ná»‘i qua má»™t máº¡ng nÆ¡-ron loáº¡i gÃ¬?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">FNN (Feed-forward Neural Network)</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 cÃ³ cÃ´ng thá»©c `e_Ne = FNN([eh; ec_bar])`.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 73: Giáº£ sá»­ má»™t bÃ i bÃ¡o cÃ³ 10 category. Theo thiáº¿t káº¿ trÃªn slide 9, cÆ¡ cháº¿ Attention sáº½ hoáº¡t Ä‘á»™ng trÃªn bao nhiÃªu category?</p><ul class="options"><li>A. 10</li><li class="correct-answer">B. 3</li><li>C. 1</li><li>D. 100</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 ghi rÃµ "(chá»n 3 cats quan trá»ng nháº¥t)". Äiá»u nÃ y ngá»¥ Ã½ ráº±ng mÃ´ hÃ¬nh cÃ³ má»™t cÆ¡ cháº¿ (cÃ³ thá»ƒ lÃ  dá»±a trÃªn táº§n suáº¥t hoáº·c má»™t tiÃªu chÃ­ khÃ¡c) Ä‘á»ƒ chá»n ra 3 category chÃ­nh trÆ°á»›c khi Ä‘Æ°a vÃ o Attention.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 74: Náº¿u má»™t ngÆ°á»i dÃ¹ng click vÃ o má»™t bÃ i bÃ¡o vÃ  Ä‘Ã³ng ngay láº­p tá»©c (vÃ­ dá»¥: Active-Time < 5s), dá»¯ liá»‡u nÃ y sáº½ Ä‘Æ°á»£c xá»­ lÃ½ nhÆ° tháº¿ nÃ o trong mÃ´ hÃ¬nh?</p><ul class="options"><li>A. ÄÆ°á»£c coi lÃ  má»™t tÆ°Æ¡ng tÃ¡c ráº¥t tÃ­ch cá»±c.</li><li class="correct-answer">B. Váº«n Ä‘Æ°á»£c ghi nháº­n lÃ  má»™t "click" (máº«u dÆ°Æ¡ng cho nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n click), nhÆ°ng cÃ³ thá»ƒ khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng cho nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n Active-Time (vÃ¬ náº±m ngoÃ i khoáº£ng 5s-205s).</li><li>C. Bá»‹ loáº¡i bá» hoÃ n toÃ n.</li><li>D. ÄÆ°á»£c coi lÃ  má»™t tÆ°Æ¡ng tÃ¡c tiÃªu cá»±c.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> MÃ´ hÃ¬nh cÃ³ hai nhiá»‡m vá»¥ riÃªng biá»‡t. HÃ nh Ä‘á»™ng click táº¡o ra má»™t máº«u dÆ°Æ¡ng cho nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n click. Tuy nhiÃªn, vÃ¬ thá»i gian Ä‘á»c náº±m ngoÃ i khoáº£ng Ä‘Æ°á»£c xem xÃ©t (5s-205s), nÃ³ sáº½ khÃ´ng Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ huáº¥n luyá»‡n cho mÃ´ hÃ¬nh phÃ¢n loáº¡i Active-Time.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 75: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 15, `S+` vÃ  `S-` trong hÃ m loss `Lp` láº§n lÆ°á»£t lÃ  táº­p cÃ¡c máº«u nÃ o?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">Táº­p cÃ¡c máº«u dÆ°Æ¡ng (positive) vÃ  Ã¢m (negative)</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> `S+` lÃ  táº­p cÃ¡c máº«u cÃ³ `y_p=1` (click), vÃ  `S-` lÃ  táº­p cÃ¡c máº«u cÃ³ `y_p=0` (khÃ´ng click). ÄÃ¢y lÃ  cÃ¡ch kÃ½ hiá»‡u chuáº©n cho hÃ m loss cross-entropy.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 76: Tham sá»‘ `Î»` trong hÃ m loss tá»•ng há»£p `L = Lp + Î»L't` (slide 16) dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬?</p><ul class="options"><li>A. Tá»‘c Ä‘á»™ há»c</li><li class="correct-answer">B. LÃ  má»™t siÃªu tham sá»‘ Ä‘á»ƒ cÃ¢n báº±ng táº§m quan trá»ng giá»¯a hai nhiá»‡m vá»¥ (dá»± Ä‘oÃ¡n click vÃ  dá»± Ä‘oÃ¡n thá»i gian).</li><li>C. Tham sá»‘ hiá»‡u chá»‰nh (regularization).</li><li>D. Sá»‘ lÆ°á»£ng máº«u.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong Multi-Task Learning, viá»‡c cÃ¢n báº±ng cÃ¡c hÃ m loss cá»§a cÃ¡c nhiá»‡m vá»¥ khÃ¡c nhau lÃ  ráº¥t quan trá»ng. `Î»` cho phÃ©p nhÃ  nghiÃªn cá»©u quyáº¿t Ä‘á»‹nh xem mÃ´ hÃ¬nh nÃªn Æ°u tiÃªn tá»‘i Æ°u hÃ³a cho nhiá»‡m vá»¥ nÃ o hÆ¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 77: Táº¡i sao káº¿t quáº£ trÃªn táº­p Adressa-4week láº¡i tháº¥p hÆ¡n Adressa-1week (slide 18, 19)?</p><ul class="options"><li>A. Do lá»—i trong quÃ¡ trÃ¬nh thá»­ nghiá»‡m.</li><li class="correct-answer">B. CÃ³ thá»ƒ vÃ¬ Adressa-4week lÃ  má»™t bá»™ dá»¯ liá»‡u lá»›n hÆ¡n vÃ  Ä‘a dáº¡ng hÆ¡n, lÃ m cho bÃ i toÃ¡n trá»Ÿ nÃªn khÃ³ hÆ¡n.</li><li>C. VÃ¬ Adressa-1week cÃ³ nhiá»u dá»¯ liá»‡u hÆ¡n.</li><li>D. VÃ¬ cÃ¡c mÃ´ hÃ¬nh bá»‹ overfitting trÃªn Adressa-4week.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Má»™t bá»™ dá»¯ liá»‡u lá»›n hÆ¡n (4 tuáº§n so vá»›i 1 tuáº§n) thÆ°á»ng chá»©a nhiá»u ngÆ°á»i dÃ¹ng vÃ  sáº£n pháº©m hÆ¡n, vá»›i cÃ¡c máº«u hÃ nh vi Ä‘a dáº¡ng vÃ  phá»©c táº¡p hÆ¡n. Äiá»u nÃ y lÃ m cho viá»‡c há»c vÃ  dá»± Ä‘oÃ¡n trá»Ÿ thÃ nh má»™t thÃ¡ch thá»©c lá»›n hÆ¡n, dáº«n Ä‘áº¿n Ä‘iá»ƒm sá»‘ cÃ¡c Ä‘á»™ Ä‘o thÆ°á»ng tháº¥p hÆ¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 78: SÆ¡ Ä‘á»“ khá»‘i "Concatenation" trong cÃ¡c kiáº¿n trÃºc trÃªn slide cÃ³ chá»©c nÄƒng gÃ¬?</p><ul class="options"><li>A. TÃ­nh tá»•ng cÃ¡c vector.</li><li class="correct-answer">B. GhÃ©p ná»‘i cÃ¡c vector láº¡i vá»›i nhau Ä‘á»ƒ táº¡o thÃ nh má»™t vector dÃ i hÆ¡n.</li><li>C. NhÃ¢n cÃ¡c vector.</li><li>D. Chá»n vector lá»›n nháº¥t.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Concatenation lÃ  má»™t phÃ©p toÃ¡n phá»• biáº¿n trong deep learning, dÃ¹ng Ä‘á»ƒ káº¿t há»£p thÃ´ng tin tá»« nhiá»u nguá»“n báº±ng cÃ¡ch Ä‘áº·t cÃ¡c vector ná»‘i tiáº¿p nhau.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 79: Trong News Encoder, Ä‘áº§u ra `e` cá»§a Attention Unit (slide 11) Ä‘Æ°á»£c dÃ¹ng lÃ m gÃ¬?</p><ul class="options"><li>A. LÃ m Ä‘áº§u ra cuá»‘i cÃ¹ng cá»§a mÃ´ hÃ¬nh.</li><li class="correct-answer">B. LÃ  biá»ƒu diá»…n cuá»‘i cÃ¹ng, tá»•ng há»£p cá»§a bÃ i bÃ¡o, Ä‘Æ°á»£c Ä‘Æ°a vÃ o cÃ¡c bÆ°á»›c tiáº¿p theo (vÃ­ dá»¥: User Encoder hoáº·c khá»‘i Multi-task).</li><li>C. DÃ¹ng Ä‘á»ƒ tÃ­nh toÃ¡n loss.</li><li>D. Bá»‹ loáº¡i bá».</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> `e` lÃ  vector biá»ƒu diá»…n cho má»™t bÃ i bÃ¡o sau khi Ä‘Ã£ káº¿t há»£p cáº£ thÃ´ng tin explicit vÃ  implicit. Vector nÃ y (`e_i^u` trong User Encoder, `e_N` trong khá»‘i Multi-task) sau Ä‘Ã³ Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c pháº§n khÃ¡c cá»§a mÃ´ hÃ¬nh.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 80: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 17, sá»‘ lÆ°á»£ng users trong bá»™ dá»¯ liá»‡u Adressa-1week lÃ  bao nhiÃªu?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">601,215</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Báº£ng trÃªn slide 17, hÃ ng "#users", cá»™t "Adressa-1week" cÃ³ giÃ¡ trá»‹ 601,215.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 81: NhÃ¬n chung, kiáº¿n trÃºc HyperNews thuá»™c trÆ°á»ng phÃ¡i gá»£i Ã½ nÃ o?</p><ul class="options"><li>A. Gá»£i Ã½ dá»±a trÃªn lÃ¡ng giá»ng (Neighborhood-based)</li><li class="correct-answer">B. Gá»£i Ã½ dá»±a trÃªn mÃ´ hÃ¬nh (Model-based)</li><li>C. Gá»£i Ã½ dá»±a trÃªn quy táº¯c (Rule-based)</li><li>D. Gá»£i Ã½ khÃ´ng cÃ¡ nhÃ¢n hÃ³a</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> HyperNews xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh deep learning phá»©c táº¡p Ä‘á»ƒ há»c cÃ¡c biá»ƒu diá»…n áº©n vÃ  dá»± Ä‘oÃ¡n. ÄÃ¢y lÃ  Ä‘áº·c trÆ°ng Ä‘iá»ƒn hÃ¬nh cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p gá»£i Ã½ dá»±a trÃªn mÃ´ hÃ¬nh.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 82: MÃ´ hÃ¬nh cÃ³ sá»­ dá»¥ng cÆ¡ cháº¿ nÃ o Ä‘á»ƒ xá»­ lÃ½ cÃ¡c cÃ¢u cÃ³ Ä‘á»™ dÃ i khÃ¡c nhau trong Title khÃ´ng?</p><ul class="options"><li class="correct-answer">A. CÃ³, táº§ng CNN vá»›i max-pooling.</li><li>B. KhÃ´ng, nÃ³ yÃªu cáº§u táº¥t cáº£ Title pháº£i cÃ³ cÃ¹ng Ä‘á»™ dÃ i.</li><li>C. CÃ³, báº±ng cÃ¡ch Ä‘á»‡m (padding) cho cÃ¡c cÃ¢u ngáº¯n.</li><li>D. CÃ³, báº±ng cÃ¡ch cáº¯t (truncating) cÃ¡c cÃ¢u dÃ i.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Má»™t trong nhá»¯ng Æ°u Ä‘iá»ƒm cá»§a viá»‡c sá»­ dá»¥ng CNN cho xá»­ lÃ½ vÄƒn báº£n lÃ  táº§ng max-pooling (slide 9). NÃ³ láº¥y giÃ¡ trá»‹ lá»›n nháº¥t tá»« Ä‘áº§u ra cá»§a má»—i bá»™ lá»c, táº¡o ra má»™t vector cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh báº¥t ká»ƒ Ä‘á»™ dÃ i cá»§a cÃ¢u Ä‘áº§u vÃ o. ÄÃ¢y lÃ  cÃ¡ch phá»• biáº¿n Ä‘á»ƒ xá»­ lÃ½ cÃ¡c cÃ¢u cÃ³ Ä‘á»™ dÃ i thay Ä‘á»•i.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 83: Theo slide 19, mÃ´ hÃ¬nh nÃ o lÃ  má»™t baseline (mÃ´ hÃ¬nh cÆ¡ sá»Ÿ) Ä‘Æ¡n giáº£n?</p><ul class="options"><li class="correct-answer">A. LibFM</li><li>B. Wide&Deep</li><li>C. LSTUR</li><li>D. HyperNews</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> LibFM lÃ  má»™t thÆ° viá»‡n mÃ£ nguá»“n má»Ÿ ná»•i tiáº¿ng cho cÃ¡c mÃ´ hÃ¬nh Factorization Machines, thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m má»™t baseline máº¡nh cho cÃ¡c bÃ i toÃ¡n gá»£i Ã½. Trong báº£ng so sÃ¡nh, nÃ³ cÃ³ hiá»‡u suáº¥t tháº¥p nháº¥t, cho tháº¥y cÃ¡c mÃ´ hÃ¬nh deep learning phá»©c táº¡p hÆ¡n Ä‘Ã£ mang láº¡i sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 84: Náº¿u bá» Ä‘i nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n Active-Time, mÃ´ hÃ¬nh HyperNews sáº½ gáº§n giá»‘ng vá»›i mÃ´ hÃ¬nh nÃ o trong báº£ng so sÃ¡nh?</p><ul class="options"><li>A. LibFM</li><li>B. Wide&Deep</li><li class="correct-answer">C. CÃ¡c mÃ´ hÃ¬nh nhÆ° LSTUR, DAN, vÃ¬ chÃºng cÅ©ng lÃ  cÃ¡c mÃ´ hÃ¬nh deep learning cho gá»£i Ã½ tin tá»©c dá»±a trÃªn lá»‹ch sá»­ ngÆ°á»i dÃ¹ng vÃ  ná»™i dung.</li><li>D. KhÃ´ng giá»‘ng mÃ´ hÃ¬nh nÃ o.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> PhiÃªn báº£n `HyperNews(NoPred)` vá» cÆ¡ báº£n lÃ  má»™t há»‡ thá»‘ng gá»£i Ã½ tin tá»©c deep learning Ä‘Æ¡n nhiá»‡m. CÃ¡c mÃ´ hÃ¬nh nhÆ° LSTUR vÃ  DAN cÅ©ng Ä‘Æ°á»£c thiáº¿t káº¿ cho cÃ¹ng má»™t bÃ i toÃ¡n, sá»­ dá»¥ng cÃ¡c kiáº¿n trÃºc tÆ°Æ¡ng tá»± (vÃ­ dá»¥: mÃ£ hÃ³a ngÆ°á»i dÃ¹ng, mÃ£ hÃ³a tin tá»©c, cÆ¡ cháº¿ attention).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 85: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 17, sá»‘ lÆ°á»£ng tá»« trung bÃ¬nh trÃªn má»—i tiÃªu Ä‘á» (#words-per-title) trong bá»™ Adressa-4week lÃ  bao nhiÃªu?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">6.50</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Báº£ng trÃªn slide 17, hÃ ng "#words-per-title", cá»™t "Adressa-4week" cÃ³ giÃ¡ trá»‹ 6.50.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 86: Táº¡i sao cáº§n Ä‘á»‹nh nghÄ©a láº¡i loss cho nhiá»‡m vá»¥ Active-Time (L't á»Ÿ slide 16)?</p><ul class="options"><li>A. Äá»ƒ lÃ m cho loss lá»›n hÆ¡n.</li><li class="correct-answer">B. Äá»ƒ xá»­ lÃ½ váº¥n Ä‘á» máº¥t cÃ¢n báº±ng lá»›p, báº±ng cÃ¡ch tÄƒng trá»ng sá»‘ cho cÃ¡c lá»›p cÃ³ Ã­t máº«u (thá»i gian Ä‘á»c dÃ i).</li><li>C. Äá»ƒ lÃ m cho loss nhá» hÆ¡n.</li><li>D. Äá»ƒ Ä‘Æ¡n giáº£n hÃ³a viá»‡c tÃ­nh toÃ¡n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Khi cÃ¡c lá»›p bá»‹ máº¥t cÃ¢n báº±ng, mÃ´ hÃ¬nh cÃ³ xu hÆ°á»›ng chá»‰ dá»± Ä‘oÃ¡n cÃ¡c lá»›p Ä‘a sá»‘. Báº±ng cÃ¡ch Ä‘á»‹nh nghÄ©a láº¡i loss vá»›i trá»ng sá»‘ `1/E_m_yt`, cÃ¡c máº«u thuá»™c lá»›p hiáº¿m sáº½ cÃ³ Ä‘Ã³ng gÃ³p lá»›n hÆ¡n vÃ o tá»•ng loss, buá»™c mÃ´ hÃ¬nh pháº£i há»c cÃ¡ch phÃ¢n loáº¡i chÃºng má»™t cÃ¡ch chÃ­nh xÃ¡c.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 87: SÆ¡ Ä‘á»“ trÃªn slide 7b (News Encoder) cho tháº¥y thÃ´ng tin Content Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi nhá»¯ng thÃ nh pháº§n nÃ o?</p><ul class="options"><li>A. Chá»‰ LDA.</li><li>B. Chá»‰ Doc2vec.</li><li class="correct-answer">C. LDA, Doc2vec, vÃ  Embedding cho Length.</li><li>D. Chá»‰ FNN.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ chi tiáº¿t cá»§a News Encoder cho tháº¥y khá»‘i "Texts Content" Ä‘Æ°á»£c Ä‘Æ°a vÃ o cáº£ LDA vÃ  Doc2vec, vÃ  thÃ´ng tin "Length" cÅ©ng Ä‘Æ°á»£c mÃ£ hÃ³a. Táº¥t cáº£ sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘Æ°a qua FNN.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 88: Náº¿u má»™t ngÆ°á»i dÃ¹ng chá»‰ Ä‘á»c cÃ¡c bÃ i bÃ¡o vá» thá»ƒ thao, vector biá»ƒu diá»…n `e_U` cá»§a ngÆ°á»i dÃ¹ng Ä‘Ã³ sáº½ cÃ³ Ä‘áº·c Ä‘iá»ƒm gÃ¬?</p><ul class="options"><li>A. Sáº½ lÃ  má»™t vector khÃ´ng.</li><li class="correct-answer">B. Sáº½ cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao vá»›i cÃ¡c vector `e_N` cá»§a cÃ¡c bÃ i bÃ¡o thá»ƒ thao khÃ¡c.</li><li>C. Sáº½ cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao vá»›i vector cá»§a cÃ¡c bÃ i bÃ¡o chÃ­nh trá»‹.</li><li>D. Sáº½ thay Ä‘á»•i ngáº«u nhiÃªn.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> User Encoder Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ há»c má»™t biá»ƒu diá»…n cho sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng. Náº¿u ngÆ°á»i dÃ¹ng chá»‰ Ä‘á»c vá» thá»ƒ thao, vector `e_U` sáº½ Ä‘Æ°á»£c hÃ¬nh thÃ nh tá»« cÃ¡c vector `e_N` cá»§a cÃ¡c bÃ i bÃ¡o thá»ƒ thao, vÃ  do Ä‘Ã³ nÃ³ sáº½ náº±m trong vÃ¹ng "thá»ƒ thao" cá»§a khÃ´ng gian Ä‘áº·c trÆ°ng áº©n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 89: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 13, xÃ¡c suáº¥t click `Å·p` Ä‘Æ°á»£c tÃ­nh báº±ng hÃ m sigmoid cá»§a tÃ­ch gÃ¬?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">TÃ­ch vÃ´ hÆ°á»›ng cá»§a e_T vÃ  e_U</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 13 cÃ³ cÃ´ng thá»©c `Å·p = sigmoid(e_T^T Ã— e_U)`. `e_T^T Ã— e_U` chÃ­nh lÃ  phÃ©p toÃ¡n tÃ­ch vÃ´ hÆ°á»›ng (dot product).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 90: Náº¿u `Î² = 1` trong cÃ´ng thá»©c `E_m = (1 - Î²^m)/(1 - Î²)`, Ä‘iá»u gÃ¬ sáº½ xáº£y ra?</p><ul class="options"><li>A. `E_m = 0`</li><li class="correct-answer">B. CÃ´ng thá»©c khÃ´ng xÃ¡c Ä‘á»‹nh (chia cho 0).</li><li>C. `E_m = m`</li><li>D. `E_m = 1`</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Náº¿u `Î² = 1`, máº«u sá»‘ `1 - Î²` sáº½ báº±ng 0, dáº«n Ä‘áº¿n phÃ©p chia khÃ´ng xÃ¡c Ä‘á»‹nh. Trong thá»±c táº¿, cÃ¡c giÃ¡ trá»‹ cá»§a `Î²` Ä‘Æ°á»£c chá»n ráº¥t gáº§n 1 (nhÆ° 0.99, 0.999) nhÆ°ng khÃ´ng bao giá» báº±ng 1.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 91: Theo slide 8, News Encoder cuá»‘i cÃ¹ng bao gá»“m máº¥y pháº§n?</p><ul class="options"><li>A. 1</li><li class="correct-answer">B. 2</li><li>C. 3</li><li>D. 4</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 8 ghi rÃµ: "Bao gá»“m 2 pháº§n: Explicit Embedding vÃ  Implicit Embedding".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 92: Trong thá»±c táº¿, viá»‡c dá»± Ä‘oÃ¡n Active-Time cÃ³ thá»ƒ giÃºp cÃ¡c nhÃ  quáº£ng cÃ¡o lÃ m gÃ¬?</p><ul class="options"><li>A. XÃ¡c Ä‘á»‹nh giÃ¡ quáº£ng cÃ¡o.</li><li class="correct-answer">B. Hiá»ƒn thá»‹ cÃ¡c quáº£ng cÃ¡o video dÃ i hÆ¡n cho nhá»¯ng ngÆ°á»i dÃ¹ng cÃ³ xu hÆ°á»›ng Ä‘á»c/xem lÃ¢u hÆ¡n.</li><li>C. Cháº·n quáº£ng cÃ¡o.</li><li>D. TÄƒng sá»‘ lÆ°á»£ng quáº£ng cÃ¡o.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 6 Ä‘á» cáº­p Ä‘áº¿n á»©ng dá»¥ng cho "Quáº£ng cÃ¡o". Náº¿u há»‡ thá»‘ng biáº¿t má»™t ngÆ°á»i dÃ¹ng cÃ³ kháº£ nÄƒng sáº½ á»Ÿ láº¡i trang trong 3 phÃºt, viá»‡c hiá»ƒn thá»‹ má»™t quáº£ng cÃ¡o video 30 giÃ¢y sáº½ hiá»‡u quáº£ hÆ¡n lÃ  hiá»ƒn thá»‹ nÃ³ cho má»™t ngÆ°á»i dÃ¹ng cÃ³ xu hÆ°á»›ng rá»i Ä‘i sau 10 giÃ¢y.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 93: Táº¡i sao Attention láº¡i há»¯u Ã­ch trong User Encoder?</p><ul class="options"><li>A. VÃ¬ nÃ³ lÃ m cho mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n.</li><li class="correct-answer">B. VÃ¬ nÃ³ cho phÃ©p mÃ´ hÃ¬nh tá»± Ä‘á»™ng xÃ¡c Ä‘á»‹nh vÃ  gÃ¡n trá»ng sá»‘ cao hÆ¡n cho cÃ¡c bÃ i bÃ¡o quan trá»ng hÆ¡n trong lá»‹ch sá»­ cá»§a ngÆ°á»i dÃ¹ng, thay vÃ¬ coi táº¥t cáº£ Ä‘á»u quan trá»ng nhÆ° nhau.</li><li>C. VÃ¬ nÃ³ nhanh hÆ¡n viá»‡c láº¥y trung bÃ¬nh.</li><li>D. VÃ¬ nÃ³ chá»‰ xem xÃ©t bÃ i bÃ¡o cuá»‘i cÃ¹ng.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> KhÃ´ng pháº£i táº¥t cáº£ cÃ¡c bÃ i bÃ¡o Ä‘Ã£ Ä‘á»c Ä‘á»u pháº£n Ã¡nh sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch nhÆ° nhau. Má»™t bÃ i bÃ¡o ngÆ°á»i dÃ¹ng Ä‘á»c ká»¹ cÃ³ thá»ƒ quan trá»ng hÆ¡n má»™t bÃ i há» chá»‰ click vÃ o xem lÆ°á»›t. CÆ¡ cháº¿ Attention (slide 12) cho phÃ©p mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c táº§m quan trá»ng tÆ°Æ¡ng Ä‘á»‘i nÃ y.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 94: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 14, vector `e_T` Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch ghÃ©p ná»‘i (concat) nhá»¯ng vector nÃ o?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">e_t vÃ  e_U</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 14 cho tháº¥y `e_t` (biá»ƒu diá»…n cá»§a news vÃ  timeliness) vÃ  `e_U` (biá»ƒu diá»…n cá»§a user) Ä‘Æ°á»£c Ä‘Æ°a vÃ o má»™t khá»‘i "Concatenation" Ä‘á»ƒ táº¡o ra `e_T`, Ä‘áº§u vÃ o cho táº§ng phÃ¢n loáº¡i Active-Time.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 95: Giáº£ sá»­ mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n xÃ¡c suáº¥t click lÃ  0.8 cho má»™t bÃ i bÃ¡o. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  gÃ¬?</p><ul class="options"><li>A. NgÆ°á»i dÃ¹ng sáº½ Ä‘á»c 80% bÃ i bÃ¡o.</li><li class="correct-answer">B. MÃ´ hÃ¬nh tin ráº±ng cÃ³ 80% kháº£ nÄƒng ngÆ°á»i dÃ¹ng sáº½ click vÃ o bÃ i bÃ¡o Ä‘Ã³.</li><li>C. CÃ³ 80% ngÆ°á»i dÃ¹ng Ä‘Ã£ click vÃ o bÃ i bÃ¡o Ä‘Ã³.</li><li>D. BÃ i bÃ¡o Ä‘Ã³ Ä‘Æ°á»£c xáº¿p háº¡ng 0.8.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Äáº§u ra cá»§a nhÃ¡nh dá»± Ä‘oÃ¡n click lÃ  `Å·p` (slide 13), lÃ  xÃ¡c suáº¥t click. GiÃ¡ trá»‹ 0.8 lÃ  má»™t Æ°á»›c lÆ°á»£ng xÃ¡c suáº¥t cho má»™t cáº·p (user, item) cá»¥ thá»ƒ.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 96: Náº¿u khÃ´ng cÃ³ cÆ¡ cháº¿ Attention, User Encoder cÃ³ thá»ƒ Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch nÃ o Ä‘Æ¡n giáº£n hÆ¡n?</p><ul class="options"><li>A. Bá» qua lá»‹ch sá»­ ngÆ°á»i dÃ¹ng.</li><li class="correct-answer">B. Láº¥y trung bÃ¬nh cá»™ng (averaging) cÃ¡c vector biá»ƒu diá»…n cá»§a cÃ¡c bÃ i bÃ¡o Ä‘Ã£ xem.</li><li>C. Chá»‰ sá»­ dá»¥ng bÃ i bÃ¡o Ä‘áº§u tiÃªn.</li><li>D. Chá»‰ sá»­ dá»¥ng bÃ i bÃ¡o cuá»‘i cÃ¹ng.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Má»™t cÃ¡ch tiáº¿p cáº­n baseline phá»• biáº¿n Ä‘á»ƒ tá»•ng há»£p má»™t chuá»—i cÃ¡c vector lÃ  láº¥y trung bÃ¬nh cá»§a chÃºng. Tuy nhiÃªn, cÃ¡ch nÃ y coi táº¥t cáº£ cÃ¡c item trong lá»‹ch sá»­ cÃ³ táº§m quan trá»ng nhÆ° nhau, Ä‘iá»u mÃ  Attention cá»‘ gáº¯ng cáº£i thiá»‡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 97: Theo slide 19, HyperNews vÆ°á»£t trá»™i hÆ¡n táº¥t cáº£ cÃ¡c baseline trÃªn Ä‘á»™ Ä‘o nÃ o?</p><ul class="options"><li>A. Chá»‰ AUC</li><li>B. Chá»‰ F1</li><li class="correct-answer">C. Cáº£ AUC vÃ  F1</li><li>D. Thá»i gian huáº¥n luyá»‡n</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> CÃ¡c giÃ¡ trá»‹ Ä‘Æ°á»£c in Ä‘áº­m trong hÃ ng "HyperNews" á»Ÿ báº£ng trÃªn slide 19 Ä‘á»u cao hÆ¡n táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ tÆ°Æ¡ng á»©ng trong cÃ¡c hÃ ng khÃ¡c cho cáº£ hai Ä‘á»™ Ä‘o AUC vÃ  F1 trÃªn cáº£ hai bá»™ dá»¯ liá»‡u.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 98: MÃ´ hÃ¬nh nÃ o trong cÃ¡c baseline (slide 19) cÅ©ng lÃ  má»™t mÃ´ hÃ¬nh deep learning cho gá»£i Ã½?</p><ul class="options"><li>A. Chá»‰ LibFM.</li><li class="correct-answer">B. DeepFM, Wide&Deep, DSSM, LSTUR, DAN.</li><li>C. Chá»‰ HyperNews(NoPred).</li><li>D. KhÃ´ng cÃ³ mÃ´ hÃ¬nh nÃ o.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Ngoáº¡i trá»« LibFM (lÃ  Factorization Machine), táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh cÃ²n láº¡i trong báº£ng so sÃ¡nh Ä‘á»u lÃ  cÃ¡c kiáº¿n trÃºc deep learning ná»•i tiáº¿ng Ä‘Æ°á»£c Ä‘á» xuáº¥t cho cÃ¡c bÃ i toÃ¡n gá»£i Ã½ hoáº·c cÃ¡c bÃ i toÃ¡n liÃªn quan.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 99: Táº¡i sao cáº§n pháº£i cÃ³ cÃ¡c bÃ i bÃ¡o "Candidate" trong máº«u training (slide 15)?</p><ul class="options"><li>A. Äá»ƒ lÃ m cho máº«u lá»›n hÆ¡n.</li><li class="correct-answer">B. Äá»ƒ táº¡o ra cÃ¡c máº«u Ã¢m (negative samples). Náº¿u chá»‰ há»c tá»« cÃ¡c bÃ i bÃ¡o ngÆ°á»i dÃ¹ng Ä‘Ã£ click (máº«u dÆ°Æ¡ng), mÃ´ hÃ¬nh sáº½ khÃ´ng há»c Ä‘Æ°á»£c cÃ¡ch phÃ¢n biá»‡t giá»¯a má»™t bÃ i bÃ¡o tá»‘t vÃ  má»™t bÃ i bÃ¡o khÃ´ng tá»‘t.</li><li>C. Äá»ƒ kiá»ƒm tra mÃ´ hÃ¬nh.</li><li>D. Äá»ƒ dá»± Ä‘oÃ¡n thá»i gian Ä‘á»c.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong implicit feedback, viá»‡c táº¡o ra cÃ¡c máº«u Ã¢m lÃ  ráº¥t quan trá»ng. "Candidate" (`xr+1`) á»Ÿ Ä‘Ã¢y thÆ°á»ng lÃ  má»™t bÃ i bÃ¡o Ä‘Æ°á»£c láº¥y máº«u ngáº«u nhiÃªn mÃ  ngÆ°á»i dÃ¹ng chÆ°a click. NÃ³ Ä‘Æ°á»£c gÃ¡n nhÃ£n `yp=0` vÃ  Ä‘Ã³ng vai trÃ² lÃ  má»™t máº«u Ã¢m trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 100: Má»¥c tiÃªu cuá»‘i cÃ¹ng cá»§a mÃ´ hÃ¬nh HyperNews lÃ  gÃ¬?</p><ul class="options"><li>A. Chá»‰ Ä‘á»ƒ dá»± Ä‘oÃ¡n thá»i gian Ä‘á»c chÃ­nh xÃ¡c.</li><li class="correct-answer">B. Cung cáº¥p cÃ¡c gá»£i Ã½ tin tá»©c Ä‘Æ°á»£c cÃ¡ nhÃ¢n hÃ³a vÃ  cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao báº±ng cÃ¡ch Ä‘á»“ng thá»i há»c cÃ¡ch gá»£i Ã½ vÃ  dá»± Ä‘oÃ¡n má»©c Ä‘á»™ tÆ°Æ¡ng tÃ¡c (thá»i gian Ä‘á»c) cá»§a ngÆ°á»i dÃ¹ng.</li><li>C. Äá»ƒ chá»©ng minh CNN tá»‘t hÆ¡n RNN.</li><li>D. Äá»ƒ táº¡o ra má»™t bá»™ dá»¯ liá»‡u má»›i.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> NhÆ° tÃªn gá»i vÃ  pháº§n giá»›i thiá»‡u (slide 5) Ä‘Ã£ nÃªu, mÃ´ hÃ¬nh nÃ y nháº±m má»¥c Ä‘Ã­ch cáº£i thiá»‡n hiá»‡u suáº¥t gá»£i Ã½ tin tá»©c (nhiá»‡m vá»¥ chÃ­nh) báº±ng cÃ¡ch sá»­ dá»¥ng thÃ´ng tin tá»« má»™t nhiá»‡m vá»¥ phá»¥ há»¯u Ã­ch lÃ  dá»± Ä‘oÃ¡n thá»i gian Ä‘á»c, táº¥t cáº£ Ä‘Æ°á»£c Ä‘Ã³ng gÃ³i trong má»™t framework deep learning Ä‘a nhiá»‡m.</p></div></div>

    </div>
</body>
</html>