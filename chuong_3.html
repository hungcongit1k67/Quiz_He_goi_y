<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>100 CÃ¢u Há»i Tráº¯c Nghiá»‡m - CF NÃ¢ng Cao & Deep Learning</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            max-width: 900px;
            margin: auto;
            background: #fff;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 0 15px rgba(0,0,0,0.1);
        }
        header {
            text-align: center;
            border-bottom: 2px solid #d9534f;
            margin-bottom: 30px;
            padding-bottom: 20px;
        }
        header h1 {
            color: #d9534f;
            margin: 0;
        }
        header p {
            margin: 5px 0 0;
            font-style: italic;
            color: #555;
        }
        .question-block {
            margin-bottom: 25px;
            padding: 20px;
            border: 1px solid #ddd;
            border-left: 5px solid #d9534f;
            border-radius: 5px;
            background-color: #fdfdfd;
        }
        .question-text {
            font-weight: bold;
            font-size: 1.1em;
            margin-bottom: 15px;
        }
        .options {
            list-style-type: none;
            padding-left: 0;
        }
        .options li {
            margin-bottom: 10px;
            padding: 8px;
            border-radius: 4px;
        }
        .explanation {
            margin-top: 15px;
            padding: 15px;
            background-color: #e9f7ef;
            border: 1px solid #a3d9b8;
            border-radius: 5px;
        }
        .explanation b {
            color: #1d7b46;
        }
        .correct-answer {
            background-color: #dff0d8;
            border-left: 3px solid #3c763d;
        }
        .fill-in-answer {
            font-weight: bold;
            color: #3c763d;
            font-size: 1.2em;
        }
    </style>
</head>
<body>

    <div class="container">
        <header>
            <h1>100 CÃ¢u Há»i Tráº¯c Nghiá»‡m - CF NÃ¢ng Cao & Deep Learning</h1>
            <p>Dá»±a trÃªn ná»™i dung slide "Há»‡ gá»£i Ã½ (IT4613)" - Viá»‡n CNTT&TT - ÄHBK HÃ  Ná»™i</p>
        </header>

        <!-- CATEGORY: CF with Basic ML -->

        <div class="question-block">
            <p class="question-text">CÃ¢u 1: Theo slide 8, khi Ã¡p dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p há»c mÃ¡y cÆ¡ báº£n cho CF, má»—i ngÆ°á»i dÃ¹ng (user) Ä‘Æ°á»£c biá»ƒu diá»…n nhÆ° tháº¿ nÃ o?</p>
            <ul class="options">
                <li>A. Má»™t giÃ¡ trá»‹ vÃ´ hÆ°á»›ng.</li>
                <li class="correct-answer">B. Má»™t vector mÃ  má»—i chiá»u lÃ  cÃ¡c item.</li>
                <li>C. Má»™t cÃ¢y quyáº¿t Ä‘á»‹nh.</li>
                <li>D. Má»™t chuá»—i vÄƒn báº£n mÃ´ táº£ sá»Ÿ thÃ­ch.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 8 nÃªu rÃµ: "Biá»ƒu diá»…n user lÃ  cÃ¡c vector mÃ  má»—i chiá»u lÃ  cÃ¡c items". Má»—i user sáº½ lÃ  má»™t hÃ ng trong ma tráº­n dá»¯ liá»‡u.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 2: Äiá»ƒm khÃ¡c biá»‡t chÃ­nh khi Ã¡p dá»¥ng cÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i (nhÆ° NaÃ¯ve Bayes, Decision Tree) vÃ o bÃ i toÃ¡n CF so vá»›i bÃ i toÃ¡n phÃ¢n loáº¡i truyá»n thá»‘ng lÃ  gÃ¬?</p>
            <ul class="options">
                <li>A. Dá»¯ liá»‡u trong CF luÃ´n lÃ  dáº¡ng liÃªn tá»¥c.</li>
                <li>B. CF khÃ´ng cáº§n dá»¯ liá»‡u huáº¥n luyá»‡n.</li>
                <li class="correct-answer">C. Báº¥t ká»³ thuá»™c tÃ­nh (item) nÃ o cÅ©ng cÃ³ thá»ƒ Ä‘Ã³ng vai trÃ² lÃ  thuá»™c tÃ­nh nhÃ£n (label).</li>
                <li>D. CF chá»‰ sá»­ dá»¥ng Máº¡ng nÆ¡-ron.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 vÃ  13 Ä‘á»u nháº¥n máº¡nh sá»± khÃ¡c biá»‡t nÃ y: "KhÃ¡c biá»‡t vá»›i NaÃ¯ve Bayes/decision tree truyá»n thá»‘ng: Báº¥t ká»³ feature nÃ o cÅ©ng cÃ³ thá»ƒ lÃ  label". Trong phÃ¢n loáº¡i truyá»n thá»‘ng, chá»‰ cÃ³ má»™t cá»™t nhÃ£n cá»‘ Ä‘á»‹nh.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 3 (Äiá»n Ä‘Ã¡p Ã¡n): Náº¿u cÃ³ N items trong há»‡ thá»‘ng, cáº§n pháº£i xÃ¢y dá»±ng bao nhiÃªu bá»™ phÃ¢n loáº¡i (vÃ­ dá»¥: cÃ¢y quyáº¿t Ä‘á»‹nh) Ä‘á»ƒ cÃ³ thá»ƒ dá»± Ä‘oÃ¡n rating cho báº¥t ká»³ item nÃ o?</p>
            <div class="explanation">
                <p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">N</span></p>
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 8 vÃ  13 nÃªu rÃµ: "Sá»‘ lÆ°á»£ng bá»™ phÃ¢n loáº¡i báº±ng sá»‘ lÆ°á»£ng items" vÃ  "Pháº£i xÃ¢y dá»±ng sá»‘ lÆ°á»£ng cÃ¢y quyáº¿t Ä‘á»‹nh báº±ng sá»‘ lÆ°á»£ng items". Má»—i item cáº§n má»™t mÃ´ hÃ¬nh riÃªng Ä‘á»ƒ dá»± Ä‘oÃ¡n rating cho nÃ³.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 4: Trong CF dá»±a trÃªn NaÃ¯ve Bayes, `P(ruj = vs)` (xÃ¡c suáº¥t rating cá»§a user u cho item j báº±ng giÃ¡ trá»‹ vs) Ä‘Æ°á»£c xem lÃ  gÃ¬?</p>
            <ul class="options">
                <li>A. XÃ¡c suáº¥t háº­u nghiá»‡m (Posterior)</li>
                <li class="correct-answer">B. XÃ¡c suáº¥t tiÃªn nghiá»‡m (Prior)</li>
                <li>C. XÃ¡c suáº¥t likelihood</li>
                <li>D. Báº±ng chá»©ng (Evidence)</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 11 Ä‘á»‹nh nghÄ©a `P(ruj = vs)` lÃ  "xÃ¡c suáº¥t tiÃªn nghiá»‡m". ÄÃ¢y lÃ  xÃ¡c suáº¥t má»™t rating báº¥t ká»³ cho item j cÃ³ giÃ¡ trá»‹ `vs` trÆ°á»›c khi quan sÃ¡t cÃ¡c rating khÃ¡c cá»§a user u.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 5: Giáº£ thiáº¿t "Ä‘á»™c láº­p cÃ³ Ä‘iá»u kiá»‡n" trong CF dá»±a trÃªn NaÃ¯ve Bayes (slide 11) phÃ¡t biá»ƒu ráº±ng Ä‘iá»u gÃ¬ lÃ  Ä‘Ãºng?</p>
            <ul class="options">
                <li>A. CÃ¡c rating cá»§a má»™t user lÃ  Ä‘á»™c láº­p vá»›i nhau.</li>
                <li class="correct-answer">B. Cho trÆ°á»›c rating cá»§a item `j` mÃ  ta muá»‘n dá»± Ä‘oÃ¡n, cÃ¡c rating cá»§a cÃ¡c item khÃ¡c trong `I_u` lÃ  Ä‘á»™c láº­p vá»›i nhau.</li>
                <li>C. Táº¥t cáº£ cÃ¡c user lÃ  Ä‘á»™c láº­p vá»›i nhau.</li>
                <li>D. Táº¥t cáº£ cÃ¡c item lÃ  Ä‘á»™c láº­p vá»›i nhau.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 11 trÃ¬nh bÃ y cÃ´ng thá»©c cá»§a giáº£ thiáº¿t nÃ y: `P(Observed ratings in Iu | ruj = vs) = Î  P(ruk | ruj = vs)`. Äiá»u nÃ y cÃ³ nghÄ©a lÃ , khi Ä‘Ã£ biáº¿t `ruj = vs`, xÃ¡c suáº¥t cá»§a cÃ¡c rating `ruk` khÃ¡c khÃ´ng cÃ²n phá»¥ thuá»™c láº«n nhau.</p>
            </div>
        </div>

        <!-- CATEGORY: DEEP LEARNING FOR CF -->

        <div class="question-block">
            <p class="question-text">CÃ¢u 6: Theo slide 14, cÃ¡c phÆ°Æ¡ng phÃ¡p Lá»c cá»™ng tÃ¡c nÃ¢ng cao sá»­ dá»¥ng Deep Learning Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn ká»¹ thuáº­t ná»n táº£ng nÃ o?</p>
            <ul class="options">
                <li>A. Lá»c cá»™ng tÃ¡c dá»±a trÃªn lÃ¡ng giá»ng</li>
                <li class="correct-answer">B. PhÃ¢n tÃ­ch ma tráº­n (Matrix Factorization)</li>
                <li>C. CÃ¢y quyáº¿t Ä‘á»‹nh</li>
                <li>D. MÃ¡y vector há»— trá»£ (SVM)</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 14 giá»›i thiá»‡u cÃ¡c phÆ°Æ¡ng phÃ¡p deep learning "trong phÃ¢n tÃ­ch ma tráº­n (matrix factorization)", cho tháº¥y MF lÃ  Ã½ tÆ°á»Ÿng ná»n táº£ng Ä‘Æ°á»£c má»Ÿ rá»™ng vÃ  cáº£i tiáº¿n.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 7: MÃ´ hÃ¬nh General Matrix Factorization (GMF) sá»­ dá»¥ng phÃ©p toÃ¡n nÃ o Ä‘á»ƒ káº¿t há»£p vector áº©n cá»§a user vÃ  item?</p>
            <ul class="options">
                <li>A. TÃ­ch vÃ´ hÆ°á»›ng (Dot product)</li>
                <li>B. GhÃ©p ná»‘i (Concatenation)</li>
                <li class="correct-answer">C. TÃ­ch theo tá»«ng pháº§n tá»­ (Element-wise Product)</li>
                <li>D. PhÃ©p cá»™ng vector</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ vÃ  cÃ´ng thá»©c trÃªn slide 21 cho tháº¥y GMF sá»­ dá»¥ng "Element-wise Product" (kÃ­ hiá»‡u âŠ™) Ä‘á»ƒ táº¡o ra vector tÆ°Æ¡ng tÃ¡c tá»« vector user `pu` vÃ  vector item `qi`.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 8: Theo slide 22, náº¿u hÃ m `a_out` lÃ  hÃ m Ä‘á»“ng nháº¥t vÃ  cÃ¡c trá»ng sá»‘ `h` Ä‘á»u báº±ng 1 trong mÃ´ hÃ¬nh GMF, nÃ³ sáº½ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i mÃ´ hÃ¬nh nÃ o?</p>
            <ul class="options">
                <li class="correct-answer">A. Matrix Factorization (MF) truyá»n thá»‘ng.</li>
                <li>B. Multi-layer Perceptron (MLP).</li>
                <li>C. Item-based CF.</li>
                <li>D. NaÃ¯ve Bayes.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 22 giáº£i thÃ­ch: "a_out lÃ  hÃ m Ä‘á»“ng nháº¥t, cÃ¡c trá»ng sá»‘ trong h Ä‘á»u báº±ng 1 => MF". Khi Ä‘Ã³, `y_ui` sáº½ lÃ  tá»•ng cá»§a cÃ¡c pháº§n tá»­ trong vector `pu âŠ™ qi`, tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i tÃ­ch vÃ´ hÆ°á»›ng `pu . qi` cá»§a MF truyá»n thá»‘ng.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 9: MÃ´ hÃ¬nh Multi-layer Perceptron (MLP) cho CF (slide 23) sá»­ dá»¥ng phÃ©p toÃ¡n nÃ o Ä‘á»ƒ káº¿t há»£p vector áº©n cá»§a user vÃ  item trÆ°á»›c khi Ä‘Æ°a vÃ o cÃ¡c táº§ng áº©n?</p>
            <ul class="options">
                <li>A. TÃ­ch vÃ´ hÆ°á»›ng (Dot product)</li>
                <li class="correct-answer">B. GhÃ©p ná»‘i (Concatenation)</li>
                <li>C. TÃ­ch theo tá»«ng pháº§n tá»­ (Element-wise Product)</li>
                <li>D. PhÃ©p trá»« vector</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 23 cho tháº¥y vector user vÃ  item Ä‘Æ°á»£c "Concatenation" (ghÃ©p ná»‘i) láº¡i vá»›i nhau Ä‘á»ƒ táº¡o thÃ nh Ä‘áº§u vÃ o cho MLP Layer 1. CÃ´ng thá»©c `z1 = [pu; qi]` cÅ©ng thá»ƒ hiá»‡n Ä‘iá»u nÃ y.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 10: MÃ´ hÃ¬nh Neural Matrix Factorization (NeuMF) káº¿t há»£p nhá»¯ng mÃ´ hÃ¬nh nÃ o?</p>
            <ul class="options">
                <li>A. MF vÃ  NaÃ¯ve Bayes</li>
                <li class="correct-answer">B. GMF vÃ  MLP</li>
                <li>C. User-based CF vÃ  Item-based CF</li>
                <li>D. MLP vÃ  CÃ¢y quyáº¿t Ä‘á»‹nh</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 24 nÃªu rÃµ "Káº¿t há»£p 2 mÃ´ hÃ¬nh GMF, MLP". NeuMF táº­n dá»¥ng kháº£ nÄƒng mÃ´ hÃ¬nh hÃ³a tÆ°Æ¡ng tÃ¡c tuyáº¿n tÃ­nh cá»§a GMF vÃ  tÆ°Æ¡ng tÃ¡c phi tuyáº¿n cá»§a MLP.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 11: Má»™t Ä‘áº·c Ä‘iá»ƒm kiáº¿n trÃºc quan trá»ng cá»§a NeuMF lÃ  gÃ¬?</p>
            <ul class="options">
                <li>A. Chá»‰ sá»­ dá»¥ng má»™t táº§ng áº©n.</li>
                <li>B. Chá»‰ Ã¡p dá»¥ng cho dá»¯ liá»‡u explicit.</li>
                <li class="correct-answer">C. Sá»­ dá»¥ng cÃ¡c táº§ng embedding riÃªng biá»‡t cho nhÃ¡nh GMF vÃ  nhÃ¡nh MLP.</li>
                <li>D. Sá»­ dá»¥ng chung má»™t táº§ng embedding cho cáº£ hai nhÃ¡nh.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 24 vÃ  25 Ä‘á»u nháº¥n máº¡nh: "Sá»­ dá»¥ng táº§ng embedding riÃªng cho má»—i mÃ´ hÃ¬nh". SÆ¡ Ä‘á»“ cÅ©ng cho tháº¥y cÃ³ "GMF User vector", "MLP User vector", "GMF Item vector", "MLP Item vector" riÃªng biá»‡t, cho phÃ©p má»—i mÃ´ hÃ¬nh há»c cÃ¡c biá»ƒu diá»…n áº©n phÃ¹ há»£p nháº¥t vá»›i nÃ³.</p>
            </div>
        </div>
        
        <div class="question-block">
            <p class="question-text">CÃ¢u 12: MÃ´ hÃ¬nh Deep Matrix Factorization (DMF) trÃªn slide 26 khÃ¡c vá»›i NeuMF á»Ÿ Ä‘iá»ƒm cÆ¡ báº£n nÃ o?</p>
            <ul class="options">
                <li>A. DMF khÃ´ng sá»­ dá»¥ng máº¡ng nÆ¡-ron.</li>
                <li>B. DMF chá»‰ dÃ¹ng cho dá»¯ liá»‡u explicit.</li>
                <li class="correct-answer">C. DMF sá»­ dá»¥ng toÃ n bá»™ vector tÆ°Æ¡ng tÃ¡c cá»§a user/item lÃ m Ä‘áº§u vÃ o vÃ  cÃ³ hai thÃ¡p MLP riÃªng biá»‡t, trong khi NeuMF dÃ¹ng ID one-hot vÃ  káº¿t há»£p GMF-MLP.</li>
                <li>D. DMF khÃ´ng há»c Ä‘Æ°á»£c biá»ƒu diá»…n áº©n.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 26 cho tháº¥y Ä‘áº§u vÃ o cá»§a DMF lÃ  cÃ¡c cá»™t/hÃ ng tá»« "Interaction Matrix" (toÃ n bá»™ vector tÆ°Æ¡ng tÃ¡c). Sau Ä‘Ã³, nÃ³ sá»­ dá»¥ng hai máº¡ng MLP song song (má»™t cho user, má»™t cho item) Ä‘á»ƒ há»c biá»ƒu diá»…n áº©n. Cuá»‘i cÃ¹ng, nÃ³ Ä‘o Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng (relevance) báº±ng cosine similarity. Kiáº¿n trÃºc nÃ y hoÃ n toÃ n khÃ¡c vá»›i NeuMF.</p>
            </div>
        </div>
        
        <!-- CATEGORY: IMPLICIT & EXPLICIT DATA -->

        <div class="question-block">
            <p class="question-text">CÃ¢u 13 (Chá»n nhiá»u Ä‘Ã¡p Ã¡n): Theo slide 27, Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u explicit feedback lÃ  gÃ¬?</p>
            <ul class="options">
                <li class="correct-answer">A. Dá»¯ liá»‡u quÃ½ giÃ¡, thá»ƒ hiá»‡n sá»Ÿ thÃ­ch cá»§a user.</li>
                <li>B. Dá»¯ liá»‡u nhiá»u, dá»… thu tháº­p.</li>
                <li class="correct-answer">C. ThÆ°a, Ã­t, khÃ³ thu tháº­p.</li>
                <li class="correct-answer">D. KhÃ³ khÄƒn khi há»c cÃ¡c mÃ´ hÃ¬nh.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 27 liá»‡t kÃª táº¥t cáº£ cÃ¡c Ä‘áº·c Ä‘iá»ƒm nÃ y cho "Dá»¯ liá»‡u explicit feedback".</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 14 (Chá»n nhiá»u Ä‘Ã¡p Ã¡n): Theo slide 27, Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u implicit feedback lÃ  gÃ¬?</p>
            <ul class="options">
                <li>A. LuÃ´n pháº£n Ã¡nh chÃ­nh xÃ¡c sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng.</li>
                <li class="correct-answer">B. Dá»¯ liá»‡u nhiá»u, dá»… thu tháº­p.</li>
                <li class="correct-answer">C. Pháº£n Ã¡nh tiá»m áº©n má»©c Ä‘á»™ Æ°a thÃ­ch cá»§a ngÆ°á»i dÃ¹ng.</li>
                <li class="correct-answer">D. CÃ³ thá»ƒ cÃ³ nhiá»…u.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 27 liá»‡t kÃª cÃ¡c Ä‘áº·c Ä‘iá»ƒm nÃ y cho "Dá»¯ liá»‡u implicit feedback". "CÃ³ nhiá»…u" vÃ¬ má»™t cÃº click cÃ³ thá»ƒ lÃ  do nháº§m láº«n, khÃ´ng nháº¥t thiáº¿t lÃ  thÃ­ch.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 15: MÃ´ hÃ¬nh Weighted Matrix Factorization (WMF) Ä‘Æ°á»£c thiáº¿t káº¿ chá»§ yáº¿u Ä‘á»ƒ xá»­ lÃ½ loáº¡i dá»¯ liá»‡u nÃ o?</p>
            <ul class="options">
                <li>A. Dá»¯ liá»‡u explicit</li>
                <li class="correct-answer">B. Dá»¯ liá»‡u implicit</li>
                <li>C. Dá»¯ liá»‡u vÄƒn báº£n</li>
                <li>D. Dá»¯ liá»‡u hÃ¬nh áº£nh</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 28-29 giá»›i thiá»‡u WMF trong bá»‘i cáº£nh xá»­ lÃ½ "Dá»¯ liá»‡u tiá»m áº©n" (implicit), nhÆ° sá»‘ láº§n xem video, lá»‹ch sá»­ mua sáº¯m.</p>
            </div>
        </div>
        
        <div class="question-block">
            <p class="question-text">CÃ¢u 16: Trong WMF (slide 29), `c_ui = 1 + Î± * r_ui` Ä‘Ã³ng vai trÃ² lÃ  gÃ¬?</p>
            <ul class="options">
                <li>A. GiÃ¡ trá»‹ rating dá»± Ä‘oÃ¡n.</li>
                <li>B. Tham sá»‘ hiá»‡u chá»‰nh (regularization).</li>
                <li class="correct-answer">C. Trá»ng sá»‘ thá»ƒ hiá»‡n Ä‘á»™ tin cáº­y (confidence) cá»§a tÆ°Æ¡ng tÃ¡c.</li>
                <li>D. Tá»‘c Ä‘á»™ há»c (learning rate).</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 29 nÃªu rÃµ `c_ui` lÃ  "trá»ng sá»‘ thá»ƒ hiá»‡n Ä‘á»™ tin cáº­y". Ã tÆ°á»Ÿng lÃ  má»™t tÆ°Æ¡ng tÃ¡c láº·p láº¡i nhiá»u láº§n (`r_ui` lá»›n) thÃ¬ Ä‘Ã¡ng tin cáº­y hÆ¡n lÃ  má»™t tÆ°Æ¡ng tÃ¡c chá»‰ xáº£y ra má»™t láº§n.</p>
            </div>
        </div>
        
        <div class="question-block">
            <p class="question-text">CÃ¢u 17: Má»¥c tiÃªu chÃ­nh cá»§a Bayesian Personalized Ranking (BPR) lÃ  gÃ¬?</p>
            <ul class="options">
                <li>A. Dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c giÃ¡ trá»‹ rating.</li>
                <li class="correct-answer">B. ÄÆ°a ra má»™t danh sÃ¡ch cÃ³ xáº¿p háº¡ng (ranking) tá»‘i Æ°u cho má»—i ngÆ°á»i dÃ¹ng.</li>
                <li>C. PhÃ¢n cá»¥m ngÆ°á»i dÃ¹ng.</li>
                <li>D. TÃ¬m cÃ¡c thuá»™c tÃ­nh áº©n cá»§a sáº£n pháº©m.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 30 giá»›i thiá»‡u BPR vá»›i má»¥c tiÃªu: "ÄÆ°a ra má»™t danh sÃ¡ch cÃ³ xáº¿p háº¡ng cÃ¡c sáº£n pháº©m cho má»—i ngÆ°á»i dÃ¹ng". BPR tá»‘i Æ°u hÃ³a trá»±c tiáº¿p cho bÃ i toÃ¡n xáº¿p háº¡ng.</p>
            </div>
        </div>
        
        <div class="question-block">
            <p class="question-text">CÃ¢u 18: BPR tiáº¿p cáº­n bÃ i toÃ¡n gá»£i Ã½ báº±ng cÃ¡ch nÃ o?</p>
            <ul class="options">
                <li>A. Theo tá»«ng Ä‘iá»ƒm (pointwise), dá»± Ä‘oÃ¡n rating cho tá»«ng cáº·p (user, item).</li>
                <li class="correct-answer">B. Theo cáº·p (pairwise), há»c má»‘i quan há»‡ thá»© tá»± giá»¯a cÃ¡c item cho má»™t user.</li>
                <li>C. Theo danh sÃ¡ch (listwise), tá»‘i Æ°u hÃ³a toÃ n bá»™ danh sÃ¡ch gá»£i Ã½ cÃ¹ng lÃºc.</li>
                <li>D. Báº±ng cÃ¡ch xÃ¢y dá»±ng cÃ¢y quyáº¿t Ä‘á»‹nh.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 30 vÃ  32 chá»‰ ra ráº±ng BPR "Tiáº¿p cáº­n theo cáº·p item", há»c má»‘i quan há»‡ "i >u j" (user u thÃ­ch item i hÆ¡n item j). ÄÃ¢y lÃ  cÃ¡ch tiáº¿p cáº­n pairwise.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 19: Trong BPR, má»™t cáº·p (user-item) khÃ´ng Ä‘Æ°á»£c quan sÃ¡t cÃ³ thá»ƒ mang Ã½ nghÄ©a gÃ¬?</p>
            <ul class="options">
                <li>A. Chá»‰ cÃ³ nghÄ©a lÃ  ngÆ°á»i dÃ¹ng khÃ´ng thÃ­ch sáº£n pháº©m Ä‘Ã³.</li>
                <li>B. Chá»‰ cÃ³ nghÄ©a lÃ  ngÆ°á»i dÃ¹ng chÆ°a biáº¿t Ä‘áº¿n sáº£n pháº©m Ä‘Ã³.</li>
                <li class="correct-answer">C. CÃ³ thá»ƒ lÃ  ngÆ°á»i dÃ¹ng thá»±c sá»± khÃ´ng thÃ­ch (negative) hoáº·c chá»‰ lÃ  chÆ°a biáº¿t (missing value).</li>
                <li>D. LuÃ´n Ä‘Æ°á»£c coi lÃ  má»™t tÆ°Æ¡ng tÃ¡c tÃ­ch cá»±c (positive).</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 30 giáº£i thÃ­ch vá» dá»¯ liá»‡u tiá»m áº©n trong BPR: "CÃ¡c cáº·p user-item khÃ´ng quan sÃ¡t Ä‘Æ°á»£c: cÃ³ thá»ƒ thá»±c sá»± khÃ´ng thÃ­ch (negative), chÆ°a biáº¿t (missing value)". ÄÃ¢y lÃ  sá»± mÆ¡ há»“ mÃ  BPR cá»‘ gáº¯ng giáº£i quyáº¿t.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 20: BPR sá»­ dá»¥ng hÃ m sigmoid Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a xÃ¡c suáº¥t `p(i >u j)`. Äáº§u vÃ o cá»§a hÃ m sigmoid nÃ y lÃ  gÃ¬?</p>
            <ul class="options">
                <li>A. Äiá»ƒm dá»± Ä‘oÃ¡n `r_ui`.</li>
                <li>B. Äiá»ƒm dá»± Ä‘oÃ¡n `r_uj`.</li>
                <li>C. Tá»•ng cá»§a cÃ¡c Ä‘iá»ƒm dá»± Ä‘oÃ¡n `r_ui + r_uj`.</li>
                <li class="correct-answer">D. Hiá»‡u cá»§a cÃ¡c Ä‘iá»ƒm dá»± Ä‘oÃ¡n `r_ui - r_uj`.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 33 trÃ¬nh bÃ y cÃ´ng thá»©c `p(i >u j|Î˜) = Ïƒ(r_uij(Î˜))` vÃ  `r_uij = r_ui - r_uj`. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  BPR mÃ´ hÃ¬nh hÃ³a xÃ¡c suáº¥t user u thÃ­ch i hÆ¡n j dá»±a trÃªn sá»± chÃªnh lá»‡ch Ä‘iá»ƒm sá»‘ dá»± Ä‘oÃ¡n giá»¯a i vÃ  j.</p>
            </div>
        </div>
        
        <!-- CATEGORY: ADVANCED & HYBRID MODELS -->

        <div class="question-block">
            <p class="question-text">CÃ¢u 21: MÃ´ hÃ¬nh Co-rating (slide 36) Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n nÃ o?</p>
            <ul class="options">
                <li>A. Chá»‰ sá»­ dá»¥ng dá»¯ liá»‡u implicit.</li>
                <li>B. Chá»‰ sá»­ dá»¥ng dá»¯ liá»‡u explicit.</li>
                <li class="correct-answer">C. Sá»­ dá»¥ng Ä‘á»“ng thá»i cáº£ dá»¯ liá»‡u implicit vÃ  explicit.</li>
                <li>D. Xáº¿p háº¡ng cÃ¡c sáº£n pháº©m.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> TiÃªu Ä‘á» slide 36 lÃ  "Lá»c cá»™ng tÃ¡c sá»­ dá»¥ng Ä‘á»“ng thá»i Implicit vÃ  explicit feedback", vÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c giá»›i thiá»‡u lÃ  "Co-rating: Sá»­ dá»¥ng cáº£ dá»¯ liá»‡u implicit X vÃ  explicit Y".</p>
            </div>
        </div>
        
        <div class="question-block">
            <p class="question-text">CÃ¢u 22: MÃ´ hÃ¬nh Neural Multi-Task Recommendation (slide 37-38) phÃ¹ há»£p nháº¥t vá»›i loáº¡i ká»‹ch báº£n nÃ o?</p>
            <ul class="options">
                <li>A. NgÆ°á»i dÃ¹ng chá»‰ cÃ³ má»™t loáº¡i hÃ nh vi duy nháº¥t (vÃ­ dá»¥: chá»‰ mua hÃ ng).</li>
                <li class="correct-answer">B. NgÆ°á»i dÃ¹ng cÃ³ nhiá»u loáº¡i hÃ nh vi cÃ³ tÃ­nh thá»© tá»± (vÃ­ dá»¥: xem -> thÃªm vÃ o giá» hÃ ng -> mua).</li>
                <li>C. Há»‡ thá»‘ng khÃ´ng cÃ³ dá»¯ liá»‡u hÃ nh vi.</li>
                <li>D. Há»‡ thá»‘ng chá»‰ cÃ³ dá»¯ liá»‡u rating 5 sao.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 37-38 mÃ´ táº£ má»™t mÃ´ hÃ¬nh cho "R loáº¡i hÃ nh vi khÃ¡c nhau" vÃ  "cÃ³ tÃ­nh thá»© tá»± tá»« tháº¥p Ä‘áº¿n cao", trong Ä‘Ã³ "hÃ nh vi loáº¡i sau phá»¥ thuá»™c vÃ o hÃ nh vi loáº¡i trÆ°á»›c". ÄÃ¢y chÃ­nh lÃ  ká»‹ch báº£n Ä‘a hÃ nh vi cÃ³ tráº­t tá»±.</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 23: Trong mÃ´ hÃ¬nh Implicit to Explicit (slide 40), thÃ´ng tin nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m Ä‘áº§u vÃ o Ä‘á»ƒ dá»± Ä‘oÃ¡n hÃ nh vi rÃµ rÃ ng (explicit)?</p>
            <ul class="options">
                <li class="correct-answer">A. Äáº§u ra cá»§a mÃ´ hÃ¬nh con dá»± Ä‘oÃ¡n tÆ°Æ¡ng tÃ¡c tiá»m áº©n (implicit).</li>
                <li>B. Dá»¯ liá»‡u nhÃ¢n kháº©u há»c cá»§a ngÆ°á»i dÃ¹ng.</li>
                <li>C. Äá»™ phá»• biáº¿n cá»§a sáº£n pháº©m.</li>
                <li>D. Dá»¯ liá»‡u tá»« cÃ¡c ngÆ°á»i dÃ¹ng khÃ¡c.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 40 mÃ´ táº£ kiáº¿n trÃºc nÃ y: "Táº§ng cuá»‘i cÃ¹ng trong mÃ´ hÃ¬nh tÆ°Æ¡ng tÃ¡c tiá»m áº©n lÃ m Ä‘áº§u vÃ o cho táº§ng khÃ¡c vá»›i giÃ¡ trá»‹ Ä‘áº§u ra dá»± Ä‘oÃ¡n Ä‘iá»ƒm cho tÆ°Æ¡ng tÃ¡c hÃ nh vi rÃµ rÃ ng." SÆ¡ Ä‘á»“ cÅ©ng cho tháº¥y Ä‘áº§u ra tá»« "Implicit Layer" Ä‘Æ°á»£c Ä‘Æ°a vÃ o "ITE Layer 1".</p>
            </div>
        </div>

        <div class="question-block">
            <p class="question-text">CÃ¢u 24 (Äiá»n Ä‘Ã¡p Ã¡n): Trong hÃ m má»¥c tiÃªu cá»§a mÃ´ hÃ¬nh Implicit to Explicit (slide 44), `L_I` vÃ  `L_E` lÃ  hÃ m lá»—i cho hai loáº¡i hÃ nh vi nÃ o?</p>
            <div class="explanation">
                <p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">TÆ°á»ng áº©n (implicit) vÃ  rÃµ rÃ ng (explicit)</span></p>
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 44 ghi rÃµ: "`L_I`, `L_E` hÃ m lá»—i cá»§a hÃ nh vi tÆ°á»ng áº©n vÃ  rÃµ rÃ ng." `L_I` tÃ­nh lá»—i cho dá»± Ä‘oÃ¡n implicit (`x_hat`) vÃ  `L_E` tÃ­nh lá»—i cho dá»± Ä‘oÃ¡n explicit (`y_hat`).</p>
            </div>
        </div>
        
        <div class="question-block">
            <p class="question-text">CÃ¢u 25: Trong kiáº¿n trÃºc NeuMF (slide 24), táº¡i sao GMF Ä‘Æ°á»£c coi lÃ  mÃ´ hÃ¬nh tuyáº¿n tÃ­nh?</p>
            <ul class="options">
                <li class="correct-answer">B. VÃ¬ náº¿u khÃ´ng cÃ³ cÃ¡c hÃ m kÃ­ch hoáº¡t phi tuyáº¿n á»Ÿ táº§ng cuá»‘i, phÃ©p nhÃ¢n element-wise vÃ  sau Ä‘Ã³ lÃ  tÃ­ch vÃ´ hÆ°á»›ng vá»›i vector trá»ng sá»‘ `h` cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t dáº¡ng tá»•ng quÃ¡t cá»§a tÃ­ch vÃ´ hÆ°á»›ng, má»™t phÃ©p toÃ¡n tuyáº¿n tÃ­nh.</li>
                <li>A. VÃ¬ nÃ³ chá»‰ cÃ³ má»™t táº§ng.</li>
                <li>C. VÃ¬ nÃ³ sá»­ dá»¥ng hÃ m kÃ­ch hoáº¡t ReLU.</li>
                <li>D. VÃ¬ nÃ³ khÃ´ng cÃ³ táº§ng embedding.</li>
            </ul>
            <div class="explanation">
                <p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 24 ghi "GMF: mÃ´ hÃ¬nh tuyáº¿n tÃ­nh". Máº·c dÃ¹ cÃ³ táº§ng embedding, báº£n cháº¥t cá»§a tÆ°Æ¡ng tÃ¡c trong GMF (element-wise product) Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ náº¯m báº¯t cÃ¡c tÆ°Æ¡ng tÃ¡c tuyáº¿n tÃ­nh, tÆ°Æ¡ng tá»± nhÆ° tÃ­ch vÃ´ hÆ°á»›ng trong MF truyá»n thá»‘ng. NgÆ°á»£c láº¡i, MLP vá»›i cÃ¡c hÃ m kÃ­ch hoáº¡t phi tuyáº¿n rÃµ rÃ ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ náº¯m báº¯t cÃ¡c tÆ°Æ¡ng tÃ¡c phá»©c táº¡p, phi tuyáº¿n.</p>
            </div>
        </div>
        
        <div class="question-block"><p class="question-text">CÃ¢u 26: HÃ m kÃ­ch hoáº¡t nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c táº§ng áº©n cá»§a mÃ´ hÃ¬nh MLP cho CF (slide 23)?</p><ul class="options"><li>A. Sigmoid</li><li>B. Tanh</li><li class="correct-answer">C. ReLU</li><li>D. Softmax</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 23 ghi rÃµ: "Sá»­ dá»¥ng ReLU lÃ m hÃ m kÃ­ch hoáº¡t." SÆ¡ Ä‘á»“ cÅ©ng cÃ³ cÃ¡c nhÃ£n "ReLU" giá»¯a cÃ¡c táº§ng MLP.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 27: (Äiá»n Ä‘Ã¡p Ã¡n) Trong WMF, náº¿u `Î± = 40` vÃ  `r_ui = 2` (user u xem item i 2 láº§n), thÃ¬ Ä‘á»™ tin cáº­y `c_ui` lÃ  bao nhiÃªu?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">81</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Theo cÃ´ng thá»©c `c_ui = 1 + Î± * r_ui` (slide 29), ta cÃ³ `c_ui = 1 + 40 * 2 = 1 + 80 = 81`.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 28: Trong hÃ m má»¥c tiÃªu cá»§a Co-rating (slide 36), tham sá»‘ `Î·` (eta) dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬?</p><ul class="options"><li>A. Tá»‘c Ä‘á»™ há»c.</li><li class="correct-answer">B. Thá»ƒ hiá»‡n má»©c Ä‘á»™ quan trá»ng giá»¯a tÆ°Æ¡ng tÃ¡c áº©n vÃ  tÆ°á»ng minh.</li><li>C. Tham sá»‘ hiá»‡u chá»‰nh.</li><li>D. Sá»‘ chiá»u cá»§a vector áº©n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 36 ghi "Sá»­ dá»¥ng trá»ng sá»‘ eta Ä‘á»ƒ thá»ƒ hiá»‡n má»©c Ä‘á»™ quan trá»ng giá»¯a cÃ¡c tÆ°Æ¡ng tÃ¡c áº©n vÃ  tÆ°á»ng minh." NÃ³ cÃ¢n báº±ng giá»¯a hai hÃ m lá»—i `L_E` (explicit) vÃ  `L_I` (implicit).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 29: Trong mÃ´ hÃ¬nh CF dá»±a trÃªn NaÃ¯ve Bayes, Ä‘á»ƒ dá»± Ä‘oÃ¡n rating cho item `j` cá»§a user `u`, ta cáº§n cÃ¡c thá»‘ng kÃª trÃªn toÃ n bá»™ dá»¯ liá»‡u training liÃªn quan Ä‘áº¿n item nÃ o?</p><ul class="options"><li>A. LiÃªn quan Ä‘áº¿n táº¥t cáº£ cÃ¡c item.</li><li>B. LiÃªn quan Ä‘áº¿n cÃ¡c item mÃ  user `u` Ä‘Ã£ rate.</li><li class="correct-answer">C. LiÃªn quan Ä‘áº¿n chÃ­nh item `j`.</li><li>D. KhÃ´ng cáº§n thá»‘ng kÃª nÃ o.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 12 ghi chÃº: "ChÃº Ã½ thá»‘ng kÃª P(vs) vÃ  P(vk|ruj = vs) theo thuá»™c tÃ­nh j trÃªn toÃ n bá»™ dá»¯ liá»‡u training". Äiá»u nÃ y cÃ³ nghÄ©a lÃ  cÃ¡c xÃ¡c suáº¥t cáº§n thiáº¿t Ä‘Æ°á»£c tÃ­nh toÃ¡n dá»±a trÃªn lá»‹ch sá»­ cá»§a chÃ­nh item `j` Ä‘Ã³.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 30: Táº¡i sao viá»‡c há»c biá»ƒu diá»…n áº©n (learning latent representations) láº¡i quan trá»ng trong cÃ¡c mÃ´ hÃ¬nh CF hiá»‡n Ä‘áº¡i?</p><ul class="options"><li>A. VÃ¬ nÃ³ lÃ m cho mÃ´ hÃ¬nh dá»… giáº£i thÃ­ch hÆ¡n.</li><li class="correct-answer">B. VÃ¬ nÃ³ giÃºp kháº¯c phá»¥c váº¥n Ä‘á» dá»¯ liá»‡u thÆ°a vÃ  náº¯m báº¯t cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p, khÃ´ng tÆ°á»ng minh cá»§a user vÃ  item.</li><li>C. VÃ¬ nÃ³ lÃ  yÃªu cáº§u báº¯t buá»™c cá»§a táº¥t cáº£ cÃ¡c thuáº­t toÃ¡n há»c mÃ¡y.</li><li>D. VÃ¬ nÃ³ giáº£m sá»‘ lÆ°á»£ng ngÆ°á»i dÃ¹ng cáº§n thiáº¿t.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> CÃ¡c slide tá»« 14 Ä‘áº¿n 26 Ä‘á»u táº­p trung vÃ o viá»‡c "há»c biá»ƒu diá»…n áº©n". Ã tÆ°á»Ÿng lÃ  thay vÃ¬ lÃ m viá»‡c vá»›i ma tráº­n thÆ°a thá»›t, ta nÃ©n thÃ´ng tin vÃ o cÃ¡c vector Ä‘áº·c trÆ°ng áº©n (latent vectors) dÃ y Ä‘áº·c, giÃºp mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a vÃ  khÃ¡m phÃ¡ cÃ¡c má»‘i quan há»‡ sÃ¢u sáº¯c hÆ¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 31: Äáº§u vÃ o cá»§a mÃ´ hÃ¬nh GMF vÃ  MLP trong kiáº¿n trÃºc NeuMF lÃ  gÃ¬?</p><ul class="options"><li>A. ToÃ n bá»™ ma tráº­n rating.</li><li class="correct-answer">B. Vector one-hot mÃ£ hÃ³a Ä‘á»‹nh danh cho user vÃ  item.</li><li>C. Dá»¯ liá»‡u nhÃ¢n kháº©u há»c.</li><li>D. VÄƒn báº£n mÃ´ táº£ sáº£n pháº©m.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 21 vÃ  23 Ä‘á»u nÃ³i ráº±ng "Äáº§u vÃ o lÃ  vector one-hot". Vector nÃ y sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘Æ°a qua táº§ng embedding Ä‘á»ƒ láº¥y ra vector Ä‘áº·c trÆ°ng áº©n tÆ°Æ¡ng á»©ng.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 32: Trong WMF, dá»¯ liá»‡u tÆ°Æ¡ng tÃ¡c tiá»m áº©n `r_ui` Ä‘Æ°á»£c chuyá»ƒn vá» dáº¡ng nhá»‹ phÃ¢n `p_ui`. `p_ui = 1` khi nÃ o?</p><ul class="options"><li>A. Khi `r_ui = 1`</li><li>B. Khi `r_ui = 0`</li><li class="correct-answer">C. Khi `r_ui > 0`</li><li>D. Khi `r_ui < 0`</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 29 Ä‘Æ°a ra cÃ´ng thá»©c chuyá»ƒn Ä‘á»•i: `p_ui = 1` náº¿u `r_ui > 0`, vÃ  `p_ui = 0` náº¿u `r_ui = 0`. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  báº¥t ká»³ tÆ°Æ¡ng tÃ¡c nÃ o (dÃ¹ lÃ  xem 1% hay 100% video) Ä‘á»u Ä‘Æ°á»£c coi lÃ  má»™t tÃ­n hiá»‡u tÃ­ch cá»±c.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 33: Má»¥c tiÃªu cá»§a hÃ m tá»‘i Æ°u BPR (slide 34) lÃ  gÃ¬?</p><ul class="options"><li>A. Tá»‘i thiá»ƒu hÃ³a sai sá»‘ dá»± Ä‘oÃ¡n rating.</li><li class="correct-answer">B. Tá»‘i Ä‘a hÃ³a xÃ¡c suáº¥t háº­u nghiá»‡m cá»§a cÃ¡c má»‘i quan há»‡ thá»© tá»± quan sÃ¡t Ä‘Æ°á»£c.</li><li>C. Tá»‘i thiá»ƒu hÃ³a sá»‘ lÆ°á»£ng lÃ¡ng giá»ng.</li><li>D. Tá»‘i Ä‘a hÃ³a Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cosine.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 32 giá»›i thiá»‡u xÃ¡c suáº¥t háº­u nghiá»‡m `p(Î˜|i >u j)`. Slide 34 trÃ¬nh bÃ y hÃ m má»¥c tiÃªu BPR-Opt, báº¯t Ä‘áº§u báº±ng viá»‡c tá»‘i Ä‘a hÃ³a `Î  p(i >u j|Î˜)p(Î˜)`, chÃ­nh lÃ  tá»‘i Ä‘a hÃ³a xÃ¡c suáº¥t háº­u nghiá»‡m (Maximum a posteriori - MAP).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 34: (Äiá»n Ä‘Ã¡p Ã¡n) Trong mÃ´ hÃ¬nh Multi-layer Perceptron (slide 23), náº¿u vector áº©n cá»§a user `pu` cÃ³ 16 chiá»u vÃ  vector áº©n cá»§a item `qi` cÃ³ 16 chiá»u, thÃ¬ vector Ä‘áº§u vÃ o `z1` cho táº§ng MLP Ä‘áº§u tiÃªn sáº½ cÃ³ bao nhiÃªu chiá»u?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">32</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> `z1` Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch ghÃ©p ná»‘i (concatenate) `pu` vÃ  `qi`. Do Ä‘Ã³, sá»‘ chiá»u cá»§a `z1` sáº½ lÃ  tá»•ng sá»‘ chiá»u cá»§a hai vector nÃ y: 16 + 16 = 32.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 35: Theo slide 25, hÃ m kÃ­ch hoáº¡t `a_out` Ä‘Æ°á»£c sá»­ dá»¥ng á»Ÿ táº§ng cuá»‘i cá»§a NeuMF lÃ  gÃ¬?</p><ul class="options"><li class="correct-answer">A. Sigmoid</li><li>B. ReLU</li><li>C. Tanh</li><li>D. Identity (Äá»“ng nháº¥t)</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 25 ghi rÃµ: "`a_out` : sá»­ dá»¥ng hÃ m sigmoid". HÃ m sigmoid Ä‘Æ°a ra káº¿t quáº£ trong khoáº£ng (0, 1), phÃ¹ há»£p Ä‘á»ƒ diá»…n giáº£i nhÆ° má»™t xÃ¡c suáº¥t tÆ°Æ¡ng tÃ¡c.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 36: KhÃ¡c biá»‡t cÆ¡ báº£n giá»¯a CF dá»±a trÃªn CÃ¢y quyáº¿t Ä‘á»‹nh vÃ  NaÃ¯ve Bayes lÃ  gÃ¬?</p><ul class="options"><li>A. CÃ¢y quyáº¿t Ä‘á»‹nh chá»‰ dÃ¹ng cho dá»¯ liá»‡u liÃªn tá»¥c.</li><li>B. NaÃ¯ve Bayes luÃ´n chÃ­nh xÃ¡c hÆ¡n.</li><li class="correct-answer">C. CÃ¢y quyáº¿t Ä‘á»‹nh cÃ³ thá»ƒ há»c cÃ¡c tÆ°Æ¡ng tÃ¡c phá»©c táº¡p hÆ¡n giá»¯a cÃ¡c feature (item), trong khi NaÃ¯ve Bayes giáº£ Ä‘á»‹nh chÃºng Ä‘á»™c láº­p cÃ³ Ä‘iá»u kiá»‡n.</li><li>D. NaÃ¯ve Bayes cáº§n nhiá»u bá»™ phÃ¢n loáº¡i hÆ¡n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> CÃ¢y quyáº¿t Ä‘á»‹nh, báº±ng cÃ¡ch chia khÃ´ng gian dá»¯ liá»‡u, cÃ³ thá»ƒ mÃ´ hÃ¬nh hÃ³a cÃ¡c má»‘i quan há»‡ phi tuyáº¿n vÃ  tÆ°Æ¡ng tÃ¡c giá»¯a cÃ¡c thuá»™c tÃ­nh. NgÆ°á»£c láº¡i, giáº£ Ä‘á»‹nh "naÃ¯ve" (ngÃ¢y thÆ¡) cá»§a NaÃ¯ve Bayes chÃ­nh lÃ  sá»± Ä‘á»™c láº­p cÃ³ Ä‘iá»u kiá»‡n, bá» qua cÃ¡c tÆ°Æ¡ng tÃ¡c nÃ y.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 37: Trong Neural Multi-Task Recommendation (slide 38), táº¡i sao hÃ nh vi loáº¡i sau láº¡i phá»¥ thuá»™c vÃ o hÃ nh vi loáº¡i trÆ°á»›c?</p><ul class="options"><li>A. Äá»ƒ giáº£m sá»‘ lÆ°á»£ng tham sá»‘.</li><li class="correct-answer">B. Äá»ƒ mÃ´ hÃ¬nh hÃ³a tÃ­nh thá»© tá»± vÃ  sá»± chuyá»ƒn tiáº¿p tá»± nhiÃªn giá»¯a cÃ¡c hÃ nh vi (vÃ­ dá»¥: pháº£i xem rá»“i má»›i cÃ³ thá»ƒ mua).</li><li>C. Äá»ƒ tÄƒng tá»‘c Ä‘á»™ huáº¥n luyá»‡n.</li><li>D. ÄÃ¢y chá»‰ lÃ  má»™t lá»±a chá»n ngáº«u nhiÃªn.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 38 mÃ´ táº£ kiáº¿n trÃºc nÆ¡i Ä‘áº§u ra dá»± Ä‘oÃ¡n cá»§a hÃ nh vi `r-1` (vÃ­ dá»¥: `y_hat_ui^(r-1)`) Ä‘Æ°á»£c Ä‘Æ°a vÃ o lÃ m má»™t pháº§n Ä‘áº§u vÃ o Ä‘á»ƒ tÃ­nh toÃ¡n cho hÃ nh vi `r`. Äiá»u nÃ y trá»±c tiáº¿p mÃ´ hÃ¬nh hÃ³a sá»± phá»¥ thuá»™c vÃ  tÃ­nh thá»© tá»±.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 38: (Äiá»n Ä‘Ã¡p Ã¡n) Theo cÃ´ng thá»©c cuá»‘i cÃ¹ng á»Ÿ slide 43, Ä‘iá»ƒm sá»‘ dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng `r_hat_ui` Ä‘Æ°á»£c tÃ­nh nhÆ° tháº¿ nÃ o tá»« dá»± Ä‘oÃ¡n hÃ nh vi tiá»m áº©n `x_hat_ui` vÃ  hÃ nh vi rÃµ rÃ ng `y_hat_ui`?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">TÃ­ch cá»§a chÃºng (x_hat_ui * y_hat_ui)</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 43 trÃ¬nh bÃ y cÃ´ng thá»©c: `r_hat_ui = x_hat_ui * y_hat_ui`.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 39: Äiá»u nÃ o sau Ä‘Ã¢y lÃ  má»™t nhÆ°á»£c Ä‘iá»ƒm cá»§a viá»‡c Ã¡p dá»¥ng cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y cÆ¡ báº£n (nhÆ° Decision Tree) cho CF?</p><ul class="options"><li>A. ChÃºng khÃ´ng thá»ƒ xá»­ lÃ½ dá»¯ liá»‡u rá»i ráº¡c.</li><li class="correct-answer">B. Cáº§n pháº£i xÃ¢y dá»±ng má»™t sá»‘ lÆ°á»£ng lá»›n cÃ¡c mÃ´ hÃ¬nh (báº±ng sá»‘ lÆ°á»£ng item), ráº¥t tá»‘n kÃ©m vÃ  khÃ³ báº£o trÃ¬.</li><li>C. ChÃºng khÃ´ng thá»ƒ há»c Ä‘Æ°á»£c tá»« dá»¯ liá»‡u.</li><li>D. Káº¿t quáº£ khÃ´ng thá»ƒ giáº£i thÃ­ch Ä‘Æ°á»£c.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> NhÆ° Ä‘Ã£ Ä‘á» cáº­p á»Ÿ slide 8 vÃ  13, viá»‡c pháº£i xÃ¢y dá»±ng N mÃ´ hÃ¬nh riÃªng biá»‡t cho N item lÃ  má»™t rÃ o cáº£n lá»›n vá» máº·t tÃ­nh toÃ¡n vÃ  quáº£n lÃ½, Ä‘áº·c biá»‡t vá»›i cÃ¡c há»‡ thá»‘ng cÃ³ hÃ ng triá»‡u item.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 40: "Gaussian NaÃ¯ve Bayes" Ä‘Æ°á»£c Ä‘á» cáº­p trong slide 9 Ä‘á»ƒ xá»­ lÃ½ loáº¡i dá»¯ liá»‡u user-item feedback nÃ o?</p><ul class="options"><li>A. Dá»¯ liá»‡u rá»i ráº¡c</li><li class="correct-answer">B. Dá»¯ liá»‡u liÃªn tá»¥c</li><li>C. Dá»¯ liá»‡u nhá»‹ phÃ¢n</li><li>D. Dá»¯ liá»‡u thiáº¿u</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 nÃ³i ráº±ng NaÃ¯ve Bayes cÃ³ thá»ƒ Ä‘Æ°á»£c "má»Ÿ rá»™ng vá»›i user-item feedback liÃªn tá»¥c vá»›i Gaussian NaÃ¯ve Bayes".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 41: Trong GMF, trá»ng sá»‘ `h` (slide 21-22) mÃ´ táº£ Ä‘iá»u gÃ¬?</p><ul class="options"><li>A. Sá»‘ chiá»u cá»§a khÃ´ng gian áº©n.</li><li class="correct-answer">B. Má»©c Ä‘á»™ quan trá»ng khÃ¡c nhau cá»§a cÃ¡c thuá»™c tÃ­nh áº©n.</li><li>C. Vector áº©n cá»§a ngÆ°á»i dÃ¹ng.</li><li>D. HÃ m kÃ­ch hoáº¡t.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 22 giáº£i thÃ­ch: "Trá»ng sá»‘ h: mÃ´ táº£ Ä‘Æ°á»£c má»©c Ä‘á»™ quan trá»ng khÃ¡c nhau cá»§a cÃ¡c thuá»™c tÃ­nh áº©n". Vector nÃ y Ä‘Æ°á»£c nhÃ¢n vá»›i káº¿t quáº£ cá»§a phÃ©p element-wise product trÆ°á»›c khi Ä‘Æ°a ra dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 42: Táº¡i sao MLP cÃ³ thá»ƒ há»c Ä‘Æ°á»£c cÃ¡c tÆ°Æ¡ng tÃ¡c phi tuyáº¿n?</p><ul class="options"><li>A. VÃ¬ nÃ³ cÃ³ nhiá»u táº§ng.</li><li class="correct-answer">B. VÃ¬ nÃ³ sá»­ dá»¥ng cÃ¡c hÃ m kÃ­ch hoáº¡t phi tuyáº¿n (nhÆ° ReLU) trong cÃ¡c táº§ng áº©n.</li><li>C. VÃ¬ nÃ³ sá»­ dá»¥ng phÃ©p ná»‘i vector.</li><li>D. VÃ¬ nÃ³ cÃ³ táº§ng embedding.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Kháº£ nÄƒng há»c cÃ¡c hÃ m phá»©c táº¡p, phi tuyáº¿n cá»§a máº¡ng nÆ¡-ron Ä‘a lá»›p Ä‘áº¿n tá»« viá»‡c káº¿t há»£p cÃ¡c phÃ©p biáº¿n Ä‘á»•i tuyáº¿n tÃ­nh (nhÃ¢n ma tráº­n) vá»›i cÃ¡c hÃ m kÃ­ch hoáº¡t phi tuyáº¿n. Náº¿u khÃ´ng cÃ³ cÃ¡c hÃ m kÃ­ch hoáº¡t nÃ y, toÃ n bá»™ máº¡ng sáº½ chá»‰ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i má»™t phÃ©p biáº¿n Ä‘á»•i tuyáº¿n tÃ­nh duy nháº¥t.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 43: Trong NeuMF, Ä‘áº§u ra cá»§a nhÃ¡nh GMF vÃ  nhÃ¡nh MLP Ä‘Æ°á»£c káº¿t há»£p nhÆ° tháº¿ nÃ o trÆ°á»›c khi Ä‘Æ°a ra dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng?</p><ul class="options"><li>A. Láº¥y trung bÃ¬nh.</li><li>B. Láº¥y tÃ­ch.</li><li class="correct-answer">C. GhÃ©p ná»‘i (Concatenation).</li><li>D. Láº¥y max.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 24 cho tháº¥y vector Ä‘áº§u ra tá»« "GMF Layer" vÃ  "MLP Layer X" Ä‘Æ°á»£c Ä‘Æ°a vÃ o "NeuMF Layer", vÃ  thao tÃ¡c táº¡i Ä‘Ã¢y lÃ  "Concatenation".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 44: Theo Yifan Hu et al. (2008), cÃ¡c tÆ°Æ¡ng tÃ¡c áº©n nhÆ° sá»‘ láº§n xem, thá»i lÆ°á»£ng xem Ä‘Æ°á»£c coi lÃ  loáº¡i pháº£n há»“i gÃ¬?</p><ul class="options"><li>A. Pháº£n há»“i tiÃªu cá»±c.</li><li class="correct-answer">B. Pháº£n há»“i tÃ­ch cá»±c.</li><li>C. Pháº£n há»“i trung tÃ­nh.</li><li>D. Pháº£n há»“i khÃ´ng cÃ³ giÃ¡ trá»‹.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 28 giáº£i thÃ­ch: "TÆ°Æ¡ng tÃ¡c áº©n, dá»¯ liá»‡u tÆ°Æ¡ng tÃ¡c tiá»m áº©n thÃ¬ Ä‘á»u lÃ  cÃ¡c pháº£n há»“i tÃ­ch cá»±c." Ã tÆ°á»Ÿng lÃ  ngÆ°á»i dÃ¹ng sáº½ khÃ´ng tÆ°Æ¡ng tÃ¡c vá»›i nhá»¯ng gÃ¬ há» hoÃ n toÃ n khÃ´ng thÃ­ch.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 45: Má»¥c Ä‘Ã­ch cá»§a viá»‡c Ä‘Æ°a ra cÃ¡c cáº·p `(u, i, j)` trong BPR, vá»›i `i` lÃ  item Ä‘Ã£ quan sÃ¡t vÃ  `j` lÃ  item khÃ´ng quan sÃ¡t, lÃ  gÃ¬?</p><ul class="options"><li>A. Äá»ƒ tÄƒng sá»‘ lÆ°á»£ng dá»¯ liá»‡u huáº¥n luyá»‡n.</li><li class="correct-answer">B. Äá»ƒ táº¡o ra cÃ¡c cáº·p so sÃ¡nh thá»© tá»±, giáº£ Ä‘á»‹nh ráº±ng ngÆ°á»i dÃ¹ng thÃ­ch item há» Ä‘Ã£ tÆ°Æ¡ng tÃ¡c hÆ¡n item há» chÆ°a tÆ°Æ¡ng tÃ¡c.</li><li>C. Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» item cold-start.</li><li>D. Äá»ƒ giáº£m Ä‘á»™ thÆ°a cá»§a dá»¯ liá»‡u.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> BPR há»c tá»« cÃ¡c cáº·p so sÃ¡nh. Báº±ng cÃ¡ch láº¥y má»™t item `i` mÃ  user `u` Ä‘Ã£ tÆ°Æ¡ng tÃ¡c (positive) vÃ  má»™t item `j` mÃ  `u` chÆ°a tÆ°Æ¡ng tÃ¡c (assumed negative/missing), BPR táº¡o ra má»™t Ä‘iá»ƒm dá»¯ liá»‡u huáº¥n luyá»‡n `i >u j` Ä‘á»ƒ tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 46: Trong hÃ m má»¥c tiÃªu cá»§a Co-rating (slide 36), `R(P,Q)` lÃ  thÃ nh pháº§n gÃ¬?</p><ul class="options"><li>A. HÃ m lá»—i.</li><li>B. HÃ m kÃ­ch hoáº¡t.</li><li class="correct-answer">C. ThÃ nh pháº§n hiá»‡u chá»‰nh (Regularization).</li><li>D. Trá»ng sá»‘.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> `R(P,Q)` Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  `||P||^2 + ||Q||^2`, tÆ°Æ¡ng tá»± nhÆ° thÃ nh pháº§n hiá»‡u chá»‰nh trong MF truyá»n thá»‘ng, dÃ¹ng Ä‘á»ƒ trÃ¡nh overfitting báº±ng cÃ¡ch pháº¡t Ä‘á»™ lá»›n cá»§a cÃ¡c vector áº©n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 47: Trong Neural Multi-Task Recommendation (slide 39), tham sá»‘ `Î»_r` dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬?</p><ul class="options"><li>A. Tá»‘c Ä‘á»™ há»c.</li><li class="correct-answer">B. Trá»ng sá»‘ biá»ƒu diá»…n má»©c Ä‘á»™ áº£nh hÆ°á»Ÿng cá»§a tá»«ng loáº¡i hÃ nh vi.</li><li>C. Tham sá»‘ hiá»‡u chá»‰nh.</li><li>D. Sá»‘ lÆ°á»£ng nÆ¡-ron trong táº§ng áº©n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 39 giáº£i thÃ­ch: "`Î»_r`, trá»ng sá»‘ biá»ƒu diá»…n má»©c Ä‘á»™ áº£nh hÆ°á»Ÿng cá»§a tá»«ng loáº¡i hÃ nh vi." NÃ³ cho phÃ©p Ä‘iá»u chá»‰nh táº§m quan trá»ng cá»§a viá»‡c dá»± Ä‘oÃ¡n Ä‘Ãºng má»—i loáº¡i hÃ nh vi trong hÃ m lá»—i tá»•ng thá»ƒ.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 48: MÃ´ hÃ¬nh Implicit to Explicit (I2E) Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn kiáº¿n trÃºc ná»n táº£ng nÃ o?</p><ul class="options"><li>A. Chá»‰ GMF</li><li>B. Chá»‰ MLP</li><li class="correct-answer">C. Má»™t kiáº¿n trÃºc tÆ°Æ¡ng tá»± NeuMF (káº¿t há»£p GMF vÃ  MLP) cho pháº§n implicit.</li><li>D. BPR</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 40 cho tháº¥y pháº§n dÆ°á»›i cá»§a mÃ´ hÃ¬nh (dá»± Ä‘oÃ¡n tÆ°Æ¡ng tÃ¡c implicit) cÃ³ cáº¥u trÃºc ráº¥t giá»‘ng NeuMF, vá»›i cÃ¡c nhÃ¡nh GMF vÃ  MLP Ä‘Æ°á»£c káº¿t há»£p. Äáº§u ra cá»§a pháº§n nÃ y sau Ä‘Ã³ Ä‘Æ°á»£c Ä‘Æ°a vÃ o má»™t máº¡ng MLP khÃ¡c (ITE) Ä‘á»ƒ dá»± Ä‘oÃ¡n tÆ°Æ¡ng tÃ¡c explicit.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 49: HÃ m lá»—i nÃ o thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n (dá»± Ä‘oÃ¡n 0/1) trong cÃ¡c mÃ´ hÃ¬nh deep learning cho CF (vÃ­ dá»¥: NeuMF, I2E)?</p><ul class="options"><li>A. Mean Squared Error (MSE)</li><li class="correct-answer">B. Binary Cross-Entropy (Log Loss)</li><li>C. Mean Absolute Error (MAE)</li><li>D. Hinge Loss</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> CÃ¡c hÃ m lá»—i trÃªn slide 39 vÃ  44 cÃ³ dáº¡ng `Î£ y*log(y_hat) + (1-y)*log(1-y_hat)`. ÄÃ¢y chÃ­nh lÃ  cÃ´ng thá»©c cá»§a Binary Cross-Entropy, lÃ  hÃ m lá»—i tiÃªu chuáº©n cho cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 50: (Äiá»n Ä‘Ã¡p Ã¡n) Trong BPR, náº¿u Ä‘iá»ƒm dá»± Ä‘oÃ¡n `r_ui = 2.5` vÃ  `r_uj = 1.0`, thÃ¬ `r_uij` báº±ng bao nhiÃªu?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">1.5</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Theo cÃ´ng thá»©c `r_uij = r_ui - r_uj` (slide 33), ta cÃ³ `r_uij = 2.5 - 1.0 = 1.5`.</p></div></div>
        
        <!-- From 51 to 100 -->
        <div class="question-block"><p class="question-text">CÃ¢u 51: Dá»¯ liá»‡u "like" má»™t bÃ i post trÃªn máº¡ng xÃ£ há»™i thuá»™c loáº¡i feedback nÃ o?</p><ul class="options"><li class="correct-answer">A. Explicit feedback</li><li>B. Implicit feedback</li><li>C. Contextual feedback</li><li>D. Negative feedback</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 27 liá»‡t kÃª "like" lÃ  má»™t vÃ­ dá»¥ cá»§a "Dá»¯ liá»‡u explicit feedback", vÃ¬ nÃ³ thá»ƒ hiá»‡n rÃµ rÃ ng sá»± yÃªu thÃ­ch cá»§a ngÆ°á»i dÃ¹ng.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 52: Viá»‡c "xem" má»™t sáº£n pháº©m trÃªn trang thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ thuá»™c loáº¡i feedback nÃ o?</p><ul class="options"><li>A. Explicit feedback</li><li class="correct-answer">B. Implicit feedback</li><li>C. Positive feedback</li><li>D. Neutral feedback</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 27 liá»‡t kÃª "view" lÃ  má»™t vÃ­ dá»¥ cá»§a "Dá»¯ liá»‡u implicit feedback", vÃ¬ nÃ³ khÃ´ng trá»±c tiáº¿p kháº³ng Ä‘á»‹nh sá»± yÃªu thÃ­ch nhÆ°ng lÃ  má»™t tÃ­n hiá»‡u tiá»m áº©n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 53: Theo slide 17, cÃ´ng thá»©c dá»± Ä‘oÃ¡n rating trong MF truyá»n thá»‘ng `v_ui = w_u^T * h_i` lÃ  má»™t phÃ©p toÃ¡n gÃ¬?</p><ul class="options"><li>A. TÃ­ch ma tráº­n</li><li class="correct-answer">B. TÃ­ch vÃ´ hÆ°á»›ng (dot product)</li><li>C. TÃ­ch theo tá»«ng pháº§n tá»­ (element-wise product)</li><li>D. PhÃ©p ná»‘i (concatenation)</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> `w_u^T * h_i` lÃ  cÃ¡ch viáº¿t toÃ¡n há»c cá»§a tÃ­ch vÃ´ hÆ°á»›ng giá»¯a vector `w_u` vÃ  `h_i`.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 54: ThÃ nh pháº§n hiá»‡u chá»‰nh (regularization) trong hÃ m má»¥c tiÃªu cá»§a MF (slide 19) sá»­ dá»¥ng chuáº©n (norm) nÃ o cá»§a cÃ¡c vector áº©n?</p><ul class="options"><li>A. L0 norm</li><li>B. L1 norm (Lasso)</li><li class="correct-answer">C. L2 norm (Ridge/Frobenius norm)</li><li>D. Infinity norm</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> CÃ´ng thá»©c `Î£||w_i||^2` lÃ  tá»•ng bÃ¬nh phÆ°Æ¡ng cá»§a chuáº©n L2 (Euclidean norm) cá»§a cÃ¡c vector. ÄÃ¢y lÃ  ká»¹ thuáº­t hiá»‡u chá»‰nh L2, cÃ²n Ä‘Æ°á»£c gá»i lÃ  Ridge regression.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 55: (Äiá»n Ä‘Ã¡p Ã¡n) Trong kiáº¿n trÃºc Deep Matrix Factorization (slide 26), Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng (relevance) giá»¯a biá»ƒu diá»…n áº©n cá»§a user vÃ  item Ä‘Æ°á»£c Ä‘o báº±ng gÃ¬?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">Cosine similarity</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 26 cÃ³ ghi chÃº "Relevance measured by cosine similarity" á»Ÿ phÃ­a trÃªn cÃ¹ng cá»§a sÆ¡ Ä‘á»“.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 56: Táº¡i sao BPR Ä‘Æ°á»£c gá»i lÃ  "Personalized Ranking"?</p><ul class="options"><li>A. VÃ¬ nÃ³ dá»± Ä‘oÃ¡n rating cho má»—i ngÆ°á»i.</li><li class="correct-answer">B. VÃ¬ nÃ³ há»c má»™t thá»© tá»± xáº¿p háº¡ng riÃªng biá»‡t cho má»—i ngÆ°á»i dÃ¹ng (i >u j), thay vÃ¬ má»™t thá»© tá»± chung cho táº¥t cáº£.</li><li>C. VÃ¬ nÃ³ sá»­ dá»¥ng thÃ´ng tin cÃ¡ nhÃ¢n nhÆ° tuá»•i, giá»›i tÃ­nh.</li><li>D. VÃ¬ nÃ³ cho phÃ©p ngÆ°á»i dÃ¹ng tá»± xáº¿p háº¡ng sáº£n pháº©m.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> TÃªn gá»i nÃ y nháº¥n máº¡nh ráº±ng má»‘i quan há»‡ thá»© tá»± `>` lÃ  phá»¥ thuá»™c vÃ o ngÆ°á»i dÃ¹ng `u`. CÃ¹ng má»™t cáº·p item (i, j), user A cÃ³ thá»ƒ thÃ­ch i hÆ¡n j, nhÆ°ng user B láº¡i cÃ³ thá»ƒ thÃ­ch j hÆ¡n i. BPR mÃ´ hÃ¬nh hÃ³a sá»± cÃ¡ nhÃ¢n hÃ³a nÃ y.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 57: Trong cÃ¡c mÃ´ hÃ¬nh CF dá»±a trÃªn Deep Learning nhÆ° NeuMF, táº§ng embedding cÃ³ vai trÃ² gÃ¬?</p><ul class="options"><li>A. Giáº£m sá»‘ lÆ°á»£ng ngÆ°á»i dÃ¹ng.</li><li class="correct-answer">B. Ãnh xáº¡ cÃ¡c ID Ä‘á»‹nh danh (thÆ°á»ng lÃ  one-hot, thÆ°a thá»›t) sang cÃ¡c vector Ä‘áº·c trÆ°ng áº©n (dÃ y Ä‘áº·c, cÃ³ sá»‘ chiá»u tháº¥p hÆ¡n).</li><li>C. TÃ­nh toÃ¡n hÃ m lá»—i.</li><li>D. Ãp dá»¥ng hÃ m kÃ­ch hoáº¡t.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Táº§ng embedding lÃ  má»™t ká»¹ thuáº­t phá»• biáº¿n trong DL Ä‘á»ƒ há»c cÃ¡c biá»ƒu diá»…n cÃ³ Ã½ nghÄ©a cho cÃ¡c thá»±c thá»ƒ rá»i ráº¡c (nhÆ° user ID, item ID). NÃ³ lÃ  má»™t dáº¡ng tra cá»©u (lookup) trong má»™t ma tráº­n trá»ng sá»‘, nÆ¡i má»—i hÃ ng lÃ  má»™t vector áº©n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 58: Táº¡i sao láº¡i cáº§n nhá»¯ng mÃ´ hÃ¬nh phá»©c táº¡p nhÆ° Neural Multi-Task hoáº·c Implicit-to-Explicit?</p><ul class="options"><li>A. Äá»ƒ lÃ m cháº­m quÃ¡ trÃ¬nh huáº¥n luyá»‡n.</li><li>B. VÃ¬ chÃºng Ä‘Æ¡n giáº£n hÆ¡n MF.</li><li class="correct-answer">C. VÃ¬ cÃ¡c hÃ nh vi cá»§a ngÆ°á»i dÃ¹ng trong thá»±c táº¿ ráº¥t Ä‘a dáº¡ng vÃ  cÃ³ má»‘i quan há»‡ phá»©c táº¡p vá»›i nhau, cÃ¡c mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n khÃ´ng náº¯m báº¯t háº¿t Ä‘Æ°á»£c.</li><li>D. VÃ¬ chÃºng khÃ´ng cáº§n dá»¯ liá»‡u.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> CÃ¡c mÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c táº¡o ra Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n thá»±c táº¿ phá»©c táº¡p hÆ¡n. VÃ­ dá»¥, viá»‡c dá»± Ä‘oÃ¡n "mua hÃ ng" (explicit) sáº½ chÃ­nh xÃ¡c hÆ¡n náº¿u ta cÅ©ng mÃ´ hÃ¬nh hÃ³a cÃ¡c hÃ nh vi trÆ°á»›c Ä‘Ã³ nhÆ° "xem" vÃ  "thÃªm vÃ o giá»" (implicit), vÃ¬ chÃºng cung cáº¥p tÃ­n hiá»‡u vÃ  ngá»¯ cáº£nh quan trá»ng.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 59: MÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi He et al. 2017?</p><ul class="options"><li>A. Deep Matrix Factorization</li><li class="correct-answer">B. Neural Matrix Factorization</li><li>C. Weighted Matrix Factorization</li><li>D. Bayesian Personalized Ranking</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 14 vÃ  46 Ä‘á»u trÃ­ch dáº«n "[He et.al 2017]" cho "Neural matrix factorization".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 60: MÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Rendle et al. 2009?</p><ul class="options"><li>A. Deep Matrix Factorization</li><li>B. Neural Matrix Factorization</li><li>C. Weighted Matrix Factorization</li><li class="correct-answer">D. Bayesian Personalized Ranking</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> TiÃªu Ä‘á» cÃ¡c slide tá»« 30 Ä‘áº¿n 35 Ä‘á»u lÃ  "Bayesian Personalized Ranking (Rendle el at - 2009)".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 61: Trong cÃ´ng thá»©c dá»± Ä‘oÃ¡n cá»§a NaÃ¯ve Bayes (slide 12), máº«u sá»‘ `Î£ P(ruj = vs) * Î  P(ruk|ruj = vs)` Ä‘Ã³ng vai trÃ² gÃ¬?</p><ul class="options"><li>A. XÃ¡c suáº¥t tiÃªn nghiá»‡m</li><li>B. XÃ¡c suáº¥t likelihood</li><li class="correct-answer">C. ThÃ nh pháº§n chuáº©n hÃ³a Ä‘á»ƒ Ä‘áº£m báº£o tá»•ng cÃ¡c xÃ¡c suáº¥t `P(ruj = vs|...)` báº±ng 1.</li><li>D. Ká»³ vá»ng cá»§a rating.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong Ä‘á»‹nh lÃ½ Bayes, máº«u sá»‘ `P(Evidence)` Ä‘Ã³ng vai trÃ² lÃ  háº±ng sá»‘ chuáº©n hÃ³a. á» Ä‘Ã¢y, tá»•ng theo táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ `vs` cÃ³ thá»ƒ cÃ³ cá»§a tá»­ sá»‘ chÃ­nh lÃ  báº±ng chá»©ng (evidence) `P(Observed ratings in Iu)`, giÃºp chuyá»ƒn Ä‘á»•i káº¿t quáº£ thÃ nh má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t há»£p lá»‡.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 62: Má»™t háº¡n cháº¿ cá»§a viá»‡c xem má»—i item lÃ  má»™t "feature" trong cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y cÆ¡ báº£n lÃ  gÃ¬?</p><ul class="options"><li class="correct-answer">A. Hiá»‡n tÆ°á»£ng "lá»i nguyá»n sá»‘ chiá»u" (curse of dimensionality) khi cÃ³ hÃ ng triá»‡u item, khiáº¿n mÃ´ hÃ¬nh khÃ³ há»c.</li><li>B. KhÃ´ng thá»ƒ xá»­ lÃ½ item má»›i.</li><li>C. KhÃ´ng thá»ƒ biá»ƒu diá»…n Ä‘Æ°á»£c user.</li><li>D. MÃ´ hÃ¬nh sáº½ quÃ¡ Ä‘Æ¡n giáº£n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Khi sá»‘ lÆ°á»£ng item (tá»©c lÃ  sá»‘ chiá»u cá»§a vector user) quÃ¡ lá»›n, khÃ´ng gian dá»¯ liá»‡u trá»Ÿ nÃªn cá»±c ká»³ thÆ°a thá»›t vÃ  rá»™ng lá»›n, gÃ¢y khÃ³ khÄƒn cho háº§u háº¿t cÃ¡c thuáº­t toÃ¡n há»c mÃ¡y trong viá»‡c tÃ¬m ra cÃ¡c máº«u cÃ³ Ã½ nghÄ©a. ÄÃ¢y lÃ  báº£n cháº¥t cá»§a "lá»i nguyá»n sá»‘ chiá»u".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 63: Trong mÃ´ hÃ¬nh GMF, náº¿u `a_out` lÃ  hÃ m sigmoid, mÃ´ hÃ¬nh MF thu Ä‘Æ°á»£c cÃ³ tÃ­nh cháº¥t gÃ¬?</p><ul class="options"><li>A. Tuyáº¿n tÃ­nh</li><li class="correct-answer">B. Phi tuyáº¿n</li><li>C. Rá»i ráº¡c</li><li>D. LiÃªn tá»¥c</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 22 ghi: "`a_out` cÃ³ thá»ƒ lÃ  hÃ m phi tuyáº¿n (sigmoid,..) thu Ä‘Æ°á»£c mÃ´ hÃ¬nh MF phi tuyáº¿n." Viá»‡c thÃªm má»™t hÃ m kÃ­ch hoáº¡t phi tuyáº¿n á»Ÿ cuá»‘i sáº½ lÃ m cho má»‘i quan há»‡ giá»¯a Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra trá»Ÿ nÃªn phi tuyáº¿n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 64: Theo slide 5, ná»™i dung nÃ o KHÃ”NG Ä‘Æ°á»£c Ä‘á» cáº­p trong chÆ°Æ¡ng nÃ y?</p><ul class="options"><li>A. Lá»c cá»™ng tÃ¡c dá»±a trÃªn deep learning.</li><li>B. Dá»¯ liá»‡u implicit vÃ  explicit feedback.</li><li class="correct-answer">C. Lá»c cá»™ng tÃ¡c dá»±a trÃªn lÃ¡ng giá»ng gáº§n (Neighborhood-based CF).</li><li>D. Lá»c cá»™ng tÃ¡c dá»±a trÃªn cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y cÆ¡ báº£n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 5 ("Ná»™i dung") khÃ´ng liá»‡t kÃª cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn lÃ¡ng giá»ng. ChÆ°Æ¡ng nÃ y táº­p trung hoÃ n toÃ n vÃ o cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn mÃ´ hÃ¬nh, tá»« cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y cÆ¡ báº£n Ä‘áº¿n deep learning.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 65: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 37, náº¿u cÃ³ R loáº¡i hÃ nh vi, mÃ´ hÃ¬nh Neural Multi-Task Recommendation sáº½ biá»ƒu diá»…n chÃºng dÆ°á»›i dáº¡ng bao nhiÃªu ma tráº­n nhá»‹ phÃ¢n?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">R</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 37 nÃªu: "CÃ³ R loáº¡i hÃ nh vi khÃ¡c nhau biá»ƒu diá»…n cho R loáº¡i tÆ°Æ¡ng tÃ¡c. Má»—i loáº¡i hÃ nh vi Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng ma tráº­n cá»¡ MxN..."</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 66: MÃ´ hÃ¬nh I2E (Implicit to Explicit) cÃ³ thá»ƒ Ä‘Æ°á»£c coi lÃ  má»™t dáº¡ng há»c gÃ¬?</p><ul class="options"><li>A. Há»c khÃ´ng giÃ¡m sÃ¡t (Unsupervised Learning)</li><li>B. Há»c tÄƒng cÆ°á»ng (Reinforcement Learning)</li><li class="correct-answer">C. Há»c chuyá»ƒn giao / Há»c Ä‘a nhiá»‡m (Transfer Learning / Multi-task Learning)</li><li>D. Há»c bÃ¡n giÃ¡m sÃ¡t (Semi-supervised Learning)</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> MÃ´ hÃ¬nh nÃ y há»c Ä‘á»“ng thá»i hai nhiá»‡m vá»¥ (dá»± Ä‘oÃ¡n implicit vÃ  explicit). HÆ¡n ná»¯a, kiáº¿n thá»©c há»c Ä‘Æ°á»£c tá»« nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n implicit (biá»ƒu diá»…n `Ï†^I`) Ä‘Æ°á»£c "chuyá»ƒn giao" Ä‘á»ƒ há»— trá»£ cho nhiá»‡m vá»¥ dá»± Ä‘oÃ¡n explicit. ÄÃ¢y lÃ  má»™t vÃ­ dá»¥ Ä‘iá»ƒn hÃ¬nh cá»§a há»c chuyá»ƒn giao vÃ  Ä‘a nhiá»‡m.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 67: Táº¡i sao trong BPR, ngÆ°á»i ta thÆ°á»ng láº¥y máº«u cÃ¡c cáº·p item (i, j) vá»›i i lÃ  item dÆ°Æ¡ng (positive) vÃ  j lÃ  item Ã¢m (chÆ°a quan sÃ¡t)?</p><ul class="options"><li>A. VÃ¬ sá»‘ lÆ°á»£ng item dÆ°Æ¡ng vÃ  Ã¢m luÃ´n báº±ng nhau.</li><li class="correct-answer">B. VÃ¬ sá»‘ lÆ°á»£ng cÃ¡c cáº·p (Ã¢m, Ã¢m) hoáº·c (dÆ°Æ¡ng, dÆ°Æ¡ng) quÃ¡ lá»›n vÃ  Ã­t mang thÃ´ng tin vá» thá»© tá»± Æ°u tiÃªn.</li><li>C. VÃ¬ mÃ´ hÃ¬nh khÃ´ng thá»ƒ xá»­ lÃ½ cÃ¡c cáº·p (dÆ°Æ¡ng, dÆ°Æ¡ng).</li><li>D. Äá»ƒ giáº£m Ä‘á»™ phá»©c táº¡p cá»§a thuáº­t toÃ¡n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> BPR há»c tá»« sá»± khÃ¡c biá»‡t vá» sá»Ÿ thÃ­ch. So sÃ¡nh má»™t item ngÆ°á»i dÃ¹ng thÃ­ch vá»›i má»™t item há» (cÃ³ thá»ƒ) khÃ´ng thÃ­ch sáº½ cung cáº¥p tÃ­n hiá»‡u máº¡nh nháº¥t cho viá»‡c há»c thá»© tá»±. Sá»‘ lÆ°á»£ng táº¥t cáº£ cÃ¡c cáº·p cÃ³ thá»ƒ cÃ³ lÃ  ráº¥t lá»›n, nÃªn viá»‡c láº¥y máº«u má»™t cÃ¡ch thÃ´ng minh lÃ  cáº§n thiáº¿t.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 68: Giáº£ sá»­ trong má»™t há»‡ thá»‘ng CF dá»±a trÃªn CÃ¢y quyáº¿t Ä‘á»‹nh, Ä‘á»ƒ dá»± Ä‘oÃ¡n rating cho phim "Titanic", cÃ¡c thuá»™c tÃ­nh Ä‘áº§u vÃ o (features) cá»§a mÃ´ hÃ¬nh sáº½ lÃ  gÃ¬?</p><ul class="options"><li>A. Thá»ƒ loáº¡i, Ä‘áº¡o diá»…n cá»§a "Titanic".</li><li class="correct-answer">B. Rating cá»§a ngÆ°á»i dÃ¹ng cho cÃ¡c phim khÃ¡c nhÆ° "Avatar", "Inception",...</li><li>C. Rating trung bÃ¬nh cá»§a "Titanic".</li><li>D. Sá»‘ lÆ°á»£ng ngÆ°á»i Ä‘Ã£ xem "Titanic".</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Theo slide 13, user lÃ  "data instance", cÃ¡c feature lÃ  "items". Váº­y Ä‘á»ƒ dá»± Ä‘oÃ¡n cho item nhÃ£n lÃ  "Titanic", cÃ¡c feature sáº½ lÃ  rating cá»§a cÃ¡c item khÃ¡c.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 69: Trong cÃ´ng thá»©c cáº­p nháº­t SGD cá»§a BPR (slide 35), táº¡i sao Ä‘áº¡o hÃ m theo `y_j` láº¡i cÃ³ dáº¥u ngÆ°á»£c láº¡i so vá»›i Ä‘áº¡o hÃ m theo `y_i`?</p><ul class="options"><li>A. ÄÃ³ lÃ  má»™t lá»—i in áº¥n.</li><li class="correct-answer">B. VÃ¬ trong `r_uij = r_ui - r_uj`, `y_i` Ä‘Ã³ng gÃ³p dÆ°Æ¡ng vÃ  `y_j` Ä‘Ã³ng gÃ³p Ã¢m vÃ o sá»± khÃ¡c biá»‡t. Do Ä‘Ã³, gradient sáº½ cÃ³ hÆ°á»›ng ngÆ°á»£c nhau.</li><li>C. VÃ¬ `y_j` luÃ´n nhá» hÆ¡n `y_i`.</li><li>D. VÃ¬ `y_j` lÃ  vector cá»§a item Ã¢m.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Theo quy táº¯c chuá»—i (chain rule) trong tÃ­nh Ä‘áº¡o hÃ m, khi láº¥y Ä‘áº¡o hÃ m cá»§a hÃ m lá»—i theo `y_i` vÃ  `y_j`, ta sáº½ cÃ³ cÃ¡c thÃ nh pháº§n tÆ°Æ¡ng á»©ng vá»›i Ä‘áº¡o hÃ m cá»§a `r_uij` theo `y_i` (lÃ  `x_u`) vÃ  theo `y_j` (lÃ  `-x_u`), dáº«n Ä‘áº¿n dáº¥u ngÆ°á»£c nhau trong cÃ´ng thá»©c cáº­p nháº­t cuá»‘i cÃ¹ng.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 70: So vá»›i MF truyá»n thá»‘ng, Æ°u Ä‘iá»ƒm chÃ­nh cá»§a cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn Deep Learning nhÆ° NeuMF lÃ  gÃ¬?</p><ul class="options"><li>A. ChÃºng luÃ´n nhanh hÆ¡n.</li><li>B. ChÃºng khÃ´ng cáº§n dá»¯ liá»‡u.</li><li class="correct-answer">C. ChÃºng cÃ³ thá»ƒ náº¯m báº¯t cÃ¡c tÆ°Æ¡ng tÃ¡c phi tuyáº¿n vÃ  phá»©c táº¡p giá»¯a user vÃ  item, Ä‘iá»u mÃ  MF (dá»±a trÃªn tÃ­ch vÃ´ hÆ°á»›ng) khÃ´ng lÃ m Ä‘Æ°á»£c.</li><li>D. ChÃºng dá»… giáº£i thÃ­ch hÆ¡n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> TÃ­ch vÃ´ hÆ°á»›ng cá»§a MF vá» cÆ¡ báº£n lÃ  má»™t mÃ´ hÃ¬nh tuyáº¿n tÃ­nh. Viá»‡c sá»­ dá»¥ng cÃ¡c máº¡ng nÆ¡-ron sÃ¢u vá»›i cÃ¡c hÃ m kÃ­ch hoáº¡t phi tuyáº¿n cho phÃ©p cÃ¡c mÃ´ hÃ¬nh nhÆ° NeuMF há»c Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ phá»©c táº¡p hÆ¡n nhiá»u, cÃ³ kháº£ nÄƒng dáº«n Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 71: Trong kiáº¿n trÃºc DMF (slide 26), táº¡i sao láº¡i cÃ³ hai "thÃ¡p" MLP riÃªng biá»‡t cho user vÃ  item?</p><ul class="options"><li>A. Äá»ƒ lÃ m cho mÃ´ hÃ¬nh Ä‘á»‘i xá»©ng.</li><li class="correct-answer">B. Äá»ƒ há»c cÃ¡c biá»ƒu diá»…n áº©n riÃªng biá»‡t vÃ  phÃ¹ há»£p cho khÃ´ng gian user vÃ  khÃ´ng gian item tá»« cÃ¡c vector tÆ°Æ¡ng tÃ¡c thÃ´.</li><li>C. VÃ¬ user vÃ  item luÃ´n cÃ³ cÃ¹ng sá»‘ lÆ°á»£ng.</li><li>D. Äá»ƒ tÄƒng sá»‘ lÆ°á»£ng tham sá»‘.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Kiáº¿n trÃºc nÃ y giáº£ Ä‘á»‹nh ráº±ng cÃ³ nhá»¯ng cáº¥u trÃºc vÃ  máº«u khÃ¡c nhau trong cÃ¡ch cÃ¡c user tÆ°Æ¡ng tÃ¡c vÃ  cÃ¡ch cÃ¡c item Ä‘Æ°á»£c tÆ°Æ¡ng tÃ¡c. Viá»‡c sá»­ dá»¥ng hai máº¡ng riÃªng biá»‡t cho phÃ©p mÃ´ hÃ¬nh há»c cÃ¡c phÃ©p chiáº¿u (projection) phi tuyáº¿n khÃ¡c nhau Ä‘á»ƒ Ã¡nh xáº¡ tá»« khÃ´ng gian tÆ°Æ¡ng tÃ¡c thÃ´ sang khÃ´ng gian áº©n cho user vÃ  item.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 72: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 40, lá»›p Ä‘áº§u vÃ o cá»§a mÃ´ hÃ¬nh I2E cho má»™t cáº·p (user, item) Ä‘Æ°á»£c gá»i lÃ  gÃ¬?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">ITE-one hot</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 40 cÃ³ má»¥c: "ITE-one hot: vector Ä‘áº§u vÃ o lÃ  vector one hot mÃ£ hÃ³a Ä‘á»‹nh danh cho ngÆ°á»i dÃ¹ng, sáº£n pháº©m."</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 73: Dá»¯ liá»‡u implicit thÆ°á»ng Ä‘Æ°á»£c coi lÃ  chá»‰ chá»©a pháº£n há»“i tÃ­ch cá»±c. Äiá»u nÃ y gÃ¢y ra thÃ¡ch thá»©c gÃ¬ cho viá»‡c há»c mÃ´ hÃ¬nh?</p><ul class="options"><li>A. KhÃ´ng cÃ³ Ä‘á»§ dá»¯ liá»‡u.</li><li class="correct-answer">B. Thiáº¿u cÃ¡c vÃ­ dá»¥ tiÃªu cá»±c (negative examples) thá»±c sá»±, khiáº¿n mÃ´ hÃ¬nh khÃ³ phÃ¢n biá»‡t giá»¯a "khÃ´ng thÃ­ch" vÃ  "chÆ°a biáº¿t".</li><li>C. Dá»¯ liá»‡u quÃ¡ dÃ y Ä‘áº·c.</li><li>D. Dá»¯ liá»‡u khÃ´ng cÃ³ nhiá»…u.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> ÄÃ¢y lÃ  váº¥n Ä‘á» cá»‘t lÃµi mÃ  cÃ¡c mÃ´ hÃ¬nh nhÆ° WMF vÃ  BPR cá»‘ gáº¯ng giáº£i quyáº¿t. Khi táº¥t cáº£ dá»¯ liá»‡u quan sÃ¡t Ä‘Æ°á»£c Ä‘á»u lÃ  "1", vÃ  dá»¯ liá»‡u khÃ´ng quan sÃ¡t Ä‘Æ°á»£c lÃ  "0", mÃ´ hÃ¬nh khÃ´ng thá»ƒ cháº¯c cháº¯n liá»‡u "0" cÃ³ nghÄ©a lÃ  khÃ´ng thÃ­ch hay chá»‰ lÃ  chÆ°a tháº¥y. WMF giáº£i quyáº¿t báº±ng trá»ng sá»‘ tin cáº­y, BPR giáº£i quyáº¿t báº±ng cÃ¡ch láº¥y máº«u cáº·p so sÃ¡nh.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 74: Táº¡i sao trong cÃ´ng thá»©c hÃ m lá»—i cá»§a Co-rating (slide 36), láº¡i cÃ³ hai thÃ nh pháº§n `L_E` vÃ  `L_I`?</p><ul class="options"><li>A. Äá»ƒ mÃ´ hÃ¬nh há»c nhanh hÆ¡n.</li><li class="correct-answer">B. VÃ¬ mÃ´ hÃ¬nh há»c Ä‘á»“ng thá»i trÃªn hai loáº¡i dá»¯ liá»‡u: `L_E` cho lá»—i trÃªn dá»¯ liá»‡u explicit (Y) vÃ  `L_I` cho lá»—i trÃªn dá»¯ liá»‡u implicit (X).</li><li>C. ÄÃ¢y lÃ  hai cÃ¡ch tÃ­nh lá»—i khÃ¡c nhau cho cÃ¹ng má»™t dá»¯ liá»‡u.</li><li>D. Äá»ƒ xá»­ lÃ½ hai nhÃ³m ngÆ°á»i dÃ¹ng khÃ¡c nhau.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> MÃ´ hÃ¬nh nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ há»c tá»« cáº£ hai nguá»“n thÃ´ng tin. Do Ä‘Ã³, hÃ m lá»—i tá»•ng thá»ƒ pháº£i bao gá»“m cáº£ thÃ nh pháº§n lá»—i cho viá»‡c dá»± Ä‘oÃ¡n dá»¯ liá»‡u explicit (vÃ­ dá»¥: rating) vÃ  thÃ nh pháº§n lá»—i cho viá»‡c dá»± Ä‘oÃ¡n dá»¯ liá»‡u implicit (vÃ­ dá»¥: cÃ³ mua hay khÃ´ng).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 75: So sÃ¡nh giá»¯a BPR vÃ  WMF, mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a trá»±c tiáº¿p cho bÃ i toÃ¡n xáº¿p háº¡ng?</p><ul class="options"><li>A. WMF</li><li class="correct-answer">B. BPR</li><li>C. Cáº£ hai</li><li>D. KhÃ´ng mÃ´ hÃ¬nh nÃ o</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> WMF váº«n tá»‘i Æ°u hÃ³a theo cÃ¡ch tiáº¿p cáº­n pointwise, cá»‘ gáº¯ng dá»± Ä‘oÃ¡n má»™t giÃ¡ trá»‹ (má»©c Ä‘á»™ tin cáº­y). Trong khi Ä‘Ã³, BPR tá»‘i Æ°u hÃ³a trá»±c tiáº¿p cho thá»© tá»± tÆ°Æ¡ng Ä‘á»‘i giá»¯a cÃ¡c item (pairwise), Ä‘iá»u nÃ y gáº§n vá»›i má»¥c tiÃªu cuá»‘i cÃ¹ng cá»§a bÃ i toÃ¡n xáº¿p háº¡ng hÆ¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 76: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 23, `ax, Wx, bx` trong cÃ´ng thá»©c cá»§a MLP tÆ°Æ¡ng á»©ng lÃ  gÃ¬?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">hÃ m kÃ­ch hoáº¡t, ma tráº­n trá»ng sá»‘, bias</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 23 Ä‘á»‹nh nghÄ©a rÃµ: "`ax, Wx, bx` : lÃ  hÃ m kÃ­ch hoáº¡t, ma tráº­n trá»ng sá»‘, bias cá»§a táº§ng thá»© x."</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 77: Náº¿u má»™t ngÆ°á»i dÃ¹ng click vÃ o má»™t sáº£n pháº©m do nháº§m láº«n, Ä‘Ã¢y lÃ  vÃ­ dá»¥ vá» Ä‘iá»u gÃ¬ trong dá»¯ liá»‡u implicit?</p><ul class="options"><li>A. Dá»¯ liá»‡u quÃ½ giÃ¡</li><li class="correct-answer">B. Nhiá»…u (Noise)</li><li>C. TÃ­n hiá»‡u máº¡nh</li><li>D. Dá»¯ liá»‡u explicit</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 27 Ä‘á» cáº­p ráº±ng dá»¯ liá»‡u implicit "CÃ³ thá»ƒ cÃ³ nhiá»…u". Má»™t cÃº click nháº§m lÃ  má»™t vÃ­ dá»¥ Ä‘iá»ƒn hÃ¬nh cá»§a nhiá»…u, vÃ¬ nÃ³ khÃ´ng pháº£n Ã¡nh Ä‘Ãºng Ã½ Ä‘á»‹nh hay sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 78: Lá»£i Ã­ch cá»§a viá»‡c sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘a nhiá»‡m (multi-task) nhÆ° Neural Multi-Task Recommendation lÃ  gÃ¬?</p><ul class="options"><li>A. MÃ´ hÃ¬nh trá»Ÿ nÃªn Ä‘Æ¡n giáº£n hÆ¡n.</li><li class="correct-answer">B. Viá»‡c há»c má»™t nhiá»‡m vá»¥ cÃ³ thá»ƒ cáº£i thiá»‡n káº¿t quáº£ cho cÃ¡c nhiá»‡m vá»¥ khÃ¡c thÃ´ng qua viá»‡c chia sáº» biá»ƒu diá»…n (shared representation).</li><li>C. Giáº£m lÆ°á»£ng dá»¯ liá»‡u cáº§n thiáº¿t.</li><li>D. KhÃ´ng cáº§n hÃ m lá»—i.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong há»c Ä‘a nhiá»‡m, cÃ¡c nhiá»‡m vá»¥ liÃªn quan (vÃ­ dá»¥: dá»± Ä‘oÃ¡n click, dá»± Ä‘oÃ¡n thÃªm vÃ o giá», dá»± Ä‘oÃ¡n mua) Ä‘Æ°á»£c há»c cÃ¹ng nhau. MÃ´ hÃ¬nh cÃ³ thá»ƒ há»c Ä‘Æ°á»£c cÃ¡c biá»ƒu diá»…n áº©n tá»•ng quÃ¡t vÃ  máº¡nh máº½ hÆ¡n báº±ng cÃ¡ch táº­n dá»¥ng tÃ­n hiá»‡u tá»« táº¥t cáº£ cÃ¡c nhiá»‡m vá»¥, giÃºp cáº£i thiá»‡n hiá»‡u suáº¥t chung.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 79: Trong WMF, tham sá»‘ `Î±` (alpha) kiá»ƒm soÃ¡t Ä‘iá»u gÃ¬?</p><ul class="options"><li>A. Tá»‘c Ä‘á»™ há»c.</li><li class="correct-answer">B. Tá»‘c Ä‘á»™ tÄƒng cá»§a Ä‘á»™ tin cáº­y so vá»›i táº§n suáº¥t tÆ°Æ¡ng tÃ¡c.</li><li>C. Sá»‘ chiá»u cá»§a vector áº©n.</li><li>D. Má»©c Ä‘á»™ hiá»‡u chá»‰nh.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong cÃ´ng thá»©c `c_ui = 1 + Î± * r_ui`, `Î±` quyáº¿t Ä‘á»‹nh má»©c Ä‘á»™ quan trá»ng cá»§a táº§n suáº¥t (`r_ui`). `Î±` lá»›n cÃ³ nghÄ©a lÃ  cÃ¡c tÆ°Æ¡ng tÃ¡c láº·p láº¡i nhiá»u láº§n sáº½ cÃ³ Ä‘á»™ tin cáº­y cao hÆ¡n ráº¥t nhiá»u so vá»›i cÃ¡c tÆ°Æ¡ng tÃ¡c chá»‰ xáº£y ra má»™t láº§n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 80: MÃ´ hÃ¬nh nÃ o KHÃ”NG Ä‘Æ°á»£c Ä‘á» cáº­p trong slide 14?</p><ul class="options"><li>A. Neural matrix factorization</li><li>B. Deep matrix factorization</li><li class="correct-answer">C. Weighted matrix factorization</li><li>D. Cáº£ A vÃ  B Ä‘á»u Ä‘Æ°á»£c Ä‘á» cáº­p.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 14 chá»‰ liá»‡t kÃª "Neural matrix factorization" vÃ  "Deep matrix factorization" lÃ m vÃ­ dá»¥ vá» cÃ¡c phÆ°Æ¡ng phÃ¡p deep learning cho CF. Weighted MF lÃ  má»™t mÃ´ hÃ¬nh khÃ¡c, Ä‘Æ°á»£c giá»›i thiá»‡u á»Ÿ pháº§n sau.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 81: Sá»± khÃ¡c biá»‡t chÃ­nh trong Ä‘áº§u vÃ o cá»§a DMF (slide 26) so vá»›i NeuMF (slide 21, 23) lÃ  gÃ¬?</p><ul class="options"><li class="correct-answer">A. DMF láº¥y toÃ n bá»™ vector tÆ°Æ¡ng tÃ¡c cá»§a user/item lÃ m Ä‘áº§u vÃ o, trong khi NeuMF láº¥y ID (dÆ°á»›i dáº¡ng one-hot) lÃ m Ä‘áº§u vÃ o.</li><li>B. NeuMF láº¥y toÃ n bá»™ vector tÆ°Æ¡ng tÃ¡c, DMF láº¥y ID.</li><li>C. Cáº£ hai Ä‘á»u láº¥y ID lÃ m Ä‘áº§u vÃ o.</li><li>D. Cáº£ hai Ä‘á»u láº¥y toÃ n bá»™ vector tÆ°Æ¡ng tÃ¡c lÃ m Ä‘áº§u vÃ o.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 26 cho tháº¥y Ä‘áº§u vÃ o cá»§a DMF lÃ  cÃ¡c cá»™t/hÃ ng tá»« "Interaction Matrix". NgÆ°á»£c láº¡i, slide 21 vÃ  23 cho tháº¥y Ä‘áº§u vÃ o cá»§a NeuMF lÃ  "vector one-hot mÃ£ hÃ³a Ä‘á»‹nh danh", tá»©c lÃ  ID.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 82: Trong mÃ´ hÃ¬nh I2E (slide 44), hÃ m lá»—i `L_I` vÃ  `L_E` Ä‘á»u lÃ  dáº¡ng cross-entropy. Äiá»u nÃ y ngá»¥ Ã½ cÃ¡c giÃ¡ trá»‹ dá»± Ä‘oÃ¡n `x_hat` vÃ  `y_hat` Ä‘Æ°á»£c coi lÃ  gÃ¬?</p><ul class="options"><li>A. CÃ¡c giÃ¡ trá»‹ rating tá»« 1 Ä‘áº¿n 5.</li><li class="correct-answer">B. CÃ¡c xÃ¡c suáº¥t (giÃ¡ trá»‹ trong khoáº£ng [0, 1]).</li><li>C. CÃ¡c giÃ¡ trá»‹ nguyÃªn.</li><li>D. CÃ¡c giÃ¡ trá»‹ khÃ´ng bá»‹ cháº·n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> HÃ m lá»—i cross-entropy Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘o lÆ°á»ng sá»± khÃ¡c biá»‡t giá»¯a hai phÃ¢n phá»‘i xÃ¡c suáº¥t. Viá»‡c sá»­ dá»¥ng nÃ³ cho tháº¥y Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh (sau hÃ m sigmoid) Ä‘Æ°á»£c diá»…n giáº£i nhÆ° lÃ  xÃ¡c suáº¥t cá»§a má»™t hÃ nh vi (implicit hoáº·c explicit) xáº£y ra.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 83: Trong Naive Bayes cho CF, xÃ¡c suáº¥t `P(ruk|ruj = vs)` Ä‘Æ°á»£c tÃ­nh nhÆ° tháº¿ nÃ o tá»« táº­p dá»¯ liá»‡u huáº¥n luyá»‡n?</p><ul class="options"><li>A. Báº±ng sá»‘ láº§n user `u` rate item `k`.</li><li class="correct-answer">B. Báº±ng cÃ¡ch Ä‘áº¿m trong táº­p huáº¥n luyá»‡n, trong sá»‘ táº¥t cáº£ cÃ¡c user Ä‘Ã£ rate item `j` vá»›i giÃ¡ trá»‹ `vs`, cÃ³ bao nhiÃªu pháº§n trÄƒm trong sá»‘ há» cÅ©ng rate item `k` vá»›i giÃ¡ trá»‹ `vk`.</li><li>C. Báº±ng Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a item `k` vÃ  `j`.</li><li>D. Báº±ng 1.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> ÄÃ¢y lÃ  cÃ¡ch Æ°á»›c lÆ°á»£ng xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n báº±ng táº§n suáº¥t tÆ°Æ¡ng Ä‘á»‘i tá»« dá»¯ liá»‡u. Ta sáº½ lá»c ra táº¥t cáº£ cÃ¡c user thá»a mÃ£n Ä‘iá»u kiá»‡n (`ruj = vs`) vÃ  sau Ä‘Ã³ tÃ­nh táº§n suáº¥t cá»§a `ruk` trong táº­p con Ä‘Ã³.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 84: Má»™t háº¡n cháº¿ cá»§a BPR lÃ  gÃ¬?</p><ul class="options"><li>A. NÃ³ khÃ´ng thá»ƒ xá»­ lÃ½ dá»¯ liá»‡u implicit.</li><li>B. NÃ³ yÃªu cáº§u dá»¯ liá»‡u pháº£i dÃ y Ä‘áº·c.</li><li class="correct-answer">C. NÃ³ bá» qua thÃ´ng tin vá» Ä‘á»™ lá»›n cá»§a sá»± khÃ¡c biá»‡t (vÃ­ dá»¥: thÃ­ch item A hÆ¡n B má»™t chÃºt so vá»›i thÃ­ch A hÆ¡n B ráº¥t nhiá»u).</li><li>D. NÃ³ khÃ´ng thá»ƒ Ä‘Æ°á»£c cÃ¡ nhÃ¢n hÃ³a.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> BPR chá»‰ quan tÃ¢m Ä‘áº¿n thá»© tá»± (A > B). NÃ³ khÃ´ng phÃ¢n biá»‡t giá»¯a trÆ°á»ng há»£p (rating A=5, rating B=4.9) vÃ  (rating A=5, rating B=1). Cáº£ hai Ä‘á»u Ä‘Æ°á»£c coi lÃ  A > B. CÃ¡c mÃ´ hÃ¬nh khÃ¡c cÃ³ thá»ƒ cá»‘ gáº¯ng náº¯m báº¯t cáº£ Ä‘á»™ lá»›n cá»§a sá»± Æ°a thÃ­ch.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 85: (Äiá»n Ä‘Ã¡p Ã¡n) Trong mÃ´ hÃ¬nh GMF, náº¿u vector `pu = [0.1, 0.8]` vÃ  `qi = [0.5, 0.2]`, thÃ¬ káº¿t quáº£ cá»§a phÃ©p `pu âŠ™ qi` lÃ  vector nÃ o?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">[0.05, 0.16]</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> PhÃ©p nhÃ¢n theo tá»«ng pháº§n tá»­ (element-wise product) sáº½ lÃ : `[0.1 * 0.5, 0.8 * 0.2] = [0.05, 0.16]`.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 86: Viá»‡c sá»­ dá»¥ng chung cÃ¡c NCF Unit trong mÃ´ hÃ¬nh Neural Multi-Task (slide 38) thá»ƒ hiá»‡n khÃ¡i niá»‡m gÃ¬ trong Deep Learning?</p><ul class="options"><li>A. Dropout</li><li class="correct-answer">B. Chia sáº» tham sá»‘ (Parameter Sharing)</li><li>C. Batch Normalization</li><li>D. Convolution</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ cho tháº¥y cÃ¡c User Embedding vÃ  Item Embedding Ä‘Æ°á»£c chia sáº» vÃ  sá»­ dá»¥ng bá»Ÿi táº¥t cáº£ cÃ¡c "NCF Unit" cho cÃ¡c nhiá»‡m vá»¥ khÃ¡c nhau. ÄÃ¢y lÃ  má»™t hÃ¬nh thá»©c chia sáº» tham sá»‘, giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c biá»ƒu diá»…n tá»•ng quÃ¡t hÆ¡n vÃ  giáº£m nguy cÆ¡ overfitting.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 87: Táº¡i sao dá»¯ liá»‡u explicit láº¡i Ä‘Æ°á»£c coi lÃ  "quÃ½ giÃ¡"?</p><ul class="options"><li>A. VÃ¬ nÃ³ cÃ³ ráº¥t nhiá»u.</li><li class="correct-answer">B. VÃ¬ nÃ³ lÃ  má»™t tÃ­n hiá»‡u ráº¥t máº¡nh vÃ  rÃµ rÃ ng vá» sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng.</li><li>C. VÃ¬ nÃ³ dá»… thu tháº­p.</li><li>D. VÃ¬ nÃ³ khÃ´ng cÃ³ nhiá»…u.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Theo slide 27, dá»¯ liá»‡u explicit "thá»ƒ hiá»‡n sá»Ÿ thÃ­ch cá»§a user". Má»™t Ä‘Ã¡nh giÃ¡ 5 sao lÃ  má»™t chá»‰ bÃ¡o vá» sá»± yÃªu thÃ­ch máº¡nh máº½ hÆ¡n nhiá»u so vá»›i má»™t cÃº click (cÃ³ thá»ƒ lÃ  do tÃ² mÃ² hoáº·c nháº§m láº«n).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 88: HÃ m lá»—i cá»§a BPR Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a báº±ng phÆ°Æ¡ng phÃ¡p nÃ o?</p><ul class="options"><li>A. Giáº£i phÆ°Æ¡ng trÃ¬nh trá»±c tiáº¿p.</li><li class="correct-answer">B. CÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn gradient, nhÆ° Stochastic Gradient Descent (SGD).</li><li>C. K-Means.</li><li>D. Thuáº­t toÃ¡n di truyá»n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 35 trÃ¬nh bÃ y cÃ¡c cÃ´ng thá»©c cáº­p nháº­t tham sá»‘ (Ä‘áº¡o hÃ m cá»§a hÃ m lá»—i), Ä‘Ã¢y lÃ  dáº¥u hiá»‡u cá»§a viá»‡c sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a dá»±a trÃªn gradient nhÆ° SGD.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 89: Trong mÃ´ hÃ¬nh I2E, táº§ng "Concatenation" (slide 40) ngay sau "Implicit Layer" lÃ m gÃ¬?</p><ul class="options"><li>A. TÃ­nh tÃ­ch vÃ´ hÆ°á»›ng.</li><li class="correct-answer">B. GhÃ©p ná»‘i Ä‘áº§u ra tá»« mÃ´ hÃ¬nh implicit vá»›i vector one-hot cá»§a item/user.</li><li>C. Ãp dá»¥ng hÃ m ReLU.</li><li>D. TÃ­nh toÃ¡n hÃ m lá»—i.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ trÃªn slide 40 cho tháº¥y táº§ng "Implicit Layer" (Ä‘áº¡i diá»‡n cho `Ï†^I`) vÃ  táº§ng "Implicit Target" (Ä‘áº¡i diá»‡n cho ITE-one hot) cÃ¹ng Ä‘Æ°á»£c Ä‘Æ°a vÃ o táº§ng "Concatenation" trÆ°á»›c khi vÃ o cÃ¡c lá»›p ITE tiáº¿p theo. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  nÃ³ káº¿t há»£p biá»ƒu diá»…n há»c Ä‘Æ°á»£c tá»« nhiá»‡m vá»¥ implicit vá»›i thÃ´ng tin Ä‘á»‹nh danh gá»‘c.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 90: Äiá»ƒm yáº¿u cá»§a phÆ°Æ¡ng phÃ¡p CF dá»±a trÃªn CÃ¢y quyáº¿t Ä‘á»‹nh so vá»›i cÃ¡c mÃ´ hÃ¬nh phÃ¢n rÃ£ ma tráº­n lÃ  gÃ¬?</p><ul class="options"><li>A. KhÃ´ng thá»ƒ xá»­ lÃ½ dá»¯ liá»‡u rá»i ráº¡c.</li><li class="correct-answer">B. KhÃ´ng chia sáº» Ä‘Æ°á»£c thÃ´ng tin giá»¯a cÃ¡c mÃ´ hÃ¬nh cho cÃ¡c item khÃ¡c nhau, vÃ  khÃ´ng há»c Ä‘Æ°á»£c biá»ƒu diá»…n áº©n.</li><li>C. LuÃ´n cháº­m hÆ¡n khi dá»± Ä‘oÃ¡n.</li><li>D. KhÃ´ng thá»ƒ xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Má»—i cÃ¢y quyáº¿t Ä‘á»‹nh Ä‘Æ°á»£c xÃ¢y dá»±ng Ä‘á»™c láº­p cho tá»«ng item. ChÃºng khÃ´ng há»c má»™t khÃ´ng gian Ä‘áº·c trÆ°ng áº©n chung cho táº¥t cáº£ user vÃ  item nhÆ° cÃ¡ch mÃ  Matrix Factorization lÃ m. Äiá»u nÃ y lÃ m cho chÃºng khÃ´ng thá»ƒ khÃ¡i quÃ¡t hÃ³a vÃ  chia sáº» thÃ´ng tin má»™t cÃ¡ch hiá»‡u quáº£.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 91: MÃ´ hÃ¬nh nÃ o trong cÃ¡c slide Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ xá»­ lÃ½ ká»‹ch báº£n mÃ  ngÆ°á»i dÃ¹ng cÃ³ cÃ¡c hÃ nh vi theo má»™t trÃ¬nh tá»± tuáº§n tá»±?</p><ul class="options"><li>A. WMF</li><li>B. BPR</li><li class="correct-answer">C. Neural Multi-Task Recommendation vÃ  Implicit to Explicit model</li><li>D. GMF</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Cáº£ Neural Multi-Task Recommendation (slide 38) vÃ  Implicit to Explicit model (slide 40) Ä‘á»u cÃ³ kiáº¿n trÃºc phÃ¢n táº§ng, nÆ¡i Ä‘áº§u ra cá»§a má»™t giai Ä‘oáº¡n (hÃ nh vi cáº¥p tháº¥p) lÃ m Ä‘áº§u vÃ o cho giai Ä‘oáº¡n tiáº¿p theo (hÃ nh vi cáº¥p cao), rÃµ rÃ ng mÃ´ hÃ¬nh hÃ³a tÃ­nh thá»© tá»± vÃ  tuáº§n tá»±.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 92: (Äiá»n Ä‘Ã¡p Ã¡n) HÃ m lá»—i trong hÃ m má»¥c tiÃªu cá»§a I2E (slide 44) lÃ  tá»•ng cÃ³ trá»ng sá»‘ cá»§a hai hÃ m lá»—i `L_I`, `L_E` vÃ  má»™t thÃ nh pháº§n hiá»‡u chá»‰nh `R(u,i)`. Trá»ng sá»‘ cá»§a `L_I` lÃ  gÃ¬?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">Î· (eta)</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> CÃ´ng thá»©c trÃªn slide 44 lÃ  `L = Î· * L_I(...) + L_E(...) + Î» * R(u,i)`. Trá»ng sá»‘ cá»§a `L_I` lÃ  `Î·`.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 93: Táº¡i sao mÃ´ hÃ¬nh GMF Ä‘Æ°á»£c gá»i lÃ  "General" Matrix Factorization?</p><ul class="options"><li>A. VÃ¬ nÃ³ Ã¡p dá»¥ng cho má»i loáº¡i dá»¯ liá»‡u.</li><li class="correct-answer">B. VÃ¬ nÃ³ tá»•ng quÃ¡t hÃ³a mÃ´ hÃ¬nh MF truyá»n thá»‘ng báº±ng cÃ¡ch cho phÃ©p há»c tÆ°Æ¡ng tÃ¡c thÃ´ng qua má»™t máº¡ng nÆ¡-ron (GMF Layer) thay vÃ¬ chá»‰ má»™t phÃ©p tÃ­ch vÃ´ hÆ°á»›ng cá»‘ Ä‘á»‹nh.</li><li>C. VÃ¬ nÃ³ lÃ  mÃ´ hÃ¬nh chung nháº¥t.</li><li>D. VÃ¬ nÃ³ Ä‘Æ°á»£c phÃ¡t minh bá»Ÿi General Electric.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> GMF lÃ  má»™t dáº¡ng tá»•ng quÃ¡t hÃ³a. MF truyá»n thá»‘ng lÃ  má»™t trÆ°á»ng há»£p Ä‘áº·c biá»‡t cá»§a GMF khi táº§ng cuá»‘i cÃ¹ng lÃ  má»™t phÃ©p tÃ­nh tá»•ng Ä‘Æ¡n giáº£n (tÆ°Æ¡ng Ä‘Æ°Æ¡ng tÃ­ch vÃ´ hÆ°á»›ng). Báº±ng cÃ¡ch thÃªm cÃ¡c trá»ng sá»‘ `h` vÃ  hÃ m kÃ­ch hoáº¡t `a_out`, GMF cho phÃ©p mÃ´ hÃ¬nh linh hoáº¡t hÆ¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 94: Trong cÃ´ng thá»©c cáº­p nháº­t SGD cho MF (slide 20), thÃ nh pháº§n `-Î»*w_u` cÃ³ tÃ¡c dá»¥ng gÃ¬?</p><ul class="options"><li>A. TÄƒng Ä‘á»™ lá»›n cá»§a vector `w_u`.</li><li class="correct-answer">B. KÃ©o vector `w_u` vá» gáº§n gá»‘c tá»a Ä‘á»™, chá»‘ng láº¡i viá»‡c cÃ¡c giÃ¡ trá»‹ cá»§a nÃ³ trá»Ÿ nÃªn quÃ¡ lá»›n (hiá»‡u chá»‰nh).</li><li>C. Äáº£m báº£o `w_u` luÃ´n dÆ°Æ¡ng.</li><li>D. TÄƒng tá»‘c Ä‘á»™ há»c.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> ÄÃ¢y chÃ­nh lÃ  Ä‘áº¡o hÃ m cá»§a thÃ nh pháº§n hiá»‡u chá»‰nh L2 (`Î» * ||w_u||^2`) theo `w_u`. Gradient nÃ y luÃ´n hÆ°á»›ng vá» phÃ­a ngÆ°á»£c láº¡i vá»›i `w_u`, do Ä‘Ã³ khi cáº­p nháº­t, nÃ³ sáº½ "co" `w_u` láº¡i má»™t chÃºt, ngÄƒn cháº·n overfitting.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 95: Trong bÃ i toÃ¡n CF, Ä‘Ã¢u lÃ  má»™t vÃ­ dá»¥ vá» dá»¯ liá»‡u "purchas" (mua hÃ ng)?</p><ul class="options"><li class="correct-answer">A. Má»™t ngÆ°á»i dÃ¹ng mua má»™t cuá»‘n sÃ¡ch trÃªn Tiki.</li><li>B. Má»™t ngÆ°á»i dÃ¹ng xem trailer má»™t bá»™ phim.</li><li>C. Má»™t ngÆ°á»i dÃ¹ng click vÃ o má»™t bÃ i bÃ¡o.</li><li>D. Má»™t ngÆ°á»i dÃ¹ng cho má»™t bÃ i hÃ¡t 5 sao.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 27 liá»‡t kÃª "purchas" lÃ  má»™t vÃ­ dá»¥ cá»§a dá»¯ liá»‡u explicit. HÃ nh Ä‘á»™ng mua hÃ ng lÃ  má»™t minh chá»©ng rÃµ rÃ ng vÃ  máº¡nh máº½ cho sá»± quan tÃ¢m vÃ  sá»Ÿ thÃ­ch.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 96: Náº¿u má»™t há»‡ thá»‘ng chá»‰ sá»­ dá»¥ng GMF, nÃ³ sáº½ gáº·p khÃ³ khÄƒn trong viá»‡c náº¯m báº¯t loáº¡i tÆ°Æ¡ng tÃ¡c nÃ o?</p><ul class="options"><li>A. TÆ°Æ¡ng tÃ¡c tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n.</li><li class="correct-answer">B. CÃ¡c tÆ°Æ¡ng tÃ¡c phá»©c táº¡p vÃ  phi tuyáº¿n giá»¯a cÃ¡c thuá»™c tÃ­nh áº©n.</li><li>C. TÆ°Æ¡ng tÃ¡c cá»§a ngÆ°á»i dÃ¹ng má»›i.</li><li>D. TÆ°Æ¡ng tÃ¡c vá»›i cÃ¡c sáº£n pháº©m má»›i.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> GMF Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a cÃ¡c tÆ°Æ¡ng tÃ¡c tuyáº¿n tÃ­nh. Äá»ƒ náº¯m báº¯t cÃ¡c má»‘i quan há»‡ phá»©c táº¡p hÆ¡n, cáº§n Ä‘áº¿n cÃ¡c kiáº¿n trÃºc cÃ³ kháº£ nÄƒng há»c phi tuyáº¿n máº¡nh máº½ hÆ¡n, nhÆ° MLP. ÄÃ¢y lÃ  lÃ½ do NeuMF káº¿t há»£p cáº£ hai.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 97: Theo slide 10, cÃ´ng thá»©c tÃ­nh xÃ¡c suáº¥t háº­u nghiá»‡m trong NaÃ¯ve Bayes dá»±a trÃªn Ä‘á»‹nh lÃ½ nÃ o?</p><ul class="options"><li>A. Äá»‹nh lÃ½ giá»›i háº¡n trung tÃ¢m</li><li>B. Äá»‹nh lÃ½ Pytago</li><li class="correct-answer">C. Äá»‹nh lÃ½ Bayes</li><li>D. Äá»‹nh lÃ½ cÆ¡ báº£n cá»§a Ä‘áº¡i sá»‘</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> CÃ´ng thá»©c `P(A|B) = P(B|A)P(A) / P(B)` trÃªn slide 10 lÃ  dáº¡ng cÆ¡ báº£n cá»§a Äá»‹nh lÃ½ Bayes, ná»n táº£ng cá»§a thuáº­t toÃ¡n NaÃ¯ve Bayes.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 98: Trong Neural Multi-Task Recommendation, "hÃ nh vi má»¥c tiÃªu" (target behavior) lÃ  gÃ¬?</p><ul class="options"><li>A. HÃ nh vi Ä‘áº§u tiÃªn trong chuá»—i.</li><li class="correct-answer">B. HÃ nh vi cuá»‘i cÃ¹ng trong chuá»—i, thÆ°á»ng lÃ  hÃ nh vi quan trá»ng nháº¥t cáº§n dá»± Ä‘oÃ¡n (vÃ­ dá»¥: mua hÃ ng).</li><li>C. Táº¥t cáº£ cÃ¡c hÃ nh vi Ä‘á»u lÃ  má»¥c tiÃªu.</li><li>D. HÃ nh vi cÃ³ táº§n suáº¥t cao nháº¥t.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 37 nÃ³i: "...trong Ä‘Ã³ hÃ nh vi cuá»‘i cÃ¹ng Ä‘Æ°á»£c gá»i lÃ  hÃ nh vi má»¥c tiÃªu." ÄÃ¢y thÆ°á»ng lÃ  hÃ nh vi cÃ³ giÃ¡ trá»‹ kinh doanh cao nháº¥t mÃ  há»‡ thá»‘ng muá»‘n tá»‘i Æ°u hÃ³a.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 99: Trong WMF, táº¡i sao cÃ¡c tÆ°Æ¡ng tÃ¡c khÃ´ng quan sÃ¡t Ä‘Æ°á»£c (missing data) cÅ©ng Ä‘Æ°á»£c Ä‘Æ°a vÃ o hÃ m lá»—i?</p<ul class="options"><li>A. Äá»ƒ lÃ m cho viá»‡c tÃ­nh toÃ¡n phá»©c táº¡p hÆ¡n.</li><li class="correct-answer">B. VÃ¬ chÃºng cÅ©ng mang thÃ´ng tin. Má»™t tÆ°Æ¡ng tÃ¡c khÃ´ng xáº£y ra cÃ³ thá»ƒ lÃ  má»™t tÃ­n hiá»‡u (yáº¿u) cho tháº¥y sá»± khÃ´ng quan tÃ¢m. WMF gÃ¡n cho chÃºng má»™t Ä‘á»™ tin cáº­y tháº¥p (c_ui=1).</li><li>C. VÃ¬ khÃ´ng thá»ƒ loáº¡i bá» chÃºng.</li><li>D. ÄÃ³ lÃ  má»™t lá»—i trong cÃ´ng thá»©c.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> HÃ m má»¥c tiÃªu cá»§a WMF tÃ­nh tá»•ng trÃªn táº¥t cáº£ cÃ¡c cáº·p (u,i), bao gá»“m cáº£ cÃ¡c cáº·p cÃ³ `r_ui=0` (tá»©c `p_ui=0`). Äá»‘i vá»›i cÃ¡c cáº·p nÃ y, `c_ui=1`, vÃ  mÃ´ hÃ¬nh sáº½ cá»‘ gáº¯ng dá»± Ä‘oÃ¡n giÃ¡ trá»‹ gáº§n 0. Äiá»u nÃ y giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cáº£ tÃ­n hiá»‡u tiÃªu cá»±c (dÃ¹ yáº¿u).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 100: Má»¥c Ä‘Ã­ch cuá»‘i cÃ¹ng cá»§a viá»‡c phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh CF dá»±a trÃªn Deep Learning lÃ  gÃ¬?</p><ul class="options"><li>A. Chá»‰ Ä‘á»ƒ sá»­ dá»¥ng GPU hiá»‡u quáº£ hÆ¡n.</li><li class="correct-answer">B. Äá»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c vÃ  kháº£ nÄƒng biá»ƒu diá»…n cá»§a cÃ¡c há»‡ gá»£i Ã½ báº±ng cÃ¡ch há»c cÃ¡c má»‘i quan há»‡ phá»©c táº¡p, phi tuyáº¿n tá»« dá»¯ liá»‡u.</li><li>C. Äá»ƒ thay tháº¿ hoÃ n toÃ n cÃ¡c mÃ´ hÃ¬nh thá»‘ng kÃª truyá»n thá»‘ng.</li><li>D. Äá»ƒ giáº£m sá»± cáº§n thiáº¿t cá»§a viá»‡c hiá»ƒu dá»¯ liá»‡u.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Sá»©c máº¡nh cá»§a Deep Learning náº±m á»Ÿ kháº£ nÄƒng tá»± Ä‘á»™ng há»c cÃ¡c biá»ƒu diá»…n vÃ  cÃ¡c máº«u phá»©c táº¡p tá»« dá»¯ liá»‡u thÃ´. Trong CF, Ä‘iá»u nÃ y cÃ³ nghÄ©a lÃ  cÃ³ thá»ƒ khÃ¡m phÃ¡ ra cÃ¡c khÃ­a cáº¡nh tinh vi trong sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng vÃ  cÃ¡c Ä‘áº·c tÃ­nh cá»§a sáº£n pháº©m, tá»« Ä‘Ã³ Ä‘Æ°a ra cÃ¡c gá»£i Ã½ chÃ­nh xÃ¡c vÃ  phÃ¹ há»£p hÆ¡n.</p></div></div>

    </div>

</body>
</html>