<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>100 Câu Hỏi Trắc Nghiệm - Gợi Ý Dựa Trên Nội Dung</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 0; padding: 20px; background-color: #f4f4f4; color: #333; }
        .container { max-width: 900px; margin: auto; background: #fff; padding: 30px; border-radius: 8px; box-shadow: 0 0 15px rgba(0,0,0,0.1); }
        header { text-align: center; border-bottom: 2px solid #d9534f; margin-bottom: 30px; padding-bottom: 20px; }
        header h1 { color: #d9534f; margin: 0; }
        header p { margin: 5px 0 0; font-style: italic; color: #555; }
        .question-block { margin-bottom: 25px; padding: 20px; border: 1px solid #ddd; border-left: 5px solid #d9534f; border-radius: 5px; background-color: #fdfdfd; }
        .question-text { font-weight: bold; font-size: 1.1em; margin-bottom: 15px; }
        .options { list-style-type: none; padding-left: 0; }
        .options li { margin-bottom: 10px; padding: 8px; border-radius: 4px; }
        .explanation { margin-top: 15px; padding: 15px; background-color: #e9f7ef; border: 1px solid #a3d9b8; border-radius: 5px; }
        .explanation b { color: #1d7b46; }
        .correct-answer { background-color: #dff0d8; border-left: 3px solid #3c763d; }
        .fill-in-answer { font-weight: bold; color: #3c763d; font-size: 1.2em; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>100 Câu Hỏi Trắc Nghiệm - Gợi Ý Dựa Trên Nội Dung</h1>
            <p>Dựa trên nội dung slide "Gợi ý dựa trên nội dung" - Viện CNTT&TT - ĐHBK Hà Nội</p>
        </header>

        <div class="question-block"><p class="question-text">Câu 1: Theo slide 4, sự khác biệt cơ bản của Gợi ý dựa trên nội dung so với Lọc cộng tác là gì?</p><ul class="options"><li>A. Gợi ý dựa trên nội dung yêu cầu một cộng đồng user lớn để hoạt động.</li><li class="correct-answer">B. Lọc cộng tác không yêu cầu thông tin về item, trong khi Gợi ý dựa trên nội dung lại khai thác thông tin này.</li><li>C. Gợi ý dựa trên nội dung luôn chính xác hơn lọc cộng tác.</li><li>D. Lọc cộng tác chỉ áp dụng cho văn bản, còn gợi ý dựa trên nội dung áp dụng cho mọi loại item.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 4 nêu rõ: "Trong khi các phương pháp lọc cộng tác không yêu cầu bất kỳ thông tin nào về các items: Tuy nhiên, sẽ là hợp lý hơn khi khai thác các thông tin này". Điều này nhấn mạnh sự khác biệt cốt lõi là việc sử dụng "nội dung" của item.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 2: Nhiệm vụ chính của hệ thống gợi ý dựa trên nội dung là gì?</p><ul class="options"><li>A. Tìm những người dùng có sở thích giống nhau.</li><li>B. Dự đoán rating của tất cả user cho tất cả item.</li><li class="correct-answer">C. Học xu hướng sở thích của user và gợi ý các item tương đồng với sở thích đó.</li><li>D. Xây dựng một đồ thị tri thức về các item.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 4, mục "Nhiệm vụ", liệt kê hai nhiệm vụ chính: "Học xu hướng sở thích của user" và "Xác định/gợi ý các items tương đồng với sở thích của user".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 3: "Content" trong Gợi ý dựa trên nội dung thường được áp dụng cho loại tài liệu nào?</p><ul class="options"><li>A. Hình ảnh và video.</li><li class="correct-answer">B. Tài liệu văn bản (text documents) như trang web hoặc tin tức.</li><li>C. Dữ liệu âm thanh.</li><li>D. Dữ liệu địa lý.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 5 khẳng định: "Hầu hết các kỹ thuật gợi ý dựa trên nội dung được áp dụng để gợi ý ‘text documents’."</p></div></div>
        <div class="question-block"><p class="question-text">Câu 4 (Chọn nhiều đáp án): Theo slide 5, nội dung của item có thể được biểu diễn dưới dạng nào?</p><ul class="options"><li class="correct-answer">A. Có cấu trúc (Structured): mỗi item được biểu diễn bởi cùng một tập thuộc tính.</li><li>B. Dạng hình ảnh.</li><li class="correct-answer">C. Phi cấu trúc (Unstructured): mô tả tự do (free-text).</li><li>D. Dạng video.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 5 phân biệt rõ hai dạng biểu diễn: "Có cấu trúc" (với bảng ví dụ về Title, Genre, Author...) và "Phi cấu trúc: mô tả tự do (free-text)".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 5: "User profile" trong gợi ý dựa trên nội dung mô tả điều gì?</p><ul class="options"><li>A. Thông tin cá nhân như tên, tuổi, địa chỉ.</li><li class="correct-answer">B. Những gì user thích (xu hướng/sở thích), thường được biểu diễn bằng các thuộc tính của item.</li><li>C. Lịch sử mua hàng của người dùng.</li><li>D. Danh sách bạn bè của người dùng.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 4 và 6 đều đề cập đến "user profile". Slide 4 định nghĩa nó là "mô tả những gì user thích (xu hướng/sở thích)". Slide 6 minh họa một user profile bằng một bảng có cấu trúc tương tự item, thể hiện các thuộc tính (Genre, Author, Keywords) mà người dùng đó quan tâm.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 6: Kỹ thuật TF-IDF được sử dụng để làm gì trong gợi ý dựa trên nội dung?</p><ul class="options"><li>A. Để tìm những người dùng giống nhau.</li><li class="correct-answer">B. Để đánh giá tầm quan trọng của một từ khóa trong một văn bản và trong toàn bộ tập văn bản.</li><li>C. Để phân loại văn bản.</li><li>D. Để giảm số lượng từ.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 8 giới thiệu TF-IDF là một "Tiêu chuẩn đánh giá" để giải quyết vấn đề "không phải mọi ‘từ’ đều có tầm quan trọng như nhau" khi biểu diễn văn bản. Nó giúp tạo ra các vector trọng số thay vì chỉ đếm từ.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 7: Thành phần TF (Term Frequency) trong TF-IDF đo lường điều gì?</p><ul class="options"><li>A. Mức độ hiếm của một từ trong toàn bộ tài liệu.</li><li class="correct-answer">B. Tần suất xuất hiện của một thuật ngữ trong một văn bản.</li><li>C. Số lượng văn bản chứa một thuật ngữ.</li><li>D. Tầm quan trọng chung của một thuật ngữ.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 8 định nghĩa: "TF: Đo lường tần suất xuất hiện (mật độ) của một thuật ngữ trong 1 văn bản". Slide 9 cũng định nghĩa `TF(i,j)` là "‘term frequency’ của từ khóa i trong văn bản j".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 8: Thành phần IDF (Inverse Document Frequency) có mục đích gì?</p><ul class="options"><li>A. Tăng trọng số của các từ xuất hiện trong nhiều văn bản.</li><li class="correct-answer">B. Giảm trọng số của các thuật ngữ xuất hiện trong nhiều (hoặc tất cả) các văn bản.</li><li>C. Đo lường độ dài của văn bản.</li><li>D. Chuẩn hóa giá trị TF.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 8 nêu rõ mục đích của IDF là "nhằm giảm trọng số của các thuật ngữ xuất hiện trong tất cả các văn bản". Những từ như "the", "a", "is" xuất hiện ở mọi nơi và không mang nhiều ý nghĩa phân biệt.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 9: Theo công thức trên slide 9, nếu một từ khóa `i` xuất hiện trong tất cả `N` văn bản, giá trị `IDF(i)` của nó sẽ là bao nhiêu?</p><ul class="options"><li>A. 1</li><li>B. N</li><li class="correct-answer">C. 0</li><li>D. Vô cùng lớn</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Công thức là `IDF(i) = log(N / n(i))`. Nếu từ khóa `i` xuất hiện trong tất cả `N` văn bản, thì `n(i) = N`. Khi đó, `IDF(i) = log(N / N) = log(1) = 0`. Điều này phản ánh đúng mục đích của IDF: từ nào xuất hiện ở mọi nơi thì không có giá trị thông tin.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 10 (Điền đáp án): Có tổng cộng 1000 văn bản (N=1000). Từ khóa "recommendation" xuất hiện trong 10 văn bản (`n(i)=10`). Tính `IDF("recommendation")` (sử dụng log cơ số 10).</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">2</span></p><p><b>💡 Giải thích:</b> `IDF(i) = log(N / n(i))`. Ta có `IDF = log10(1000 / 10) = log10(100) = 2`.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 11 (Điền đáp án): Trong ví dụ ở slide 10, từ "Antony" xuất hiện 157 lần trong vở "Antony and Cleopatra" và 73 lần trong "Julius Caesar". Đây là giá trị của thành phần nào?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">TF (Term Frequency)</span></p><p><b>💡 Giải thích:</b> Bảng ở slide 10 có tiêu đề "Term frequency". Các con số trong bảng là số lần đếm (count) của mỗi từ trong mỗi văn bản, chính là giá trị TF thô.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 12: Tại sao trong bảng TF-IDF (slide 11), giá trị của "Caesar" trong "Antony and Cleopatra" (8.59) lại cao hơn trong "Julius Caesar" (2.54), dù TF thô của nó thấp hơn (232 so với 227)?</p><ul class="options"><li class="correct-answer">A. Do việc chuẩn hóa độ dài văn bản khi tính TF, vở "Antony and Cleopatra" có thể ngắn hơn đáng kể.</li><li>B. Do lỗi tính toán trong slide.</li><li>C. Vì IDF của từ "Caesar" cao hơn khi xét trong "Antony and Cleopatra".</li><li>D. Vì "Caesar" là nhân vật phụ trong "Antony and Cleopatra".</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> TF-IDF bị ảnh hưởng bởi cả TF và IDF. Tuy nhiên, một yếu tố quan trọng mà slide 8 đề cập là "chuẩn hóa phải được thực hiện khi tính đến độ dài của văn bản". Nếu vở "Antony and Cleopatra" ngắn hơn nhiều, thì tần suất tương đối (TF đã chuẩn hóa) của từ "Caesar" trong đó sẽ cao hơn, dẫn đến trọng số TF-IDF cuối cùng cao hơn.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 13: "Stop words" là gì?</p><ul class="options"><li>A. Những từ quan trọng nhất.</li><li class="correct-answer">B. Những từ xuất hiện rất phổ biến trong hầu hết mọi văn bản và ít mang ý nghĩa (ví dụ: "a", "the", "on").</li><li>C. Những từ bị cấm.</li><li>D. Những từ sai chính tả.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 12 định nghĩa stop words là "Các từ xuất hiện hầu hết trong mọi văn bản" và cho ví dụ như "a", "the", "on".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 14: Kỹ thuật "Stemming" có mục đích gì?</p><ul class="options"><li>A. Đếm số lượng từ.</li><li>B. Xóa các từ không quan trọng.</li><li class="correct-answer">C. Thay thế các biến thể của một từ bằng từ gốc chung của chúng.</li><li>D. Tìm các cụm từ.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 12 giải thích Stemming là "Nhằm mục đích thay thế các biến thể của các từ bằng từ gốc chung" và cho ví dụ "went" -> "go", "stemming" -> "stem".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 15: Tại sao cần thực hiện các kỹ thuật như loại bỏ stop words và stemming?</p><ul class="options"><li class="correct-answer">B. Để cải thiện không gian vector bằng cách giảm số chiều và giảm nhiễu, giúp các vector biểu diễn trở nên súc tích và có ý nghĩa hơn.</li><li>A. Để làm cho vector dài hơn.</li><li>C. Để tăng tốc độ mạng.</li><li>D. Để tuân thủ các quy định về dữ liệu.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 12 có tiêu đề "Cải thiện không gian vector". Loại bỏ stop words giúp giảm các chiều không cần thiết. Stemming giúp nhóm các từ cùng nghĩa vào một chiều duy nhất. Cả hai đều nhằm mục đích làm cho biểu diễn vector tốt hơn.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 16: Phương pháp nào được sử dụng để đo độ tương đồng giữa các vector item (văn bản)?</p><ul class="options"><li>A. Pearson Correlation</li><li class="correct-answer">B. Cosine Similarity</li><li>C. Jaccard Similarity</li><li>D. Euclidean Distance</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 13 giới thiệu "Độ tương đồng Cosine" là phương pháp để đo "độ tương đồng giữa các vector", tính toán dựa trên góc giữa chúng.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 17 (Điền đáp án): Nếu hai vector văn bản trực giao với nhau (góc 90 độ), độ tương đồng Cosine của chúng là bao nhiêu?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">0</span></p><p><b>💡 Giải thích:</b> Độ tương đồng Cosine được tính bằng cos(θ), với θ là góc giữa hai vector. cos(90°) = 0. Điều này có nghĩa là hai văn bản không có từ khóa chung nào (trong không gian vector TF-IDF).</p></div></div>
        <div class="question-block"><p class="question-text">Câu 18: Công thức Dice coefficient trên slide 7 được dùng để làm gì?</p><ul class="options"><li>A. Để tính TF-IDF.</li><li class="correct-answer">B. Để tính mức độ tương đồng của một item mới với một user dựa trên sự trùng lặp từ khóa.</li><li>C. Để tìm láng giềng gần nhất.</li><li>D. Để cập nhật truy vấn.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 7 giới thiệu cách tiếp cận cơ bản là "Tính mức độ tương đồng của một ‘unseen item’ với một user dựa trên sự trùng lặp từ khóa (e.g. sử dụng Dice coefficient)".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 19: Phương pháp "láng giềng gần nhất" (nearest neighbors) trong gợi ý dựa trên nội dung hoạt động như thế nào?</p><ul class="options"><li>A. Tìm n user láng giềng gần nhất của user hiện tại.</li><li class="correct-answer">B. Tìm n item đã được user đánh giá mà tương đồng nhất với item mục tiêu, sau đó dựa vào đánh giá của user cho các item đó để đưa ra gợi ý.</li><li>C. Tìm n item phổ biến nhất.</li><li>D. Tìm n item có giá rẻ nhất.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 14 mô tả phương pháp này: "Tìm n láng giềng gần nhất trong D của một item i", "Sử dụng các láng giềng này để đánh giá cho i". Ở đây, `D` là tập các item đã được user đánh giá, và "láng giềng" là các item tương tự về mặt nội dung.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 20: Phương pháp Rocchio (slide 15-16) được sử dụng để làm gì?</p><ul class="options"><li>A. Để tính độ tương đồng.</li><li>B. Để xây dựng user profile.</li><li class="correct-answer">C. Để cải thiện truy vấn tìm kiếm dựa trên phản hồi của người dùng (thích/không thích) về các kết quả đã truy xuất.</li><li>D. Để loại bỏ stop words.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 15 giới thiệu Rocchio là một phương pháp "Truy xuất dựa trên truy vấn". Slide 16 mô tả cách nó "Tính toán truy vấn đã sửa đổi Qi+1 từ truy vấn hiện tại Qi" dựa trên tập văn bản được thích (D+) và không được thích (D-).</p></div></div>
        <div class="question-block"><p class="question-text">Câu 21: Trong công thức Rocchio `Qi+1 = α*Qi + β(...) - γ(...)`, tham số `α` có ý nghĩa gì?</p><ul class="options"><li>A. Trọng số cho phản hồi tích cực.</li><li>B. Trọng số cho phản hồi tiêu cực.</li><li class="correct-answer">C. Trọng số cho truy vấn gốc.</li><li>D. Tốc độ học.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 16 giải thích `α`, `β`, `γ` được dùng để "fine-tune" phản hồi, trong đó `α` là "trọng số cho truy vấn gốc". Nó kiểm soát mức độ giữ lại các từ khóa ban đầu của người dùng.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 22: "Pseudo relevance Feedback" (Phản hồi liên quan giả) là gì?</p><ul class="options"><li>A. Yêu cầu người dùng đánh giá tất cả tài liệu.</li><li class="correct-answer">B. Giả sử rằng n tài liệu đầu tiên trong kết quả tìm kiếm là phù hợp, và sử dụng chúng để tự động cải thiện truy vấn.</li><li>C. Tạo ra các phản hồi giả để tấn công hệ thống.</li><li>D. Sử dụng phản hồi từ các chuyên gia.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 17 định nghĩa Pseudo relevance Feedback là "Giả sử rằng n tài liệu đầu tiên phù hợp nhất để truy vấn." Đây là một cách để tự động hóa phương pháp Rocchio mà không cần sự tương tác rõ ràng từ người dùng.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 23: Theo slide 19, đường phân tách trong một bộ phân loại tuyến tính trong không gian 2 chiều có dạng gì?</p><ul class="options"><li>A. Một điểm</li><li>B. Một hình tròn</li><li class="correct-answer">C. Một đường thẳng</li><li>D. Một hình parabol</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 19 mô tả "Bộ phân loại đơn giản trong không gian hai chiều... dạng một đường thẳng phân tách" và cho công thức `w1*x1 + w2*x2 = b`.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 24: Theo slide 21, cây quyết định hoạt động tốt nhất với loại đặc trưng nào?</p><ul class="options"><li class="correct-answer">A. Các đặc trưng "meta" như tên tác giả, thể loại (số lượng ít).</li><li>B. Các vector TF-IDF (số lượng lớn).</li><li>C. Các đặc trưng hình ảnh.</li><li>D. Các đặc trưng âm thanh.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 21 nêu rằng cây quyết định "hoạt động tốt nhất với số lượng đặc trưng ít" và nên "sử dụng các đặc trưng “meta” như tên tác giả, thể loại, ... thay vì TF-IDF."</p></div></div>
        <div class="question-block"><p class="question-text">Câu 25: Một ưu điểm chính của các mô hình quyết định rõ ràng như RIPPER (slide 22) là gì?</p><ul class="options"><li>A. Chúng luôn có độ chính xác cao nhất.</li><li class="correct-answer">B. Các quy tắc quyết định mà chúng tạo ra có thể được sử dụng để giải thích cho các gợi ý.</li><li>C. Chúng không cần dữ liệu huấn luyện.</li><li>D. Chúng hoạt động nhanh nhất.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 22, mục "Ưu điểm chính", nêu rõ: "các quy tắc quyết định được sử dụng làm cơ sở để tạo ra các giải thích cho gợi ý". Một quy tắc như "IF genre=sci-fi AND author=Asimov THEN recommend=YES" rất dễ hiểu.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 26: Trích chọn đặc trưng (Feature Selection) là gì?</p><ul class="options"><li>A. Tạo ra các đặc trưng mới từ các đặc trưng cũ.</li><li class="correct-answer">B. Chọn ra một tập con các đặc trưng có sẵn để cải thiện hiệu suất mô hình.</li><li>C. Gán nhãn cho các đặc trưng.</li><li>D. Mã hóa các đặc trưng.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 23 định nghĩa trích chọn đặc trưng là "quá trình chọn ra một tập con các đặc trưng sẵn có".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 27: Theo Chakrabarti (2002), một chiến lược trích chọn đặc trưng là loại bỏ những từ nào?</p><ul class="options"><li>A. Những từ sai chính tả.</li><li>B. Những từ không có trong từ điển.</li><li class="correct-answer">C. Những từ xuất hiện "quá hiếm" hoặc "quá thường xuyên".</li><li>D. Những danh từ riêng.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 23 trích dẫn chiến lược của Chakrabarti (2002) là "dựa trên tần suất để loại bỏ các từ xuất hiện "quá hiếm" hoặc "quá thường xuyên"".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 28 (Chọn nhiều đáp án): Theo slide 24, các hạn chế của việc chỉ sử dụng từ khóa để gợi ý là gì?</p><ul class="options"><li class="correct-answer">A. Không đánh giá được các yếu tố như tính cập nhật, tính thẩm mỹ, phong cách viết.</li><li class="correct-answer">B. Nội dung có thể quá ngắn để trích xuất từ khóa có ý nghĩa.</li><li class="correct-answer">C. Nội dung có thể không trích xuất tự động được (ví dụ: đa phương tiện).</li><li>D. Luôn yêu cầu một lượng lớn dữ liệu huấn luyện.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 24 liệt kê tất cả các hạn chế này trong mục đầu tiên.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 29: Hạn chế "Chuyên môn hóa quá mức" (Overspecialization) trong gợi ý dựa trên nội dung có nghĩa là gì?</p><ul class="options"><li>A. Hệ thống gợi ý quá nhiều loại sản phẩm khác nhau.</li><li class="correct-answer">B. Hệ thống có xu hướng chỉ đề xuất những item rất giống với những gì người dùng đã thích, làm giảm khả năng khám phá.</li><li>C. Hệ thống đòi hỏi người dùng phải là chuyên gia.</li><li>D. Hệ thống chỉ hoạt động trong một lĩnh vực duy nhất.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 24, mục "Chuyên môn hóa quá mức", giải thích rằng "Các thuật toán có xu hướng đề xuất “các thứ giống nhau”" hoặc "các items mới khá giống nhau". Điều này hạn chế sự đa dạng và tính mới lạ (serendipity) của các gợi ý.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 30: Theo slide 25, tại sao hệ thống dựa trên nội dung thuần túy lại hiếm khi được tìm thấy trong môi trường thương mại?</p><ul class="options"><li>A. Vì chúng quá đắt để xây dựng.</li><li>B. Vì chúng không thể được cá nhân hóa.</li><li class="correct-answer">C. Vì chúng có các hạn chế như chuyên môn hóa quá mức và thường được kết hợp với các phương pháp khác (như lọc cộng tác) để tạo ra hệ thống hybrid tốt hơn.</li><li>D. Vì chúng vi phạm quyền riêng tư.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Dòng cuối cùng của slide 25 kết luận: "Hệ thống dựa trên nội dung thuần túy hiếm khi được tìm thấy trong môi trường thương mại". Điều này ngụ ý rằng các hạn chế đã được thảo luận (overspecialization, cần dữ liệu huấn luyện,...) làm cho chúng không đủ mạnh mẽ khi đứng một mình. Các hệ thống thực tế thường là hybrid.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 31: Để gợi ý "tiểu thuyết giả tưởng cho những người đã từng thích tiểu thuyết giả tưởng" (slide 4), hệ thống cần thông tin gì?</p><ul class="options"><li class="correct-answer">A. Thể loại của các cuốn sách và lịch sử sở thích của người dùng.</li><li>B. Chỉ cần lịch sử mua hàng của người dùng.</li><li>C. Chỉ cần thể loại của các cuốn sách.</li><li>D. Đánh giá của những người dùng khác.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Ví dụ này minh họa cho cốt lõi của gợi ý dựa trên nội dung: kết hợp thông tin về item ("tiểu thuyết giả tưởng" - content) với thông tin về user ("những người đã từng thích" - user profile).</p></div></div>
        <div class="question-block"><p class="question-text">Câu 32: Biểu diễn một cuốn sách bằng các thuộc tính như `Title`, `Genre`, `Author` là ví dụ của loại biểu diễn nội dung nào?</p><ul class="options"><li>A. Phi cấu trúc</li><li class="correct-answer">B. Có cấu trúc</li><li>C. Dựa trên đồ thị</li><li>D. Dựa trên thời gian</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 5 gọi đây là biểu diễn "Có cấu trúc" vì mỗi item đều được mô tả bởi cùng một tập các thuộc tính cố định.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 33: "Item representation" và "User profile" (slide 6) có điểm gì chung trong cách biểu diễn?</p><ul class="options"><li>A. Chúng luôn có cùng số hàng.</li><li class="correct-answer">B. Chúng thường sử dụng cùng một bộ thuộc tính (features) để mô tả.</li><li>C. Chúng chỉ chứa dữ liệu dạng số.</li><li>D. Chúng không có điểm chung.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 6 cho thấy cả hai bảng "Item representation" và "User profile" đều có các cột như `Genre`, `Author`, `Keywords`. Điều này cho phép hệ thống so sánh trực tiếp giữa sở thích của người dùng và đặc điểm của sản phẩm.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 34: (Điền đáp án) Theo slide 7, `keywords(b_j)` mô tả điều gì?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">Một tập các từ khóa mô tả cuốn sách b_j</span></p><p><b>💡 Giải thích:</b> Chú thích bên cạnh công thức trên slide 7 giải thích rõ: "`keywords(b_j)` mô tả Book b_j bởi một tập các keywords".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 35: Tại sao việc biểu diễn từ khóa một cách đơn giản (chỉ đếm) lại gặp vấn đề với "văn bản dài" theo slide 8?</p><ul class="options"><li>A. Vì văn bản dài khó đọc.</li><li class="correct-answer">B. Vì văn bản dài có xu hướng có nhiều từ khóa chung với profile của user một cách ngẫu nhiên, ngay cả khi chúng không thực sự liên quan.</li><li>C. Vì văn bản dài không thể biểu diễn bằng vector.</li><li>D. Vì văn bản dài luôn có TF thấp.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 8 nêu vấn đề "văn bản dài thường dễ trùng lặp với user profile". Một văn bản dài có thể chứa hàng nghìn từ, làm tăng xác suất nó có một vài từ khóa giống với sở thích của người dùng, nhưng điều đó không có nghĩa là chủ đề chính của nó phù hợp.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 36: Việc chuẩn hóa TF theo độ dài văn bản nhằm mục đích gì?</p><ul class="options"><li>A. Để làm cho tất cả các vector có cùng độ dài.</li><li class="correct-answer">B. Để tránh việc các văn bản dài hơn tự động có trọng số TF cao hơn cho các từ chỉ vì chúng dài hơn.</li><li>C. Để tăng trọng số của các văn bản dài.</li><li>D. Để giảm số chiều của vector.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 8 đề cập đến việc "chuẩn hóa phải được thực hiện khi tính đến độ dài của văn bản". Nếu một từ xuất hiện 10 lần trong một văn bản 100 từ thì nó quan trọng hơn nhiều so với việc nó xuất hiện 10 lần trong một văn bản 10000 từ. Chuẩn hóa sẽ phản ánh điều này.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 37: Trong ví dụ TF-IDF ở slide 10-11, không gian vector có bao nhiêu chiều?</p><ul class="options"><li>A. 6</li><li class="correct-answer">B. 7</li><li>C. 10</li><li>D. 11</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 10 ghi chú "Vector v với số chiều |v| = 7". Có 7 từ khóa (hàng) được sử dụng để tạo thành không gian vector: Antony, Brutus, Caesar, Calpurnia, Cleopatra, mercy, worser.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 38: Kỹ thuật nào sau đây giúp giảm số chiều của không gian vector?</p><ul class="options"><li class="correct-answer">A. Loại bỏ "stop words".</li><li>B. Sử dụng Cosine Similarity.</li><li>C. Sử dụng phương pháp Rocchio.</li><li>D. Thêm các đặc trưng mới.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 12, trong mục "Loại bỏ 'stop words'", giải thích rằng việc này giúp làm cho vector bớt "dài và thưa", tức là giảm số chiều (vì mỗi từ là một chiều).</p></div></div>
        <div class="question-block"><p class="question-text">Câu 39: Việc phát hiện cụm từ "United Nations" thay vì chỉ dùng "United" và "Nations" riêng lẻ có lợi ích gì?</p><ul class="options"><li>A. Giảm số lượng từ.</li><li class="correct-answer">B. Nắm bắt được ngữ nghĩa chính xác hơn, vì "United Nations" có một ý nghĩa cụ thể khác với tổng của hai từ riêng lẻ.</li><li>C. Tăng tốc độ tính toán.</li><li>D. Giúp stemming hiệu quả hơn.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 12 đề cập đến việc "Phát hiện các cụm từ dưới dạng thuật ngữ" vì chúng "Mô tả tốt cho một văn bản hơn là chỉ dùng các từ đơn lẻ". Đây là một cách để giải quyết hạn chế về ngữ nghĩa.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 40: (Điền đáp án) Theo slide 13, "Adjusted Cosine Similarity" được tính toán từ ratings nào?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">Ratings gốc đã được trừ đi trung bình đánh giá của người dùng</span></p><p><b>💡 Giải thích:</b> Slide 13 ghi "Trung bình đánh giá của người dùng (r_u), tính toán từ ratings gốc" và công thức sử dụng các thành phần `(r_u,a - r_u)`. Đây chính là rating đã được chuẩn hóa theo trung bình của người dùng.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 41: Trong phương pháp láng giềng gần nhất (slide 14), nếu 4 trong 5 item láng giềng gần nhất của item `i` được user thích, điều này ngụ ý điều gì?</p><ul class="options"><li>A. Item `i` chắc chắn được user thích.</li><li class="correct-answer">B. Có khả năng cao item `i` cũng sẽ được user thích.</li><li>C. Item `i` chắc chắn không được user thích.</li><li>D. Không thể kết luận gì.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 14 đưa ra ví dụ: "4 trong k được thích bởi user đang xem xét => item i cũng có thể được thích bởi user này". Đây là một suy luận dựa trên sự tương đồng, không phải là một sự chắc chắn.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 42: Tại sao phương pháp Rocchio thường chỉ sử dụng các phản hồi tích cực (D+)?</p><ul class="options"><li>A. Vì phản hồi tiêu cực khó thu thập hơn.</li><li class="correct-answer">B. Vì người dùng thường biết rõ họ thích gì hơn là họ không thích gì, do đó phản hồi tích cực có giá trị và đáng tin cậy hơn.</li><li>C. Vì việc tính toán với phản hồi tiêu cực phức tạp hơn.</li><li>D. Vì phản hồi tích cực luôn nhiều hơn.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 16 kết luận: "Thường chỉ sử dụng các phản hồi tích cực vì chúng có giá trị hơn các phản hồi tiêu cực."</p></div></div>
        <div class="question-block"><p class="question-text">Câu 43: Thách thức chính của phương pháp Rocchio trong thực tế là gì?</p><ul class="options"><li>A. Tốn nhiều bộ nhớ.</li><li class="correct-answer">B. Cần có sự tương tác của người dùng để cung cấp phản hồi, điều mà người dùng thường không muốn làm.</li><li>C. Không thể cập nhật truy vấn.</li><li>D. Chỉ hoạt động với 2 lớp.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 17 nêu rõ thách thức "Cần có sự tương tác của user trong giai đoạn truy xuất". Việc yêu cầu người dùng đánh giá kết quả tìm kiếm là một rào cản lớn đối với trải nghiệm người dùng.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 44: Khi coi gợi ý như bài toán phân loại văn bản (slide 18), "label" của một văn bản là gì?</p><ul class="options"><li>A. Tên tác giả.</li><li class="correct-answer">B. Thích (1) hoặc không thích (0).</li><li>C. Thể loại của văn bản.</li><li>D. ID của văn bản.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 18 giới thiệu cách tiếp cận với "2 lớp: 0/1" và bảng dữ liệu có cột "Label" chứa các giá trị 0 và 1, tương ứng với không thích và thích.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 45: (Điền đáp án) Trong ví dụ ở slide 18, có tổng cộng bao nhiêu văn bản có `Label = 1`?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">3</span></p><p><b>💡 Giải thích:</b> Nhìn vào cột "Label" trong bảng, các Doc-ID 1, 3, 4 có giá trị Label là 1. Vậy có 3 văn bản.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 46: Trong ví dụ ở slide 18, `P(recommender = 1|Label = 1) = 3/3` có nghĩa là gì?</p><ul class="options"><li>A. Tất cả các văn bản đều chứa từ "recommender".</li><li class="correct-answer">B. Trong số các văn bản được gán nhãn "thích" (Label=1), tất cả chúng (3/3) đều chứa từ "recommender".</li><li>C. Có 3 văn bản được gán nhãn "thích".</li><li>D. Tất cả 3 văn bản chứa từ "recommender" đều được gán nhãn "thích".</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Đây là xác suất có điều kiện. Nó tính tần suất của `recommender=1` trong tập con các văn bản có `Label=1`. Có 3 văn bản có Label=1 (Doc-ID 1, 3, 4), và cả 3 văn bản này đều có `recommender=1`.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 47: Một bộ phân loại tuyến tính (slide 19) phân loại một văn bản bằng cách nào?</p><ul class="options"><li>A. Bằng cách tìm láng giềng gần nhất.</li><li class="correct-answer">B. Bằng cách kiểm tra xem vector của văn bản nằm ở phía nào của đường/mặt phẳng phân tách.</li><li>C. Bằng cách duyệt qua một cây quyết định.</li><li>D. Bằng cách tính xác suất Bayes.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 19 giải thích: "Phân loại một văn bản bằng cách kiểm tra `w1*x1 + w2*x2 > b`". Dấu của biểu thức này cho biết điểm dữ liệu nằm ở phía nào của đường thẳng `w1*x1 + w2*x2 = b`.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 48: Hạn chế của việc biểu diễn logic 0/1 (có/không có từ khóa) là gì?</p><ul class="options"><li>A. Quá phức tạp.</li><li class="correct-answer">B. Mất mát thông tin về tần suất xuất hiện của từ khóa.</li><li>C. Không thể áp dụng cho văn bản.</li><li>D. Yêu cầu nhiều bộ nhớ.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 20, trong mục "Cách biểu diễn logic 0/1 đơn giản", có nêu "Mất mát số lượng từ khóa". Một từ xuất hiện 10 lần sẽ được coi là giống với một từ xuất hiện 1 lần, điều này rõ ràng là một sự mất mát thông tin.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 49: Trong cây quyết định cho bài toán gợi ý (slide 21), các nút lá đại diện cho điều gì?</p><ul class="options"><li>A. Một đặc trưng của item.</li><li class="correct-answer">B. Quyết định cuối cùng (thích hoặc không thích).</li><li>C. Một ví dụ thử nghiệm.</li><li>D. Tên tác giả.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 21 nêu rõ: "chỉ có hai lớp xuất hiện tại các nút lá: thích hoặc không thích".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 50: Theo slide 25, một vấn đề mà các phương pháp học trong gợi ý dựa trên nội dung có thể gặp phải là gì?</p><ul class="options"><li>A. Underfitting</li><li class="correct-answer">B. Overfitting</li><li>C. Cold-start</li><li>D. Data sparsity</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 25, trong mục "Danh sách gợi ý chứa quá nhiều mục tương đồng", có ghi: "Một số phương pháp học có xu hướng “overfit”".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 51: (Điền đáp án) Theo slide 23, phương pháp trích chọn đặc trưng dựa trên kiến thức lĩnh vực có thể sử dụng công cụ nào?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">WordNet</span></p><p><b>💡 Giải thích:</b> Slide 23 đề cập đến chiến lược "dựa trên kiến thức lĩnh vực và thông tin từ vựng WordNet (Pazzani và Billsus 1997)".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 52: "Giai đoạn tăng tốc" (ramp-up phase) trong gợi ý dựa trên nội dung đề cập đến vấn đề gì?</p><ul class="options"><li>A. Hệ thống chạy chậm lúc đầu.</li><li class="correct-answer">B. Vẫn cần một lượng dữ liệu huấn luyện ban đầu để học xu hướng của người dùng.</li><li>C. Cần phải cài đặt nhiều phần mềm.</li><li>D. Phải tăng tốc độ CPU.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 24, mục "Đòi hỏi giai đoạn tăng tốc", giải thích rằng hệ thống "Vẫn yêu cầu một số dữ liệu huấn luyện". Mặc dù không cần cộng đồng user, nó vẫn cần dữ liệu về sở thích của chính user đó để bắt đầu hoạt động hiệu quả.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 53: Theo slide 25, điều nào sau đây là một kết luận về Gợi ý dựa trên nội dung?</p><ul class="options"><li>A. Nó yêu cầu cộng đồng user để hoạt động.</li><li class="correct-answer">B. Các kỹ thuật này nhằm mục đích học một mô hình của xu hướng user.</li><li>C. Nó không cần dữ liệu huấn luyện.</li><li>D. Các hệ thống thương mại chủ yếu là dựa trên nội dung thuần túy.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 25 có ghi: "Các phương pháp tiếp cận ở trên nhằm mục đích học một mô hình của xu hướng user dựa trên phản hồi explicite hoặc implicit".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 54: (Điền đáp án) Trong ví dụ ở slide 10, từ `worser` có tần suất (TF) trong vở `Othello` là bao nhiêu?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">1</span></p><p><b>💡 Giải thích:</b> Nhìn vào bảng ở slide 10, tại hàng "worser" và cột "Othello", giá trị là 1.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 55: (Điền đáp án) Trong ví dụ ở slide 10, từ `Caesar` có tần suất (TF) trong vở `The Tempest` là bao nhiêu?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">0</span></p><p><b>💡 Giải thích:</b> Nhìn vào bảng ở slide 10, tại hàng "Caesar" và cột "The Tempest", giá trị là 0.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 56: (Điền đáp án) Trong bảng ở slide 5, `Genre` của cuốn sách "The Night of the Gun" là gì?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">Memoir</span></p><p><b>💡 Giải thích:</b> Trong bảng ở slide 5, hàng "The Night of the Gun", cột "Genre" có giá trị là "Memoir" (Hồi ký).</p></div></div>
        <div class="question-block"><p class="question-text">Câu 57: Trong phương pháp láng giềng gần nhất, việc "Tăng/giảm ngưỡng độ đo tương đồng" (slide 14) có thể giúp giải quyết vấn đề gì?</p><ul class="options"><li>A. Tăng tốc độ hệ thống.</li><li class="correct-answer">B. Ngăn hệ thống gợi ý ra các item mà user đã biết đến (hoặc các item quá giống nhau).</li><li>C. Giảm bộ nhớ yêu cầu.</li><li>D. Tăng độ chính xác dự đoán.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 14 ghi rằng việc này để "ngăn hệ thống gợi ý ra các items mà user đã biết đến". Nếu một item có độ tương đồng quá cao (ví dụ, > 0.99), nó có thể là phiên bản khác của cùng một item. Bằng cách đặt ngưỡng, ta có thể lọc bỏ những trường hợp này.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 58: Phương pháp Rocchio có thể được coi là một dạng của kỹ thuật nào trong học máy?</p><ul class="options"><li>A. Học không giám sát</li><li>B. Học sâu</li><li class="correct-answer">C. Học có giám sát (sử dụng phản hồi làm nhãn)</li><li>D. Học tăng cường</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Rocchio sử dụng các nhãn "thích" (D+) và "không thích" (D-) do người dùng cung cấp để cập nhật mô hình (vector truy vấn). Đây là một dạng của học có giám sát.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 59: Nếu một từ chỉ xuất hiện trong duy nhất một văn bản trong toàn bộ kho dữ liệu, giá trị IDF của nó sẽ như thế nào?</p><ul class="options"><li>A. Bằng 0.</li><li class="correct-answer">B. Đạt giá trị lớn nhất có thể.</li><li>C. Bằng 1.</li><li>D. Âm.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Theo công thức `IDF(i) = log(N / n(i))`, khi `n(i) = 1`, tỉ số `N/n(i)` đạt giá trị lớn nhất là `N`. Do đó, `log(N)` sẽ là giá trị IDF lớn nhất, cho thấy từ đó rất có giá trị trong việc phân biệt văn bản chứa nó.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 60: Hạn chế của việc sử dụng các phương pháp thống kê như Chi-squared (X²) để đánh giá từ khóa (slide 23) là gì?</p><ul class="options"><li class="correct-answer">A. Chúng đánh giá các từ khóa một cách riêng lẻ và độc lập, bỏ qua mối quan hệ và ngữ nghĩa giữa chúng.</li><li>B. Chúng quá chậm để tính toán.</li><li>C. Chúng chỉ hoạt động với số lượng nhỏ từ khóa.</li><li>D. Chúng không thể xếp hạng từ khóa.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 23 nói rằng các phương pháp này "Tốt để đánh giá tầm quan trọng của các đặc trưng riêng lẻ (từ khóa) một cách độc lập". Điều này ngụ ý rằng chúng không xem xét sự kết hợp hay phụ thuộc giữa các từ, ví dụ như "New" và "York" có ý nghĩa hơn khi đi cùng nhau.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 61: (Điền đáp án) Theo slide 12, việc thay thế từ "went" bằng "go" là một ví dụ của kỹ thuật gì?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">Stemming</span></p><p><b>💡 Giải thích:</b> Slide 12 đưa ra ví dụ: `"went" - "go"` trong phần giải thích về "stemming".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 62: Một vector "count vector" (slide 10) biểu diễn một văn bản bằng cách nào?</p><ul class="options"><li>A. Bằng trọng số TF-IDF của các từ.</li><li class="correct-answer">B. Bằng số lần xuất hiện (tần suất thô) của mỗi từ trong từ điển.</li><li>C. Bằng một chuỗi nhị phân 0/1.</li><li>D. Bằng một tập các từ khóa.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 10 giới thiệu "count vector" với bảng dữ liệu chứa số lần đếm trực tiếp của các từ trong mỗi văn bản. Đây là bước đầu tiên trước khi tính toán TF-IDF.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 63: Tại sao "suy luận từ phản hồi ngầm của hành vi user có thể khó khăn" (slide 25)?</p><ul class="options"><li>A. Vì dữ liệu ngầm quá ít.</li><li class="correct-answer">B. Vì hành vi ngầm (ví dụ: click) có thể không phản ánh đúng sự yêu thích, nó có thể do tò mò, nhầm lẫn (nhiễu).</li><li>C. Vì dữ liệu ngầm khó lưu trữ.</li><li>D. Vì không có thuật toán nào cho dữ liệu ngầm.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 25 đưa ra kết luận này. Dữ liệu ngầm (implicit) vốn mơ hồ hơn dữ liệu tường minh (explicit). Một cú click không chắc chắn bằng một đánh giá 5 sao. Việc suy luận ý định thực sự của người dùng từ các hành vi này là một thách thức.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 64: Trong phương pháp Rocchio, nếu người dùng chỉ cung cấp phản hồi tích cực (D+), công thức cập nhật truy vấn sẽ trở thành gì?</p><ul class="options"><li>A. `Qi+1 = α*Qi - γ(...)`</li><li class="correct-answer">B. `Qi+1 = α*Qi + β(...)`</li><li>C. `Qi+1 = α*Qi`</li><li>D. `Qi+1 = β(...) - γ(...)`</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Nếu chỉ có D+, thành phần liên quan đến D- (có hệ số `γ`) sẽ bị loại bỏ khỏi công thức đầy đủ `Qi+1 = α*Qi + β(...) - γ(...)` trên slide 16.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 65: Theo slide 19, phương pháp nào KHÔNG được liệt kê như một phương pháp phân loại tuyến tính khác?</p><ul class="options"><li>A. Naive Bayes</li><li>B. Rocchio</li><li>C. Support vector machines</li><li class="correct-answer">D. K-Nearest Neighbors</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 19, trong mục "Các phương pháp khác", liệt kê: "Phân loại Naive Bayes, phương pháp Rocchio, giải thuật Windrow-Hoff, Support vector machines". K-Nearest Neighbors là một phương pháp dựa trên láng giềng, không phải là một bộ phân loại tuyến tính theo nghĩa này.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 66: (Điền đáp án) Theo slide 18, nếu một văn bản có các từ khóa "recommender" và "intelligent" nhưng không có "learning" và "school", vector biểu diễn logic 0/1 của nó là gì?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">[1, 1, 0, 0]</span></p><p><b>💡 Giải thích:</b> Dựa trên thứ tự các cột trong bảng, vector sẽ là [recommender, intelligent, learning, school]. Với các từ khóa đã cho, vector sẽ là [1, 1, 0, 0].</p></div></div>
        <div class="question-block"><p class="question-text">Câu 67: Một trong những hạn chế của không gian vector là "Không cung cấp thông tin về ngữ nghĩa" (slide 12). Điều này có nghĩa là gì?</p><ul class="options"><li>A. Hệ thống không hiểu được các từ.</li><li class="correct-answer">B. Hệ thống coi các từ "car" và "automobile" là hai chiều hoàn toàn khác nhau, mặc dù chúng đồng nghĩa.</li><li>C. Hệ thống không thể xử lý các câu dài.</li><li>D. Hệ thống chỉ xử lý được danh từ.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Hạn chế về ngữ nghĩa có nghĩa là mô hình túi từ (bag-of-words) không hiểu được mối quan hệ giữa các từ. Các từ đồng nghĩa (synonyms) hay các mối quan hệ phức tạp hơn sẽ bị bỏ qua, mỗi từ được coi là một chiều độc lập.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 68: Nếu hai vector TF-IDF của hai văn bản là giống hệt nhau, độ tương đồng Cosine của chúng là bao nhiêu?</p><ul class="options"><li class="correct-answer">A. 1</li><li>B. 0</li><li>C. -1</li><li>D. 0.5</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Nếu hai vector giống hệt nhau, chúng cùng hướng. Góc giữa chúng là 0 độ. cos(0°) = 1. Điều này cho thấy sự tương đồng tối đa.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 69: (Điền đáp án) Trong ví dụ ở slide 18, `P(learning = 0|Label = 1)` bằng bao nhiêu?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">1/3</span></p><p><b>💡 Giải thích:</b> Có 3 văn bản có `Label=1` (Doc-ID 1, 3, 4). Trong số này, chỉ có Doc-ID 3 có `learning=0`. Vậy xác suất là 1/3.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 70: Lợi thế của gợi ý dựa trên nội dung so với lọc cộng tác trong trường hợp "item cold-start" là gì?</p><ul class="options"><li>A. Không có lợi thế nào.</li><li class="correct-answer">B. Nó có thể gợi ý một item mới ngay khi có mô tả nội dung của nó, không cần chờ người dùng tương tác.</li><li>C. Nó nhanh hơn.</li><li>D. Nó chính xác hơn.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Lọc cộng tác không thể làm gì với một item mới cho đến khi có người dùng đánh giá nó. Ngược lại, gợi ý dựa trên nội dung chỉ cần phân tích "nội dung" của item mới (ví dụ: các từ khóa trong mô tả) và có thể ngay lập tức so sánh nó với hồ sơ sở thích của người dùng để đưa ra gợi ý.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 71: Trong bảng ở slide 5, các giá trị trong cột "Keywords" là ví dụ của loại biểu diễn nội dung nào?</p><ul class="options"><li>A. Có cấu trúc</li><li class="correct-answer">B. Phi cấu trúc (free-text)</li><li>C. Nhị phân</li><li>D. Dạng số</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Cột "Keywords" chứa các chuỗi văn bản tự do, không theo một định dạng cố định nào. Đây là một ví dụ của dữ liệu phi cấu trúc, được dùng để trích xuất các từ khóa.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 72: (Điền đáp án) Theo slide 21, các nút bên trong của cây quyết định được gán nhãn bằng gì?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">Các đặc trưng của item (từ khóa)</span></p><p><b>💡 Giải thích:</b> Slide 21 ghi: "các nút bên trong được gán nhãn bằng các đặc trưng của item (từ khóa)".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 73: Tại sao phương pháp phân loại tuyến tính (slide 19) được gọi là "tuyến tính"?</p><ul class="options"><li>A. Vì nó chạy theo một đường thẳng.</li><li class="correct-answer">B. Vì ranh giới quyết định của nó là một siêu phẳng (đường thẳng trong 2D, mặt phẳng trong 3D,...), là một hàm tuyến tính của các đặc trưng.</li><li>C. Vì nó chỉ hoạt động với dữ liệu tuyến tính.</li><li>D. Vì thời gian chạy của nó là tuyến tính.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Tên gọi "tuyến tính" đề cập đến dạng của hàm phân loại. Hàm `w^T * x = b` là một hàm tuyến tính. Các mô hình này giả định rằng hai lớp có thể được phân tách bằng một ranh giới tuyến tính.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 74: Để xây dựng một user profile từ các item người dùng đã thích, một cách đơn giản là gì?</p><ul class="options"><li>A. Yêu cầu người dùng tự điền.</li><li class="correct-answer">B. Tổng hợp (ví dụ: lấy trung bình hoặc hợp) các vector TF-IDF của các item mà người dùng đã thích.</li><li>C. Sao chép profile của người dùng khác.</li><li>D. Sử dụng thông tin nhân khẩu học.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> User profile là một biểu diễn của sở thích người dùng trong cùng không gian với item. Một cách tự nhiên để xây dựng nó là kết hợp các biểu diễn của những item mà người dùng đã có phản hồi tích cực, ví dụ như tính vector trung bình của chúng.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 75: (Điền đáp án) Nếu một văn bản không chứa từ khóa `i`, giá trị `TF(i,j)` của nó bằng bao nhiêu?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">0</span></p><p><b>💡 Giải thích:</b> Term Frequency đo lường tần suất xuất hiện. Nếu một từ không xuất hiện, tần suất của nó là 0.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 76: (Điền đáp án) Nếu một văn bản không chứa từ khóa `i`, giá trị `TF-IDF(i,j)` của nó bằng bao nhiêu?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">0</span></p><p><b>💡 Giải thích:</b> Vì `TF-IDF(i,j) = TF(i,j) * IDF(i)`, và `TF(i,j) = 0`, nên `TF-IDF(i,j)` cũng sẽ bằng 0.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 77: Theo slide 14, phương pháp láng giềng gần nhất phù hợp để mô hình hóa loại sở thích nào?</p><ul class="options"><li>A. Sở thích dài hạn (long-term interests)</li><li class="correct-answer">B. Sở thích ngắn hạn / các câu chuyện nối tiếp (short-term interests / follow-up stories)</li><li>C. Sở thích của cộng đồng</li><li>D. Sở thích về giá cả</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 14 ghi rằng phương pháp này "Phù hợp để mô hình hóa short-term interests / follow-up stories". Ví dụ, nếu bạn vừa đọc một tin về một sự kiện, hệ thống có thể gợi ý ngay các tin tức liên quan đến sự kiện đó.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 78: Kỹ thuật hậu cắt tỉa (post-pruning) trong thuật toán RIPPER (slide 22) có mục đích gì?</p><ul class="options"><li>A. Để làm cho cây quy tắc lớn hơn.</li><li class="correct-answer">B. Để đơn giản hóa các quy tắc và tránh overfitting bằng cách loại bỏ các điều kiện ít có giá trị.</li><li>C. Để tăng số lượng quy tắc.</li><li>D. Để xử lý dữ liệu thiếu.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Cắt tỉa (pruning) là một kỹ thuật phổ biến trong các mô hình dựa trên cây hoặc quy tắc. Mục đích của nó là loại bỏ các phần của mô hình (cành, lá, điều kiện) không có khả năng tổng quát hóa tốt trên dữ liệu mới, từ đó chống lại hiện tượng overfitting (quá khớp).</p></div></div>
        <div class="question-block"><p class="question-text">Câu 79: Tại sao một item có nội dung "quá ngắn" lại là một thách thức cho gợi ý dựa trên nội dung (slide 24)?</p><ul class="options"><li>A. Vì nó khó lưu trữ.</li><li class="correct-answer">B. Vì có quá ít từ khóa để xây dựng một vector biểu diễn nội dung có ý nghĩa và đáng tin cậy.</li><li>C. Vì người dùng không thích các item có nội dung ngắn.</li><li>D. Vì nó làm chậm hệ thống.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 24 đề cập đến hạn chế "nội dung cũng có thể bị hạn chế / quá ngắn". Các phương pháp dựa trên phân tích văn bản như TF-IDF hoạt động kém hiệu quả khi chỉ có một vài từ để phân tích.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 80: Đâu là một ví dụ về phản hồi "tường minh" (explicit) theo slide 14?</p><ul class="options"><li>A. Thời gian đọc một bài báo.</li><li>B. Số lần click vào một link.</li><li class="correct-answer">C. Đánh giá "thích" hoặc "không thích" một văn bản.</li><li>D. Lướt qua một sản phẩm.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 14, trong mục về tập văn bản D, có phân biệt: "(thích/không thích)" là "Tường minh", trong khi các hành vi khác là "Ngầm ẩn".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 81: (Điền đáp án) Theo slide 25, các kỹ thuật máy học được sử dụng trong gợi ý dựa trên nội dung có cần dữ liệu huấn luyện không?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">Có</span></p><p><b>💡 Giải thích:</b> Slide 25 kết luận: "Tất cả các kỹ thuật học đều yêu cầu một lượng dữ liệu huấn luyện nhất định".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 82: Trong slide 6, `User profile` được tạo ra từ đâu?</p><ul class="options"><li>A. Từ thông tin người dùng tự khai báo.</li><li class="correct-answer">B. Từ các thuộc tính của các item mà người dùng đã thể hiện sự yêu thích trong quá khứ.</li><li>C. Từ các người dùng khác.</li><li>D. Từ các sản phẩm phổ biến.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Bảng `User profile` trên slide 6 chứa các thuộc tính như "Fiction", "Detective, murder, New York", "Brunonia, Barry, Ken Follett". Đây là sự tổng hợp các đặc điểm từ những cuốn sách mà người dùng này có thể đã thích, tạo thành một hồ sơ sở thích.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 83: Theo slide 7, công thức Dice coefficient tính toán sự tương đồng dựa trên cái gì?</p><ul class="options"><li>A. Tần suất của từ khóa.</li><li class="correct-answer">B. Số lượng từ khóa chung và tổng số từ khóa của hai tập hợp.</li><li>C. Góc giữa hai vector.</li><li>D. Khoảng cách Euclid.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Công thức `2 * |keywords(bi) ∩ keywords(bj)| / (|keywords(bi)| + |keywords(bj)|)` cho thấy nó dựa trên kích thước của phần giao (số từ khóa chung) và tổng kích thước của hai tập từ khóa.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 84: Một hạn chế của việc "giảm kích thước" không gian vector bằng cách chỉ giữ lại "Top 100 từ" (slide 12) là gì?</p><ul class="options"><li>A. 100 từ là quá nhiều.</li><li class="correct-answer">B. Có thể vô tình loại bỏ các từ khóa quan trọng nhưng ít phổ biến hơn (từ khóa "ngách").</li><li>C. Tốc độ sẽ bị chậm lại.</li><li>D. Sẽ gây ra overfitting.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Việc chỉ chọn các từ phổ biến nhất có thể làm mất đi các tín hiệu tinh tế và đặc trưng cho các chủ đề phụ hoặc các sở thích "ngách" của người dùng, dẫn đến các gợi ý quá chung chung.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 85: Nếu một user profile được biểu diễn bằng vector `v_user` và một item được biểu diễn bằng `v_item`, độ phù hợp có thể được tính bằng cách nào?</p><ul class="options"><li>A. Bằng tổng của hai vector.</li><li class="correct-answer">B. Bằng độ tương đồng cosine giữa `v_user` và `v_item`.</li><li>C. Bằng số chiều của `v_user`.</li><li>D. Bằng cách so sánh giá trị lớn nhất trong mỗi vector.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Khi cả user và item đều được biểu diễn trong cùng một không gian vector, độ tương đồng cosine là một cách tự nhiên và phổ biến để đo lường mức độ "khớp" giữa sở thích của người dùng và nội dung của sản phẩm.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 86: (Điền đáp án) Theo slide 16, tham số `β` trong công thức Rocchio là trọng số cho cái gì?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">Phản hồi tích cực</span></p><p><b>💡 Giải thích:</b> Slide 16 chú thích rõ: "β trọng số cho phản hồi tích cực".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 87: (Điền đáp án) Theo slide 16, tham số `γ` trong công thức Rocchio là trọng số cho cái gì?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">Phản hồi tiêu cực</span></p><p><b>💡 Giải thích:</b> Slide 16 chú thích rõ: "γ trọng số cho phản hồi tiêu cực".</p></div></div>
        <div class="question-block">
            <p class="question-text">Câu 88: Nếu một hệ thống chỉ gợi ý sách của cùng một tác giả mà người dùng đã đọc, đây là biểu hiện của vấn đề gì?</p>
            <ul class="options">
                <li>A. Cold-start</li>
                <li class="correct-answer">B. Chuyên môn hóa quá mức (Overspecialization)</li>
                <li>C. Dữ liệu thưa (Sparsity)</li>
                <li>D. Khả năng mở rộng (Scalability)</li>
            </ul>
            <div class="explanation">
                <p><b>💡 Giải thích:</b> Đây là một ví dụ kinh điển của "Chuyên môn hóa quá mức" được đề cập ở slide 24. Hệ thống chỉ tìm thấy các item có nội dung quá giống nhau (cùng tác giả) và không giúp người dùng khám phá các tác giả mới hoặc thể loại mới.</p>
            </div>
        </div>
        <div class="question-block"><p class="question-text">Câu 89: Theo Pazzani và Billsus (1997), chiến lược trích chọn đặc trưng có thể dựa vào đâu?</p><ul class="options"><li>A. Tần suất của từ.</li><li class="correct-answer">B. Kiến thức lĩnh vực và thông tin từ vựng từ WordNet.</li><li>C. Phân tích thành phần chính (PCA).</li><li>D. Đánh giá của người dùng.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 23 trích dẫn "[...] dựa trên kiến thức lĩnh vực và thông tin từ vựng WordNet (Pazzani và Billsus 1997)".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 90: "Truy xuất dựa trên truy vấn" (Query-based retrieval) là tên gọi khác của phương pháp nào được đề cập trong slide 15?</p><ul class="options"><li>A. Nearest Neighbors</li><li class="correct-answer">B. Rocchio</li><li>C. Phân loại tuyến tính</li><li>D. Cây quyết định</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 15 giới thiệu "Truy xuất dựa trên truy vấn: Phương pháp Rocchio". Phương pháp này hoạt động bằng cách tinh chỉnh một vector truy vấn.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 91: Tại sao việc "xóa các từ không thuộc lĩnh vực" (slide 12) lại có thể cải thiện không gian vector?</p><ul class="options"><li>A. Vì các từ đó luôn là stop words.</li><li class="correct-answer">B. Vì nó giúp loại bỏ các chiều không liên quan, giảm nhiễu và tập trung vào các thuật ngữ thực sự quan trọng cho lĩnh vực đang xét.</li><li>C. Vì các từ đó khó stemming.</li><li>D. Vì các từ đó có IDF cao.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Đây là một hình thức sử dụng "kiến thức từ vựng" (slide 12) để cải thiện biểu diễn. Ví dụ, trong một hệ thống gợi ý phim, các từ về y học có thể được coi là nhiễu và nên được loại bỏ để mô hình tập trung vào các từ khóa liên quan đến phim ảnh.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 92: (Điền đáp án) Trong phương pháp phân loại xác suất (slide 18), để dự đoán nhãn cho Doc-ID 6, hệ thống cần tính hai xác suất có điều kiện nào?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">P(Label=1 | X) và P(Label=0 | X)</span></p><p><b>💡 Giải thích:</b> Bài toán phân loại nhị phân yêu cầu tính xác suất để văn bản thuộc về mỗi lớp. Hệ thống sẽ tính P(Label=1 | X) và P(Label=0 | X) cho văn bản X (Doc-ID 6), sau đó chọn lớp có xác suất cao hơn làm nhãn dự đoán.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 93: Sự khác biệt giữa phản hồi "ngầm ẩn" và "tường minh" trong Gợi ý dựa trên nội dung là gì?</p><ul class="options"><li>A. Không có sự khác biệt.</li><li class="correct-answer">B. Tường minh là hành động thể hiện rõ ý định (thích/không thích), trong khi ngầm ẩn là hành vi có thể suy ra sở thích (click, xem).</li><li>C. Ngầm ẩn luôn chính xác hơn tường minh.</li><li>D. Tường minh chỉ có giá trị 0/1.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 14 phân biệt hai loại này trong ngữ cảnh tập văn bản D. "Tường minh (thích/không thích)" yêu cầu hành động rõ ràng, trong khi "Ngầm ẩn" có thể được suy ra từ các hành vi khác của người dùng.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 94: Nếu một hệ thống gợi ý dựa trên nội dung hoạt động tốt, user profile của một người thích phim hành động sẽ có độ tương đồng cao với vector của phim nào sau đây?</p><ul class="options"><li>A. Một phim tình cảm lãng mạn.</li><li class="correct-answer">B. Một phim hành động mới ra mắt.</li><li>C. Một bộ phim tài liệu.</li><li>D. Một cuốn sách dạy nấu ăn.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Nguyên tắc của gợi ý dựa trên nội dung là tìm sự tương đồng giữa hồ sơ sở thích của người dùng và nội dung của sản phẩm. Do đó, profile của người thích phim hành động sẽ "khớp" nhất với các phim có nội dung hành động.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 95: (Điền đáp án) Theo slide 22, thuật toán quy nạp RIPPER có kỹ thuật hậu xử lý nào?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">Hậu cắt tỉa (post-pruning)</span></p><p><b>💡 Giải thích:</b> Slide 22 liệt kê "kĩ thuật hậu cắt tỉa- postpruning của RIPPER" là một đặc điểm của phương pháp này.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 96: Tại sao phương pháp gợi ý dựa trên nội dung lại ít bị ảnh hưởng bởi vấn đề "user cold-start" hơn Lọc cộng tác?</p><ul class="options"><li>A. Vì nó không cần dữ liệu người dùng.</li><li class="correct-answer">B. Mặc dù cần dữ liệu, nhưng nó có thể bắt đầu gợi ý ngay khi người dùng mới cung cấp một vài sở thích ban đầu (ví dụ: chọn thể loại yêu thích), không cần đợi họ tương tác với nhiều sản phẩm.</li><li>C. Vì nó sử dụng thông tin từ những người dùng khác.</li><li>D. Vì nó nhanh hơn.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Lọc cộng tác cần tìm những người dùng "giống bạn", điều này là không thể nếu bạn là người dùng mới và chưa có hành vi. Gợi ý dựa trên nội dung chỉ cần biết "bạn thích gì" (ví dụ, bạn nói bạn thích phim kinh dị) và có thể ngay lập tức tìm các phim có thể loại kinh dị để gợi ý.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 97: Theo slide 24, Web 2.0 đã giúp giải quyết vấn đề "giai đoạn tăng tốc" bằng cách nào?</p><ul class="options"><li>A. Bằng cách làm cho internet nhanh hơn.</li><li class="correct-answer">B. Bằng cách cung cấp các nguồn dữ liệu khác (ví dụ: từ mạng xã hội, blog) để học xu hướng của người dùng.</li><li>C. Bằng cách tạo ra các thuật toán mới.</li><li>D. Bằng cách giảm lượng dữ liệu cần thiết.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 24 ghi: "Web 2.0: sử dụng các nguồn khác để học xu hướng user". Sự bùng nổ của nội dung do người dùng tạo ra (user-generated content) đã cung cấp một lượng lớn dữ liệu để xây dựng hồ sơ người dùng mà không cần họ phải đánh giá trực tiếp trên hệ thống.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 98: Mục đích cuối cùng của việc biểu diễn văn bản dưới dạng vector là gì?</p><ul class="options"><li>A. Để lưu trữ hiệu quả hơn.</li><li class="correct-answer">B. Để có thể áp dụng các phép toán đại số tuyến tính và hình học (như tính độ tương đồng, phân loại) trên đó.</li><li>C. Để làm cho văn bản khó đọc hơn.</li><li>D. Để tuân thủ một tiêu chuẩn quốc tế.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Máy tính không thể "hiểu" văn bản trực tiếp. Việc chuyển đổi văn bản thành các vector số (như TF-IDF) cho phép chúng ta sử dụng các công cụ toán học mạnh mẽ để so sánh, phân nhóm, và phân loại chúng, là nền tảng cho các thuật toán gợi ý và truy hồi thông tin.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 99: Trong phương pháp Rocchio, vector "nguyên mẫu" (prototype vector) của một danh mục (ví dụ D+) được tính như thế nào?</p><ul class="options"><li>A. Bằng cách chọn một văn bản ngẫu nhiên từ danh mục.</li><li class="correct-answer">B. Bằng cách tính vector trung bình (centroid) của tất cả các văn bản trong danh mục đó.</li><li>C. Bằng cách ghép nối tất cả các văn bản lại với nhau.</li><li>D. Bằng cách tìm vector có độ dài lớn nhất.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 16, trong mục "Tính toán vectơ nguyên mẫu cho các danh mục này", có một hình ảnh minh họa vector trung bình (D' average vector hay centroid). Đây là cách phổ biến để tạo ra một vector đại diện cho một nhóm các vector.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 100: Theo slide 25, gợi ý dựa trên nội dung có một lợi thế lớn so với lọc cộng tác là gì?</p><ul class="options"><li>A. Luôn chính xác hơn.</li><li>B. Không bao giờ bị overfit.</li><li class="correct-answer">C. Không yêu cầu có cộng đồng người dùng để hoạt động.</li><li>D. Có thể giải thích được tất cả các gợi ý.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Dòng đầu tiên của slide 25 kết luận: "Ngược lại với các phương pháp lọc cộng tác, các kỹ thuật dựa trên nội dung không yêu cầu cộng đồng user để hoạt động". Đây là một lợi thế quan trọng, đặc biệt đối với các hệ thống mới hoặc có lượng người dùng thấp.</p></div></div>

    </div>
</body>
</html>