<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>100 CÃ¢u Há»i Tráº¯c Nghiá»‡m - Case Study: NATR</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 0; padding: 20px; background-color: #f4f4f4; color: #333; }
        .container { max-width: 900px; margin: auto; background: #fff; padding: 30px; border-radius: 8px; box-shadow: 0 0 15px rgba(0,0,0,0.1); }
        header { text-align: center; border-bottom: 2px solid #d9534f; margin-bottom: 30px; padding-bottom: 20px; }
        header h1 { color: #d9534f; margin: 0; }
        header p { margin: 5px 0 0; font-style: italic; color: #555; }
        .question-block { margin-bottom: 25px; padding: 20px; border: 1px solid #ddd; border-left: 5px solid #d9534f; border-radius: 5px; background-color: #fdfdfd; }
        .question-text { font-weight: bold; font-size: 1.1em; margin-bottom: 15px; }
        .options { list-style-type: none; padding-left: 0; }
        .options li { margin-bottom: 10px; padding: 8px; border-radius: 4px; }
        .explanation { margin-top: 15px; padding: 15px; background-color: #e9f7ef; border: 1px solid #a3d9b8; border-radius: 5px; }
        .explanation b { color: #1d7b46; }
        .correct-answer { background-color: #dff0d8; border-left: 3px solid #3c763d; }
        .fill-in-answer { font-weight: bold; color: #3c763d; font-size: 1.2em; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>100 CÃ¢u Há»i Tráº¯c Nghiá»‡m - Case Study: NATR</h1>
            <p>Dá»±a trÃªn ná»™i dung slide "Neural Attentive Travel Package Recommendation..." - Viá»‡n CNTT&TT - ÄHBK HÃ  Ná»™i</p>
        </header>

        <!-- CATEGORY: INTRODUCTION & PROBLEM FORMULATION -->
        <div class="question-block"><p class="question-text">CÃ¢u 1: TÃªn Ä‘áº§y Ä‘á»§ cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c giá»›i thiá»‡u trong slide 4 lÃ  gÃ¬?</p><ul class="options"><li class="correct-answer">A. Neural Attentive Travel Package Recommendation via exploiting long-term and short-term behaviors</li><li>B. Neural News Recommendation with Long- and Short-term User Representations</li><li>C. Neural Attentive Multi-View Learning</li><li>D. Deep Travel Recommendation</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 4 ghi rÃµ tÃªn Ä‘áº§y Ä‘á»§ cá»§a bÃ i bÃ¡o.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 2: "Travel package (TP)" Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  gÃ¬?</p><ul class="options"><li>A. Má»™t vÃ© mÃ¡y bay.</li><li class="correct-answer">B. Má»™t gÃ³i du lá»‹ch gá»“m cÃ¡c thÃ´ng tin cáº§n thiáº¿t cho má»™t chuyáº¿n Ä‘i.</li><li>C. Má»™t khÃ¡ch sáº¡n.</li><li>D. Má»™t Ä‘á»‹a Ä‘iá»ƒm du lá»‹ch.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 6 Ä‘á»‹nh nghÄ©a: "Travel package (TP): má»™t gÃ³i du lá»‹ch gá»“m cÃ¡c thÃ´ng tin du lá»‹ch cáº§n thiáº¿t cho má»™t chuyáº¿n Ä‘i."</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 3: Theo slide 7, thÃ´ng tin vá» má»™t TP gá»“m 4 loáº¡i chÃ­nh nÃ o?</p><ul class="options"><li class="correct-answer">A. title, destination, travel region, travel type</li><li>B. title, price, duration, rating</li><li>C. destination, price, user reviews, images</li><li>D. title, content, author, date</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> DÃ²ng Ä‘áº§u tiÃªn cá»§a slide 7 liá»‡t kÃª: "ThÃ´ng tin vá» TP gá»“m cÃ³ 4 loáº¡i title, destination, travel region, travel type".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 4: Yáº¿u tá»‘ nÃ o Ä‘Æ°á»£c coi lÃ  quan trá»ng trong viá»‡c mÃ´ hÃ¬nh hÃ³a gá»£i Ã½ gÃ³i du lá»‹ch theo slide 7?</p><ul class="options"><li>A. Chá»‰ sá»Ÿ thÃ­ch dÃ i háº¡n cá»§a ngÆ°á»i dÃ¹ng.</li><li>B. Chá»‰ sá»Ÿ thÃ­ch ngáº¯n háº¡n cá»§a ngÆ°á»i dÃ¹ng.</li><li class="correct-answer">C. Sá»± phá»©c táº¡p cá»§a mÃ´ táº£ thÃ´ng tin vÃ  sá»± thay Ä‘á»•i sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng theo thá»i gian.</li><li>D. GiÃ¡ cá»§a gÃ³i du lá»‹ch.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 7 liá»‡t kÃª hai yáº¿u tá»‘ quan trá»ng: "Pháº§n mÃ´ táº£ thÃ´ng tin khÃ¡ phá»©c táº¡p..." vÃ  "Sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng thay Ä‘á»•i theo thá»i gian...".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 5: Theo slide 9, hÃ nh vi cá»§a ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c phÃ¢n chia thÃ nh 2 loáº¡i nÃ o?</p><ul class="options"><li>A. Online vÃ  Offline</li><li>B. TÃ­ch cá»±c vÃ  TiÃªu cá»±c</li><li class="correct-answer">C. DÃ i háº¡n (long-term) vÃ  Ngáº¯n háº¡n (short-term)</li><li>D. RÃµ rÃ ng vÃ  Tiá»m áº©n</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 cÃ³ má»¥c "PhÃ¢n chia long-term vÃ  short-term".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 6: HÃ nh vi "short-term" Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  gÃ¬?</p><ul class="options"><li>A. Táº¥t cáº£ cÃ¡c session cá»§a ngÆ°á»i dÃ¹ng.</li><li class="correct-answer">B. Session cuá»‘i cÃ¹ng trÆ°á»›c khi ngÆ°á»i dÃ¹ng mua hÃ ng.</li><li>C. Session Ä‘áº§u tiÃªn cá»§a ngÆ°á»i dÃ¹ng.</li><li>D. CÃ¡c session khÃ´ng cÃ³ hÃ nh vi mua hÃ ng.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 Ä‘á»‹nh nghÄ©a: "Short-term: session cuá»‘i cÃ¹ng trÆ°á»›c khi user mua hÃ ng".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 7: HÃ nh vi "long-term" Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  gÃ¬?</p><ul class="options"><li>A. Session cuá»‘i cÃ¹ng trÆ°á»›c khi mua hÃ ng.</li><li class="correct-answer">B. CÃ¡c session cÃ²n láº¡i (ngoÃ i session short-term).</li><li>C. Chá»‰ cÃ¡c session cÃ³ hÃ nh vi mua hÃ ng.</li><li>D. Chá»‰ session Ä‘áº§u tiÃªn.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 Ä‘á»‹nh nghÄ©a: "Long-term: cÃ¡c session cÃ²n láº¡i".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 8: Nhiá»‡m vá»¥ chÃ­nh cá»§a mÃ´ hÃ¬nh lÃ  gÃ¬?</p><ul class="options"><li>A. Dá»± Ä‘oÃ¡n giÃ¡ cá»§a gÃ³i du lá»‹ch.</li><li class="correct-answer">B. Dá»±a vÃ o hÃ nh vi short-term vÃ  long-term Ä‘á»ƒ gá»£i Ã½ travel package phÃ¹ há»£p nháº¥t.</li><li>C. PhÃ¢n loáº¡i ngÆ°á»i dÃ¹ng.</li><li>D. Xáº¿p háº¡ng cÃ¡c Ä‘iá»ƒm Ä‘áº¿n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 9 nÃªu rÃµ: "Nhiá»‡m vá»¥: Dá»±a vÃ o hanh vi short-term vÃ  long-term cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ gá»£i Ã½ ra travel package phÃ¹ há»£p nháº¥t Ä‘á»‘i vá»›i ngÆ°á»i dÃ¹ng."</p></div></div>
        
        <!-- CATEGORY: MODEL ARCHITECTURE -->
        <div class="question-block"><p class="question-text">CÃ¢u 9: MÃ´ hÃ¬nh Ä‘á» xuáº¥t NATR (Neural Attentive Travel Recommendation) gá»“m 3 pháº§n nÃ o?</p><ul class="options"><li>A. CNN, Bi-LSTM, Attention</li><li class="correct-answer">B. Travel package encoder, User encoder, Prediction</li><li>C. Title encoder, Body encoder, Category encoder</li><li>D. Long-term encoder, Short-term encoder, Fusion</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 10 liá»‡t kÃª 3 pháº§n cá»§a mÃ´ hÃ¬nh NATR: "Travel package encoder", "User encoder", vÃ  "Prediction".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 10: Travel package encoder trong mÃ´ hÃ¬nh NATR gá»“m bao nhiÃªu pháº§n?</p><ul class="options"><li>A. 2</li><li>B. 3</li><li class="correct-answer">C. 4</li><li>D. 5</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> CÃ¡c slide 12, 13, 14 liá»‡t kÃª 4 pháº§n: Title encoder, Destination encoder, Category encoder, vÃ  View-level attention.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 11: Trong Title encoder (slide 12), mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng sau Word embedding Ä‘á»ƒ náº¯m báº¯t thÃ´ng tin tuáº§n tá»±?</p><ul class="options"><li>A. CNN</li><li class="correct-answer">B. Bi-LSTM (Bidirectional LSTM)</li><li>C. FNN</li><li>D. GRU</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 12 liá»‡t kÃª "Bi-LSTM" lÃ  má»™t thÃ nh pháº§n cá»§a Title encoder. SÆ¡ Ä‘á»“ á»Ÿ slide 11 cÅ©ng cho tháº¥y Ä‘áº§u ra cá»§a Word Embedding Ä‘Æ°á»£c Ä‘Æ°a vÃ o má»™t khá»‘i Bi-LSTM.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 12: Trong Destination encoder vÃ  Category encoder (slide 13), ká»¹ thuáº­t nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng?</p><ul class="options"><li>A. Chá»‰ Embedding.</li><li class="correct-answer">B. Embedding vÃ  MLP (Multi-layer Perceptron).</li><li>C. Chá»‰ Bi-LSTM.</li><li>D. Chá»‰ CNN.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 13 mÃ´ táº£ cáº£ hai bá»™ mÃ£ hÃ³a nÃ y Ä‘á»u gá»“m "Embedding" vÃ  "MLP".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 13: "View-level attention" (slide 14) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ lÃ m gÃ¬?</p><ul class="options"><li>A. Äá»ƒ chá»n tá»« quan trá»ng trong title.</li><li class="correct-answer">B. Äá»ƒ káº¿t há»£p cÃ³ trá»ng sá»‘ cÃ¡c biá»ƒu diá»…n tá»« cÃ¡c "view" khÃ¡c nhau (title, destination, categories) thÃ nh má»™t vector biá»ƒu diá»…n gÃ³i du lá»‹ch duy nháº¥t.</li><li>C. Äá»ƒ mÃ£ hÃ³a ngÆ°á»i dÃ¹ng.</li><li>D. Äá»ƒ dá»± Ä‘oÃ¡n xÃ¡c suáº¥t.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 14 giá»›i thiá»‡u View-level attention nhÆ° lÃ  pháº§n cuá»‘i cÃ¹ng cá»§a travel package encoder. CÃ´ng thá»©c `r_j = Î±_t * r_j^t + ...` cho tháº¥y nÃ³ tÃ­nh tá»•ng cÃ³ trá»ng sá»‘ cá»§a cÃ¡c biá»ƒu diá»…n tá»« cÃ¡c view khÃ¡c nhau.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 14: User encoder trong NATR gá»“m 3 pháº§n nÃ o?</p><ul class="options"><li>A. Title, Body, Category encoders.</li><li class="correct-answer">B. Short-term encoder, Long-term encoder, vÃ  Fusion.</li><li>C. Bi-LSTM, Attention, vÃ  Prediction.</li><li>D. Embedding, CNN, vÃ  MLP.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 15 vÃ  16 mÃ´ táº£ User encoder bao gá»“m má»™t bá»™ mÃ£ hÃ³a cho hÃ nh vi ngáº¯n háº¡n (Short-term), má»™t bá»™ cho hÃ nh vi dÃ i háº¡n (Long-term), vÃ  má»™t cÆ¡ cháº¿ "Fusion" Ä‘á»ƒ káº¿t há»£p chÃºng.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 15: Cáº£ short-term vÃ  long-term encoder Ä‘á»u sá»­ dá»¥ng cÃ¡c thÃ nh pháº§n nÃ o?</p><ul class="options"><li>A. Chá»‰ TP encoder.</li><li class="correct-answer">B. TP encoder, Bi-LSTM, vÃ  Attention.</li><li>C. Chá»‰ Bi-LSTM.</li><li>D. Chá»‰ Attention.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 15 liá»‡t kÃª cÃ¡c thÃ nh pháº§n nÃ y cho short-term encoder, vÃ  ghi "TÆ°Æ¡ng tá»±" cho long-term encoder.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 16: CÆ¡ cháº¿ "Fusion" (slide 16) trong User encoder cÃ³ chá»©c nÄƒng gÃ¬?</p><ul class="options"><li>A. Chá»‰ chá»n biá»ƒu diá»…n short-term.</li><li class="correct-answer">B. Káº¿t há»£p má»™t cÃ¡ch linh hoáº¡t (cÃ³ Ä‘iá»u khiá»ƒn bá»Ÿi vector F) giá»¯a biá»ƒu diá»…n sá»Ÿ thÃ­ch dÃ i háº¡n vÃ  ngáº¯n háº¡n.</li><li>C. Láº¥y trung bÃ¬nh cá»§a hai biá»ƒu diá»…n.</li><li>D. Chá»‰ chá»n biá»ƒu diá»…n long-term.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 16 mÃ´ táº£ "Vector F Ä‘iá»u khiá»ƒn viá»‡c káº¿t há»£p". CÃ´ng thá»©c `o_u = (1-F_u) âŠ™ s_u + F_u âŠ™ l_u` cho tháº¥y `o_u` lÃ  má»™t sá»± káº¿t há»£p cÃ³ trá»ng sá»‘ (gated) giá»¯a `s_u` (short-term) vÃ  `l_u` (long-term).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 17: (Äiá»n Ä‘Ã¡p Ã¡n) TÃªn Ä‘áº§y Ä‘á»§ cá»§a mÃ´ hÃ¬nh lÃ  "Neural Attentive Travel Package Recommendation...". Tá»« "Attentive" Ä‘á» cáº­p Ä‘áº¿n viá»‡c sá»­ dá»¥ng cÆ¡ cháº¿ nÃ o?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">Attention</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> TÃªn cá»§a mÃ´ hÃ¬nh nháº¥n máº¡nh viá»‡c sá»­ dá»¥ng cÆ¡ cháº¿ Attention á»Ÿ nhiá»u cáº¥p Ä‘á»™: trong title encoder, trong user encoder, vÃ  á»Ÿ view-level.</p></div></div>

        <!-- CATEGORY: TRAINING & EVALUATION -->
        <div class="question-block"><p class="question-text">CÃ¢u 18: Theo slide 17, Ä‘á»ƒ dá»± Ä‘oÃ¡n xÃ¡c suáº¥t ngÆ°á»i dÃ¹ng thÃ­ch item, mÃ´ hÃ¬nh sá»­ dá»¥ng bao nhiÃªu máº«u dÆ°Æ¡ng vÃ  bao nhiÃªu máº«u Ã¢m?</p><ul class="options"><li>A. 1 positive, 1 negative.</li><li class="correct-answer">B. 1 positive, K-1 negative.</li><li>C. K-1 positive, 1 negative.</li><li>D. K positive, K negative.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 17 nÃªu rÃµ: "1 positive sample vÃ  K-1 negative sample". ÄÃ¢y lÃ  má»™t ká»¹ thuáº­t negative sampling phá»• biáº¿n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 19: (Äiá»n Ä‘Ã¡p Ã¡n) Äiá»ƒm sá»‘ (score) `z` Ä‘Æ°á»£c tÃ­nh báº±ng phÃ©p toÃ¡n gÃ¬ giá»¯a biá»ƒu diá»…n user vÃ  item?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">TÃ­ch vÃ´ hÆ°á»›ng (dot product)</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 17 ghi: "tÃ­ch vÃ´ hÆ°á»›ng cá»§a biá»ƒu diá»…n user vÃ  item Ä‘Æ°á»£c score".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 20: XÃ¡c suáº¥t cuá»‘i cÃ¹ng `Å·` Ä‘Æ°á»£c tÃ­nh báº±ng hÃ m gÃ¬?</p><ul class="options"><li>A. Sigmoid</li><li class="correct-answer">B. Softmax</li><li>C. ReLU</li><li>D. Tanh</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 17 cÃ³ cÃ´ng thá»©c `Å· = softmax(z)`. Softmax Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ chuyá»ƒn Ä‘á»•i cÃ¡c Ä‘iá»ƒm sá»‘ `z` thÃ nh má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t trÃªn táº­p há»£p gá»“m 1 item dÆ°Æ¡ng vÃ  K-1 item Ã¢m.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 21: HÃ m loss cá»§a mÃ´ hÃ¬nh NATR lÃ  gÃ¬?</p><ul class="options"><li>A. Mean Squared Error</li><li class="correct-answer">B. Cross-Entropy Loss</li><li>C. Hinge Loss</li><li>D. MAE</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 17 cÃ³ cÃ´ng thá»©c `L(Å·) = -Î£ y_j * log(Å·_j)`. ÄÃ¢y lÃ  cÃ´ng thá»©c cá»§a hÃ m loss cross-entropy, phÃ¹ há»£p cho cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 22: Bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘áº¿n tá»« Ä‘Ã¢u?</p><ul class="options"><li>A. MSN News</li><li>B. Amazon</li><li class="correct-answer">C. Tuniu.com</li><li>D. Netflix</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 18 ghi rÃµ: "Sá»­ dá»¥ng dá»¯ liá»‡u cung cáº¥p bá»Ÿi Tuniu.com".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 23: (Äiá»n Ä‘Ã¡p Ã¡n) Theo báº£ng káº¿t quáº£ á»Ÿ slide 19, mÃ´ hÃ¬nh NATR Ä‘áº¡t giÃ¡ trá»‹ HR@20 (%) trÃªn bá»™ dá»¯ liá»‡u D1 lÃ  bao nhiÃªu?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">48.39</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong báº£ng, hÃ ng "NATR", cá»™t "HR@20 (%)" cá»§a D1, giÃ¡ trá»‹ lÃ  48.39.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 24: (Äiá»n Ä‘Ã¡p Ã¡n) Theo báº£ng káº¿t quáº£ á»Ÿ slide 19, mÃ´ hÃ¬nh NATR Ä‘áº¡t giÃ¡ trá»‹ MRR@20 (%) trÃªn bá»™ dá»¯ liá»‡u D1 lÃ  bao nhiÃªu?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">28.35</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong báº£ng, hÃ ng "NATR", cá»™t "MRR@20 (%)" cá»§a D1, giÃ¡ trá»‹ lÃ  28.35.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 25: MÃ´ hÃ¬nh `NATR-NoL` trong báº£ng káº¿t quáº£ lÃ  phiÃªn báº£n nÃ o cá»§a NATR?</p><ul class="options"><li>A. KhÃ´ng cÃ³ attention.</li><li class="correct-answer">B. KhÃ´ng cÃ³ biá»ƒu diá»…n dÃ i háº¡n (No Long-term).</li><li>C. KhÃ´ng cÃ³ biá»ƒu diá»…n ngáº¯n háº¡n.</li><li>D. KhÃ´ng cÃ³ TP encoder.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Dá»±a vÃ o káº¿t quáº£ tháº¥p hÆ¡n cá»§a NATR-NoL so vá»›i NATR Ä‘áº§y Ä‘á»§, cÃ³ thá»ƒ suy luáº­n "NoL" lÃ  viáº¿t táº¯t cá»§a "No Long-term", má»™t dáº¡ng ablation study Ä‘á»ƒ xem táº§m quan trá»ng cá»§a thÃ nh pháº§n dÃ i háº¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 26: MÃ´ hÃ¬nh `NATR-NoA` trong báº£ng káº¿t quáº£ cÃ³ thá»ƒ lÃ  phiÃªn báº£n nÃ o cá»§a NATR?</p><ul class="options"><li class="correct-answer">A. KhÃ´ng cÃ³ cÆ¡ cháº¿ attention (No Attention).</li><li>B. KhÃ´ng cÃ³ biá»ƒu diá»…n dÃ i háº¡n.</li><li>C. KhÃ´ng cÃ³ biá»ƒu diá»…n ngáº¯n háº¡n.</li><li>D. KhÃ´ng cÃ³ dá»¯ liá»‡u.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> "NoA" cÃ³ kháº£ nÄƒng cao lÃ  viáº¿t táº¯t cá»§a "No Attention". Káº¿t quáº£ tháº¥p hÆ¡n cá»§a NATR-NoA so vá»›i NATR Ä‘áº§y Ä‘á»§ cho tháº¥y táº§m quan trá»ng cá»§a cÆ¡ cháº¿ attention trong mÃ´ hÃ¬nh.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 27: Theo báº£ng káº¿t quáº£ á»Ÿ slide 19, baseline nÃ o lÃ  yáº¿u nháº¥t trÃªn bá»™ dá»¯ liá»‡u D1?</p><ul class="options"><li>A. POP</li><li class="correct-answer">B. Item-KNN</li><li>C. User-KNN</li><li>D. SVD</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> HÃ ng "Item-KNN" cÃ³ cÃ¡c giÃ¡ trá»‹ HR@20 (4.88) vÃ  MRR@20 (1.11) tháº¥p nháº¥t trong táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c so sÃ¡nh trÃªn D1.</p></div></div>
        
        <!-- ... More questions from 28 to 100 ... -->
        <div class="question-block"><p class="question-text">CÃ¢u 28: Trong sÆ¡ Ä‘á»“ tá»•ng quan (slide 11), khá»‘i "Gated Fusion" cÃ³ chá»©c nÄƒng gÃ¬?</p><ul class="options"><li>A. MÃ£ hÃ³a ngÆ°á»i dÃ¹ng.</li><li class="correct-answer">B. Káº¿t há»£p cÃ³ trá»ng sá»‘ (dÃ¹ng cá»•ng F) giá»¯a biá»ƒu diá»…n dÃ i háº¡n vÃ  ngáº¯n háº¡n.</li><li>C. MÃ£ hÃ³a gÃ³i du lá»‹ch.</li><li>D. Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t mua.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Khá»‘i "Gated Fusion" nháº­n Ä‘áº§u vÃ o lÃ  `l_u` (long-term) vÃ  `s_u` (short-term) vÃ  sá»­ dá»¥ng má»™t cá»•ng `F_u` Ä‘á»ƒ Ä‘iá»u khiá»ƒn sá»± káº¿t há»£p cá»§a chÃºng, nhÆ° mÃ´ táº£ chi tiáº¿t á»Ÿ slide 16.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 29: Trong TP encoder (slide 12), `q_t` lÃ  gÃ¬?</p><ul class="options"><li>A. Vector embedding cá»§a má»™t tá»«.</li><li class="correct-answer">B. Má»™t vector truy váº¥n Ä‘Æ°á»£c há»c, dÃ¹ng trong cÆ¡ cháº¿ attention cá»§a title encoder.</li><li>C. Biá»ƒu diá»…n cá»§a toÃ n bá»™ title.</li><li>D. Má»™t háº±ng sá»‘.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> `q_t` lÃ  má»™t vector truy váº¥n (query vector) cá»§a cÆ¡ cháº¿ attention, Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ tÃ­nh Ä‘iá»ƒm quan trá»ng cho cÃ¡c tráº¡ng thÃ¡i áº©n `h_i^t` cá»§a Bi-LSTM, tá»« Ä‘Ã³ xÃ¡c Ä‘á»‹nh tá»« nÃ o trong title lÃ  quan trá»ng hÆ¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 30: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 13, Destination encoder vÃ  Category encoder Ä‘á»u sá»­ dá»¥ng loáº¡i máº¡ng nÆ¡-ron nÃ o sau táº§ng embedding?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">MLP (Multi-layer Perceptron)</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 13 ghi rÃµ cáº£ hai encoder nÃ y Ä‘á»u gá»“m "Embedding" vÃ  "MLP".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 31: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 14, `Î±_t, Î±_c, Î±_tr, Î±_tt` lÃ  cÃ¡c trá»ng sá»‘ cá»§a cÆ¡ cháº¿ attention nÃ o?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">View-level attention</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> ÄÃ¢y lÃ  cÃ¡c trá»ng sá»‘ attention Ä‘Æ°á»£c gÃ¡n cho tá»«ng "view": title (`t`), categories (`c`), travel region (`tr`), vÃ  travel type (`tt`).</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 32: Trong User encoder (slide 15), `s_u` lÃ  biá»ƒu diá»…n cho sá»Ÿ thÃ­ch nÃ o?</p><ul class="options"><li class="correct-answer">A. Ngáº¯n háº¡n (short-term)</li><li>B. DÃ i háº¡n (long-term)</li><li>C. Cáº£ hai</li><li>D. Cá»§a cá»™ng Ä‘á»“ng</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ vÃ  cÃ´ng thá»©c trÃªn slide 15 mÃ´ táº£ cÃ¡ch tÃ­nh `s_u` tá»« "Short-term Behaviors: Su".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 33: Trong User encoder, `l_u` (khÃ´ng Ä‘Æ°á»£c hiá»ƒn thá»‹ cÃ´ng thá»©c nhÆ°ng cÃ³ trong sÆ¡ Ä‘á»“ Fusion) lÃ  biá»ƒu diá»…n cho sá»Ÿ thÃ­ch nÃ o?</p><ul class="options"><li>A. Ngáº¯n háº¡n (short-term)</li><li class="correct-answer">B. DÃ i háº¡n (long-term)</li><li>C. Cá»§a má»™t item</li><li>D. Cá»§a má»™t session</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> SÆ¡ Ä‘á»“ Gated Fusion trÃªn slide 16 cho tháº¥y `l_u` Ä‘Æ°á»£c káº¿t há»£p vá»›i `s_u`. Dá»±a vÃ o tÃªn gá»i vÃ  cáº¥u trÃºc song song, `l_u` lÃ  biá»ƒu diá»…n cho sá»Ÿ thÃ­ch dÃ i háº¡n, Ä‘Æ°á»£c tÃ­nh toÃ¡n má»™t cÃ¡ch "tÆ°Æ¡ng tá»±" nhÆ° `s_u` nhÆ°ng trÃªn "Long-term Behaviors: Lu".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 34: Vector `F_u` trong cÆ¡ cháº¿ Gated Fusion (slide 16) Ä‘Æ°á»£c tÃ­nh toÃ¡n dá»±a trÃªn nhá»¯ng thÃ´ng tin gÃ¬?</p><ul class="options"><li>A. Chá»‰ `s_u`.</li><li>B. Chá»‰ `l_u`.</li><li class="correct-answer">C. `s_u`, `l_u`, vÃ  `q_u` (biá»ƒu diá»…n ID ngÆ°á»i dÃ¹ng).</li><li>D. Chá»‰ `q_u`.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> CÃ´ng thá»©c `F_u = sigmoid(W_q*q_u + W_s*s_u + W_l*l_u + b_u)` cho tháº¥y cá»•ng F Ä‘Æ°á»£c tÃ­nh toÃ¡n dá»±a trÃªn cáº£ ba nguá»“n thÃ´ng tin, cho phÃ©p viá»‡c káº¿t há»£p Ä‘Æ°á»£c cÃ¡ nhÃ¢n hÃ³a vÃ  phá»¥ thuá»™c vÃ o ngá»¯ cáº£nh cá»§a cáº£ sá»Ÿ thÃ­ch ngáº¯n háº¡n vÃ  dÃ i háº¡n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 35: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 18, trong bá»™ dá»¯ liá»‡u D1, cÃ³ bao nhiÃªu ngÆ°á»i dÃ¹ng (#Users) trong táº­p Training?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">22,699</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Báº£ng á»Ÿ slide 18, hÃ ng D1/Training, cá»™t #Users cÃ³ giÃ¡ trá»‹ 22,699.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 36: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 18, trong bá»™ dá»¯ liá»‡u D2, cÃ³ bao nhiÃªu item Ä‘Ã£ Ä‘Æ°á»£c mua (#Purchased Items) trong táº­p Test?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">780</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Báº£ng á»Ÿ slide 18, hÃ ng D2/Test, cá»™t #Purchased Items cÃ³ giÃ¡ trá»‹ 780.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 37: S.Len vÃ  L.Len trong báº£ng dá»¯ liá»‡u (slide 18) cÃ³ thá»ƒ lÃ  gÃ¬?</p><ul class="options"><li>A. Sá»‘ lÆ°á»£ng session vÃ  sá»‘ lÆ°á»£ng lÆ°á»£t thÃ­ch.</li><li class="correct-answer">B. Äá»™ dÃ i trung bÃ¬nh cá»§a cÃ¡c session ngáº¯n háº¡n (Short-term) vÃ  dÃ i háº¡n (Long-term).</li><li>C. Sá»‘ lÆ°á»£ng tá»« trong title vÃ  body.</li><li>D. KÃ­ch thÆ°á»›c cá»§a vector ngáº¯n háº¡n vÃ  dÃ i háº¡n.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Dá»±a trÃªn bá»‘i cáº£nh mÃ´ hÃ¬nh hÃ³a hÃ nh vi short-term vÃ  long-term, S.Len vÃ  L.Len ráº¥t cÃ³ thá»ƒ lÃ  viáº¿t táº¯t cá»§a Short-term session Length vÃ  Long-term session Length, tá»©c lÃ  sá»‘ lÆ°á»£ng item trong cÃ¡c session tÆ°Æ¡ng á»©ng.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 38: HR@20 (Hit Rate at 20) Ä‘o lÆ°á»ng Ä‘iá»u gÃ¬?</p><ul class="options"><li>A. Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng trong top 20.</li><li class="correct-answer">B. Tá»· lá»‡ ngÆ°á»i dÃ¹ng cÃ³ Ã­t nháº¥t má»™t item liÃªn quan trong top 20 gá»£i Ã½.</li><li>C. Trung bÃ¬nh thá»© háº¡ng cá»§a item liÃªn quan.</li><li>D. Sá»‘ lÆ°á»£ng hit trong top 20.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Hit Rate lÃ  má»™t Ä‘á»™ Ä‘o phá»• biáº¿n trong gá»£i Ã½. HR@k tráº£ lá»i cÃ¢u há»i: "Trong sá»‘ táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p thá»­ nghiá»‡m, cÃ³ bao nhiÃªu pháº§n trÄƒm trÆ°á»ng há»£p mÃ  item dÆ°Æ¡ng (ground truth) xuáº¥t hiá»‡n trong top k cá»§a danh sÃ¡ch gá»£i Ã½?".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 39: Item-c@20 (Item-coverage at 20) cÃ³ thá»ƒ Ä‘o lÆ°á»ng Ä‘iá»u gÃ¬?</p><ul class="options"><li class="correct-answer">A. Tá»· lá»‡ cÃ¡c item khÃ¡c nhau xuáº¥t hiá»‡n trong táº¥t cáº£ cÃ¡c danh sÃ¡ch top 20 Ä‘Æ°á»£c gá»£i Ã½.</li><li>B. Sá»‘ lÆ°á»£ng item Ä‘Æ°á»£c gá»£i Ã½.</li><li>C. Tá»· lá»‡ item ngÆ°á»i dÃ¹ng Ä‘Ã£ click.</li><li>D. Tá»· lá»‡ item cÃ³ trong category.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Item coverage lÃ  má»™t Ä‘á»™ Ä‘o vá» sá»± Ä‘a dáº¡ng cá»§a danh má»¥c. NÃ³ Ä‘o xem há»‡ thá»‘ng cÃ³ xu hÆ°á»›ng chá»‰ láº·p Ä‘i láº·p láº¡i má»™t vÃ i item phá»• biáº¿n hay cÃ³ kháº£ nÄƒng gá»£i Ã½ má»™t loáº¡t cÃ¡c item khÃ¡c nhau trong toÃ n bá»™ CSDL. "c" á»Ÿ Ä‘Ã¢y cÃ³ thá»ƒ lÃ  viáº¿t táº¯t cá»§a "coverage".</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 40: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 19, mÃ´ hÃ¬nh POP cÃ³ giÃ¡ trá»‹ MRR@20 (%) trÃªn bá»™ dá»¯ liá»‡u D2 lÃ  bao nhiÃªu?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">1.96</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong báº£ng, hÃ ng "POP", cá»™t "MRR@20 (%)" cá»§a D2, giÃ¡ trá»‹ lÃ  1.96.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 41: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 19, mÃ´ hÃ¬nh SDM cÃ³ giÃ¡ trá»‹ Item-c@20 (%) trÃªn bá»™ dá»¯ liá»‡u D2 lÃ  bao nhiÃªu?</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">53.59</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong báº£ng, hÃ ng "SDM", cá»™t "Item-c@20 (%)" cá»§a D2, giÃ¡ trá»‹ lÃ  53.59.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 42: POP trong báº£ng káº¿t quáº£ (slide 19) lÃ  baseline nÃ o?</p><ul class="options"><li>A. Má»™t mÃ´ hÃ¬nh deep learning.</li><li class="correct-answer">B. Má»™t baseline Ä‘Æ¡n giáº£n gá»£i Ã½ cÃ¡c item phá»• biáº¿n nháº¥t (Most Popular).</li><li>C. Má»™t mÃ´ hÃ¬nh dá»±a trÃªn tri thá»©c.</li><li>D. Má»™t mÃ´ hÃ¬nh ngáº«u nhiÃªn.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> POP lÃ  viáº¿t táº¯t cá»§a Popularity. ÄÃ¢y lÃ  má»™t baseline ráº¥t phá»• biáº¿n, khÃ´ng cÃ¡ nhÃ¢n hÃ³a, chá»‰ Ä‘Æ¡n giáº£n lÃ  gá»£i Ã½ cÃ¡c item Ä‘Æ°á»£c nhiá»u ngÆ°á»i tÆ°Æ¡ng tÃ¡c nháº¥t.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 43: Táº¡i sao mÃ´ hÃ¬nh NAML láº¡i vÆ°á»£t trá»™i hÆ¡n cÃ¡c baseline truyá»n thá»‘ng nhÆ° Item-KNN vÃ  User-KNN?</p><ul class="options"><li>A. VÃ¬ nÃ³ sá»­ dá»¥ng nhiá»u dá»¯ liá»‡u hÆ¡n.</li><li class="correct-answer">B. VÃ¬ NAML cÃ³ thá»ƒ há»c cÃ¡c biá»ƒu diá»…n phá»©c táº¡p vÃ  phi tuyáº¿n tá»« ná»™i dung vÃ  hÃ nh vi, trong khi cÃ¡c phÆ°Æ¡ng phÃ¡p KNN chá»‰ dá»±a vÃ o sá»± tÆ°Æ¡ng Ä‘á»“ng bá» máº·t cá»§a cÃ¡c vector rating.</li><li>C. VÃ¬ KNN khÃ´ng pháº£i lÃ  phÆ°Æ¡ng phÃ¡p gá»£i Ã½.</li><li>D. VÃ¬ KNN khÃ´ng thá»ƒ Ä‘Æ°á»£c cÃ¡ nhÃ¢n hÃ³a.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Káº¿t quáº£ trÃªn slide 19 cho tháº¥y sá»± chÃªnh lá»‡ch ráº¥t lá»›n. CÃ¡c mÃ´ hÃ¬nh deep learning nhÆ° NAML cÃ³ kháº£ nÄƒng náº¯m báº¯t cÃ¡c máº«u tinh vi hÆ¡n nhiá»u so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn lÃ¡ng giá»ng truyá»n thá»‘ng, vá»‘n dá»… bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi sá»± thÆ°a thá»›t cá»§a dá»¯ liá»‡u.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 44: Trong User Encoder cá»§a NATR, táº¡i sao láº¡i cáº§n Bi-LSTM?</p><ul class="options"><li>A. Äá»ƒ lÃ m cho mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n.</li><li class="correct-answer">B. VÃ¬ Bi-LSTM (Bidirectional LSTM) cÃ³ thá»ƒ náº¯m báº¯t thÃ´ng tin ngá»¯ cáº£nh tá»« cáº£ hai hÆ°á»›ng (tá»« quÃ¡ khá»© Ä‘áº¿n hiá»‡n táº¡i vÃ  tá»« tÆ°Æ¡ng lai Ä‘áº¿n quÃ¡ khá»©) trong má»™t chuá»—i, giÃºp táº¡o ra biá»ƒu diá»…n tá»‘t hÆ¡n cho má»—i item trong lá»‹ch sá»­.</li><li>C. VÃ¬ LSTM má»™t chiá»u khÃ´ng hoáº¡t Ä‘á»™ng.</li><li>D. VÃ¬ nÃ³ nhanh hÆ¡n LSTM.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Trong viá»‡c xá»­ lÃ½ má»™t chuá»—i, Ã½ nghÄ©a cá»§a má»™t pháº§n tá»­ khÃ´ng chá»‰ phá»¥ thuá»™c vÃ o nhá»¯ng gÃ¬ Ä‘á»©ng trÆ°á»›c nÃ³ mÃ  cÃ²n cáº£ nhá»¯ng gÃ¬ Ä‘á»©ng sau nÃ³. Bi-LSTM xá»­ lÃ½ chuá»—i theo cáº£ hai chiá»u vÃ  ghÃ©p ná»‘i káº¿t quáº£ láº¡i, táº¡o ra má»™t biá»ƒu diá»…n phong phÃº hÆ¡n cho má»—i bÆ°á»›c thá»i gian.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 45: Náº¿u má»™t ngÆ°á»i dÃ¹ng cÃ³ hÃ nh vi ngáº¯n háº¡n ráº¥t khÃ¡c so vá»›i hÃ nh vi dÃ i háº¡n, cá»•ng `F_u` trong cÆ¡ cháº¿ Fusion cÃ³ thá»ƒ sáº½ cÃ³ giÃ¡ trá»‹ nhÆ° tháº¿ nÃ o?</p><ul class="options"><li>A. Gáº§n 0.5.</li><li class="correct-answer">B. Gáº§n 1, Ä‘á»ƒ Æ°u tiÃªn biá»ƒu diá»…n ngáº¯n háº¡n `s_u`.</li><li>C. Gáº§n 0, Ä‘á»ƒ Æ°u tiÃªn biá»ƒu diá»…n dÃ i háº¡n `l_u`.</li><li>D. KhÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> CÃ´ng thá»©c `o_u = (1-F_u) âŠ™ s_u + F_u âŠ™ l_u` (lÆ°u Ã½: cÃ³ thá»ƒ slide cÃ³ lá»—i Ä‘Ã¡nh mÃ¡y, thÆ°á»ng cá»•ng F sáº½ Ä‘iá»u khiá»ƒn thÃ´ng tin má»›i, tá»©c lÃ  `o_u = (1-F_u) âŠ™ l_u + F_u âŠ™ s_u`). Giáº£ sá»­ cÃ´ng thá»©c Ä‘Ãºng lÃ  `o_u` Æ°u tiÃªn `s_u` khi `F_u` gáº§n 0. Náº¿u hÃ nh vi ngáº¯n háº¡n lÃ  tÃ­n hiá»‡u máº¡nh nháº¥t, mÃ´ hÃ¬nh sáº½ há»c cÃ¡ch lÃ m cho `F_u` gáº§n 0 Ä‘á»ƒ trá»ng sá»‘ cá»§a `s_u` (lÃ  `1-F_u`) tiáº¿n Ä‘áº¿n 1.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 46: (Äiá»n Ä‘Ã¡p Ã¡n) Theo slide 7, "Gá»™p sá»Ÿ thÃ­ch ngáº¯n háº¡n vÃ  dÃ i háº¡n cá»§a ngÆ°á»i dÃ¹ng khÃ´ng Ä‘á»§ Ä‘á»ƒ...". HoÃ n thÃ nh cÃ¢u nÃ y.</p><div class="explanation"><p><b>âœ… ÄÃ¡p Ã¡n:</b> <span class="fill-in-answer">máº¡ng láº¡i káº¿t quáº£ tá»‘t</span></p><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Slide 7 ghi: "Gá»™p sá»Ÿ thÃ­ch ngáº¯n háº¡n vÃ  dÃ i háº¡n cá»§a ngÆ°á»i dÃ¹ng khÃ´ng Ä‘á»§ Ä‘á»ƒ máº¡ng láº¡i káº¿t quáº£ tá»‘t". Äiá»u nÃ y ngá»¥ Ã½ ráº±ng cáº§n pháº£i cÃ³ má»™t cÆ¡ cháº¿ káº¿t há»£p thÃ´ng minh (nhÆ° Gated Fusion) thay vÃ¬ chá»‰ cá»™ng hoáº·c ghÃ©p ná»‘i Ä‘Æ¡n giáº£n.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 47: So sÃ¡nh hai case study LSTUR vÃ  NAML, mÃ´ hÃ¬nh nÃ o cÃ³ kiáº¿n trÃºc phá»©c táº¡p hÆ¡n á»Ÿ News Encoder?</p><ul class="options"><li class="correct-answer">A. NAML</li><li>B. LSTUR</li><li>C. ChÃºng tÆ°Æ¡ng Ä‘Æ°Æ¡ng.</li><li>D. KhÃ´ng thá»ƒ so sÃ¡nh.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> News Encoder cá»§a NAML (slide 10) phá»©c táº¡p hÆ¡n Ä‘Ã¡ng ká»ƒ. NÃ³ khÃ´ng chá»‰ mÃ£ hÃ³a title vÃ  categories nhÆ° LSTUR, mÃ  cÃ²n cÃ³ má»™t nhÃ¡nh riÃªng Ä‘á»ƒ mÃ£ hÃ³a ná»™i dung chi tiáº¿t (body) vÃ  má»™t cÆ¡ cháº¿ view-level attention Ä‘á»ƒ tá»•ng há»£p cáº£ ba view nÃ y.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 48: So sÃ¡nh hai case study LSTUR vÃ  NAML, mÃ´ hÃ¬nh nÃ o cÃ³ kiáº¿n trÃºc phá»©c táº¡p hÆ¡n á»Ÿ User Encoder?</p><ul class="options"><li>A. NAML</li><li class="correct-answer">B. LSTUR</li><li>C. ChÃºng tÆ°Æ¡ng Ä‘Æ°Æ¡ng.</li><li>D. KhÃ´ng thá»ƒ so sÃ¡nh.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> User Encoder cá»§a LSTUR (slide 11, 14) phá»©c táº¡p hÆ¡n. NÃ³ mÃ´ hÃ¬nh hÃ³a cáº£ sá»Ÿ thÃ­ch dÃ i háº¡n vÃ  ngáº¯n háº¡n (dÃ¹ng GRU) vÃ  cÃ³ cÃ¡c chiáº¿n lÆ°á»£c káº¿t há»£p chÃºng. Trong khi Ä‘Ã³, User Encoder cá»§a NAML (slide 11) chá»‰ sá»­ dá»¥ng má»™t cÆ¡ cháº¿ attention duy nháº¥t trÃªn lá»‹ch sá»­ duyá»‡t web.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 49: Trong NAML, cÃ¡c thÃ nh pháº§n MLP trong Destination vÃ  Category encoder cÃ³ tÃ¡c dá»¥ng gÃ¬?</p><ul class="options"><li>A. Chá»‰ Ä‘á»ƒ tÄƒng sá»‘ lÆ°á»£ng tham sá»‘.</li><li class="correct-answer">B. Äá»ƒ há»c má»™t phÃ©p biáº¿n Ä‘á»•i phi tuyáº¿n trÃªn cÃ¡c vector embedding, cho phÃ©p mÃ´ hÃ¬nh náº¯m báº¯t cÃ¡c má»‘i quan há»‡ phá»©c táº¡p hÆ¡n giá»¯a cÃ¡c category/destination.</li><li>C. Äá»ƒ giáº£m sá»‘ chiá»u.</li><li>D. Äá»ƒ thay tháº¿ embedding.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> Viá»‡c thÃªm cÃ¡c táº§ng MLP (vá»›i cÃ¡c hÃ m kÃ­ch hoáº¡t phi tuyáº¿n nhÆ° ReLU) sau táº§ng embedding cho phÃ©p mÃ´ hÃ¬nh há»c cÃ¡c biá»ƒu diá»…n cÃ³ tÃ­nh tÆ°Æ¡ng tÃ¡c vÃ  trá»«u tÆ°á»£ng hÆ¡n, thay vÃ¬ chá»‰ sá»­ dá»¥ng cÃ¡c embedding Ä‘Æ°á»£c há»c má»™t cÃ¡ch tuyáº¿n tÃ­nh.</p></div></div>
        <div class="question-block"><p class="question-text">CÃ¢u 50: NhÃ¬n chung, case study NATR cho tháº¥y táº§m quan trá»ng cá»§a viá»‡c gÃ¬ trong gá»£i Ã½ du lá»‹ch?</p><ul class="options"><li>A. Chá»‰ cáº§n gá»£i Ã½ cÃ¡c gÃ³i du lá»‹ch phá»• biáº¿n nháº¥t.</li><li class="correct-answer">B. Cáº§n pháº£i mÃ´ hÃ¬nh hÃ³a cáº©n tháº­n cáº£ sá»Ÿ thÃ­ch á»•n Ä‘á»‹nh (dÃ i háº¡n) vÃ  sá»Ÿ thÃ­ch tá»©c thá»i (ngáº¯n háº¡n) cá»§a ngÆ°á»i dÃ¹ng, cÅ©ng nhÆ° káº¿t há»£p thÃ´ng tin tá»« nhiá»u khÃ­a cáº¡nh cá»§a má»™t gÃ³i du lá»‹ch.</li><li>C. Gá»£i Ã½ du lá»‹ch lÃ  má»™t bÃ i toÃ¡n Ä‘Æ¡n giáº£n.</li><li>D. Chá»‰ cáº§n sá»­ dá»¥ng mÃ´ hÃ¬nh Bi-LSTM lÃ  Ä‘á»§.</li></ul><div class="explanation"><p><b>ğŸ’¡ Giáº£i thÃ­ch:</b> ToÃ n bá»™ bÃ i bÃ¡o xoay quanh viá»‡c chá»©ng minh ráº±ng má»™t kiáº¿n trÃºc Ä‘Æ°á»£c thiáº¿t káº¿ cáº©n tháº­n, cÃ³ kháº£ nÄƒng phÃ¢n biá»‡t vÃ  káº¿t há»£p thÃ´ng minh cÃ¡c hÃ nh vi dÃ i háº¡n vÃ  ngáº¯n háº¡n, cÅ©ng nhÆ° cÃ¡c "view" khÃ¡c nhau cá»§a sáº£n pháº©m, sáº½ cho hiá»‡u suáº¥t vÆ°á»£t trá»™i so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n Ä‘Æ¡n giáº£n hÆ¡n.</p></div></div>

    </div>
</body>
</html>