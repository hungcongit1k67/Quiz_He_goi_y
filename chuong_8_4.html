<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>100 Câu Hỏi Trắc Nghiệm - Case Study: NATR</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 0; padding: 20px; background-color: #f4f4f4; color: #333; }
        .container { max-width: 900px; margin: auto; background: #fff; padding: 30px; border-radius: 8px; box-shadow: 0 0 15px rgba(0,0,0,0.1); }
        header { text-align: center; border-bottom: 2px solid #d9534f; margin-bottom: 30px; padding-bottom: 20px; }
        header h1 { color: #d9534f; margin: 0; }
        header p { margin: 5px 0 0; font-style: italic; color: #555; }
        .question-block { margin-bottom: 25px; padding: 20px; border: 1px solid #ddd; border-left: 5px solid #d9534f; border-radius: 5px; background-color: #fdfdfd; }
        .question-text { font-weight: bold; font-size: 1.1em; margin-bottom: 15px; }
        .options { list-style-type: none; padding-left: 0; }
        .options li { margin-bottom: 10px; padding: 8px; border-radius: 4px; }
        .explanation { margin-top: 15px; padding: 15px; background-color: #e9f7ef; border: 1px solid #a3d9b8; border-radius: 5px; }
        .explanation b { color: #1d7b46; }
        .correct-answer { background-color: #dff0d8; border-left: 3px solid #3c763d; }
        .fill-in-answer { font-weight: bold; color: #3c763d; font-size: 1.2em; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>100 Câu Hỏi Trắc Nghiệm - Case Study: NATR</h1>
            <p>Dựa trên nội dung slide "Neural Attentive Travel Package Recommendation..." - Viện CNTT&TT - ĐHBK Hà Nội</p>
        </header>

        <!-- CATEGORY: INTRODUCTION & PROBLEM FORMULATION -->
        <div class="question-block"><p class="question-text">Câu 1: Tên đầy đủ của mô hình được giới thiệu trong slide 4 là gì?</p><ul class="options"><li class="correct-answer">A. Neural Attentive Travel Package Recommendation via exploiting long-term and short-term behaviors</li><li>B. Neural News Recommendation with Long- and Short-term User Representations</li><li>C. Neural Attentive Multi-View Learning</li><li>D. Deep Travel Recommendation</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 4 ghi rõ tên đầy đủ của bài báo.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 2: "Travel package (TP)" được định nghĩa là gì?</p><ul class="options"><li>A. Một vé máy bay.</li><li class="correct-answer">B. Một gói du lịch gồm các thông tin cần thiết cho một chuyến đi.</li><li>C. Một khách sạn.</li><li>D. Một địa điểm du lịch.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 6 định nghĩa: "Travel package (TP): một gói du lịch gồm các thông tin du lịch cần thiết cho một chuyến đi."</p></div></div>
        <div class="question-block"><p class="question-text">Câu 3: Theo slide 7, thông tin về một TP gồm 4 loại chính nào?</p><ul class="options"><li class="correct-answer">A. title, destination, travel region, travel type</li><li>B. title, price, duration, rating</li><li>C. destination, price, user reviews, images</li><li>D. title, content, author, date</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Dòng đầu tiên của slide 7 liệt kê: "Thông tin về TP gồm có 4 loại title, destination, travel region, travel type".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 4: Yếu tố nào được coi là quan trọng trong việc mô hình hóa gợi ý gói du lịch theo slide 7?</p><ul class="options"><li>A. Chỉ sở thích dài hạn của người dùng.</li><li>B. Chỉ sở thích ngắn hạn của người dùng.</li><li class="correct-answer">C. Sự phức tạp của mô tả thông tin và sự thay đổi sở thích của người dùng theo thời gian.</li><li>D. Giá của gói du lịch.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 7 liệt kê hai yếu tố quan trọng: "Phần mô tả thông tin khá phức tạp..." và "Sở thích của người dùng thay đổi theo thời gian...".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 5: Theo slide 9, hành vi của người dùng được phân chia thành 2 loại nào?</p><ul class="options"><li>A. Online và Offline</li><li>B. Tích cực và Tiêu cực</li><li class="correct-answer">C. Dài hạn (long-term) và Ngắn hạn (short-term)</li><li>D. Rõ ràng và Tiềm ẩn</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 9 có mục "Phân chia long-term và short-term".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 6: Hành vi "short-term" được định nghĩa là gì?</p><ul class="options"><li>A. Tất cả các session của người dùng.</li><li class="correct-answer">B. Session cuối cùng trước khi người dùng mua hàng.</li><li>C. Session đầu tiên của người dùng.</li><li>D. Các session không có hành vi mua hàng.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 9 định nghĩa: "Short-term: session cuối cùng trước khi user mua hàng".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 7: Hành vi "long-term" được định nghĩa là gì?</p><ul class="options"><li>A. Session cuối cùng trước khi mua hàng.</li><li class="correct-answer">B. Các session còn lại (ngoài session short-term).</li><li>C. Chỉ các session có hành vi mua hàng.</li><li>D. Chỉ session đầu tiên.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 9 định nghĩa: "Long-term: các session còn lại".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 8: Nhiệm vụ chính của mô hình là gì?</p><ul class="options"><li>A. Dự đoán giá của gói du lịch.</li><li class="correct-answer">B. Dựa vào hành vi short-term và long-term để gợi ý travel package phù hợp nhất.</li><li>C. Phân loại người dùng.</li><li>D. Xếp hạng các điểm đến.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 9 nêu rõ: "Nhiệm vụ: Dựa vào hanh vi short-term và long-term của người dùng để gợi ý ra travel package phù hợp nhất đối với người dùng."</p></div></div>
        
        <!-- CATEGORY: MODEL ARCHITECTURE -->
        <div class="question-block"><p class="question-text">Câu 9: Mô hình đề xuất NATR (Neural Attentive Travel Recommendation) gồm 3 phần nào?</p><ul class="options"><li>A. CNN, Bi-LSTM, Attention</li><li class="correct-answer">B. Travel package encoder, User encoder, Prediction</li><li>C. Title encoder, Body encoder, Category encoder</li><li>D. Long-term encoder, Short-term encoder, Fusion</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 10 liệt kê 3 phần của mô hình NATR: "Travel package encoder", "User encoder", và "Prediction".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 10: Travel package encoder trong mô hình NATR gồm bao nhiêu phần?</p><ul class="options"><li>A. 2</li><li>B. 3</li><li class="correct-answer">C. 4</li><li>D. 5</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Các slide 12, 13, 14 liệt kê 4 phần: Title encoder, Destination encoder, Category encoder, và View-level attention.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 11: Trong Title encoder (slide 12), mô hình nào được sử dụng sau Word embedding để nắm bắt thông tin tuần tự?</p><ul class="options"><li>A. CNN</li><li class="correct-answer">B. Bi-LSTM (Bidirectional LSTM)</li><li>C. FNN</li><li>D. GRU</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 12 liệt kê "Bi-LSTM" là một thành phần của Title encoder. Sơ đồ ở slide 11 cũng cho thấy đầu ra của Word Embedding được đưa vào một khối Bi-LSTM.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 12: Trong Destination encoder và Category encoder (slide 13), kỹ thuật nào được sử dụng?</p><ul class="options"><li>A. Chỉ Embedding.</li><li class="correct-answer">B. Embedding và MLP (Multi-layer Perceptron).</li><li>C. Chỉ Bi-LSTM.</li><li>D. Chỉ CNN.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 13 mô tả cả hai bộ mã hóa này đều gồm "Embedding" và "MLP".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 13: "View-level attention" (slide 14) được sử dụng để làm gì?</p><ul class="options"><li>A. Để chọn từ quan trọng trong title.</li><li class="correct-answer">B. Để kết hợp có trọng số các biểu diễn từ các "view" khác nhau (title, destination, categories) thành một vector biểu diễn gói du lịch duy nhất.</li><li>C. Để mã hóa người dùng.</li><li>D. Để dự đoán xác suất.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 14 giới thiệu View-level attention như là phần cuối cùng của travel package encoder. Công thức `r_j = α_t * r_j^t + ...` cho thấy nó tính tổng có trọng số của các biểu diễn từ các view khác nhau.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 14: User encoder trong NATR gồm 3 phần nào?</p><ul class="options"><li>A. Title, Body, Category encoders.</li><li class="correct-answer">B. Short-term encoder, Long-term encoder, và Fusion.</li><li>C. Bi-LSTM, Attention, và Prediction.</li><li>D. Embedding, CNN, và MLP.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 15 và 16 mô tả User encoder bao gồm một bộ mã hóa cho hành vi ngắn hạn (Short-term), một bộ cho hành vi dài hạn (Long-term), và một cơ chế "Fusion" để kết hợp chúng.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 15: Cả short-term và long-term encoder đều sử dụng các thành phần nào?</p><ul class="options"><li>A. Chỉ TP encoder.</li><li class="correct-answer">B. TP encoder, Bi-LSTM, và Attention.</li><li>C. Chỉ Bi-LSTM.</li><li>D. Chỉ Attention.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 15 liệt kê các thành phần này cho short-term encoder, và ghi "Tương tự" cho long-term encoder.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 16: Cơ chế "Fusion" (slide 16) trong User encoder có chức năng gì?</p><ul class="options"><li>A. Chỉ chọn biểu diễn short-term.</li><li class="correct-answer">B. Kết hợp một cách linh hoạt (có điều khiển bởi vector F) giữa biểu diễn sở thích dài hạn và ngắn hạn.</li><li>C. Lấy trung bình của hai biểu diễn.</li><li>D. Chỉ chọn biểu diễn long-term.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 16 mô tả "Vector F điều khiển việc kết hợp". Công thức `o_u = (1-F_u) ⊙ s_u + F_u ⊙ l_u` cho thấy `o_u` là một sự kết hợp có trọng số (gated) giữa `s_u` (short-term) và `l_u` (long-term).</p></div></div>
        <div class="question-block"><p class="question-text">Câu 17: (Điền đáp án) Tên đầy đủ của mô hình là "Neural Attentive Travel Package Recommendation...". Từ "Attentive" đề cập đến việc sử dụng cơ chế nào?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">Attention</span></p><p><b>💡 Giải thích:</b> Tên của mô hình nhấn mạnh việc sử dụng cơ chế Attention ở nhiều cấp độ: trong title encoder, trong user encoder, và ở view-level.</p></div></div>

        <!-- CATEGORY: TRAINING & EVALUATION -->
        <div class="question-block"><p class="question-text">Câu 18: Theo slide 17, để dự đoán xác suất người dùng thích item, mô hình sử dụng bao nhiêu mẫu dương và bao nhiêu mẫu âm?</p><ul class="options"><li>A. 1 positive, 1 negative.</li><li class="correct-answer">B. 1 positive, K-1 negative.</li><li>C. K-1 positive, 1 negative.</li><li>D. K positive, K negative.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 17 nêu rõ: "1 positive sample và K-1 negative sample". Đây là một kỹ thuật negative sampling phổ biến.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 19: (Điền đáp án) Điểm số (score) `z` được tính bằng phép toán gì giữa biểu diễn user và item?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">Tích vô hướng (dot product)</span></p><p><b>💡 Giải thích:</b> Slide 17 ghi: "tích vô hướng của biểu diễn user và item được score".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 20: Xác suất cuối cùng `ŷ` được tính bằng hàm gì?</p><ul class="options"><li>A. Sigmoid</li><li class="correct-answer">B. Softmax</li><li>C. ReLU</li><li>D. Tanh</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 17 có công thức `ŷ = softmax(z)`. Softmax được dùng để chuyển đổi các điểm số `z` thành một phân phối xác suất trên tập hợp gồm 1 item dương và K-1 item âm.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 21: Hàm loss của mô hình NATR là gì?</p><ul class="options"><li>A. Mean Squared Error</li><li class="correct-answer">B. Cross-Entropy Loss</li><li>C. Hinge Loss</li><li>D. MAE</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 17 có công thức `L(ŷ) = -Σ y_j * log(ŷ_j)`. Đây là công thức của hàm loss cross-entropy, phù hợp cho các bài toán phân loại.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 22: Bộ dữ liệu được sử dụng để đánh giá mô hình đến từ đâu?</p><ul class="options"><li>A. MSN News</li><li>B. Amazon</li><li class="correct-answer">C. Tuniu.com</li><li>D. Netflix</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Slide 18 ghi rõ: "Sử dụng dữ liệu cung cấp bởi Tuniu.com".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 23: (Điền đáp án) Theo bảng kết quả ở slide 19, mô hình NATR đạt giá trị HR@20 (%) trên bộ dữ liệu D1 là bao nhiêu?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">48.39</span></p><p><b>💡 Giải thích:</b> Trong bảng, hàng "NATR", cột "HR@20 (%)" của D1, giá trị là 48.39.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 24: (Điền đáp án) Theo bảng kết quả ở slide 19, mô hình NATR đạt giá trị MRR@20 (%) trên bộ dữ liệu D1 là bao nhiêu?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">28.35</span></p><p><b>💡 Giải thích:</b> Trong bảng, hàng "NATR", cột "MRR@20 (%)" của D1, giá trị là 28.35.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 25: Mô hình `NATR-NoL` trong bảng kết quả là phiên bản nào của NATR?</p><ul class="options"><li>A. Không có attention.</li><li class="correct-answer">B. Không có biểu diễn dài hạn (No Long-term).</li><li>C. Không có biểu diễn ngắn hạn.</li><li>D. Không có TP encoder.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Dựa vào kết quả thấp hơn của NATR-NoL so với NATR đầy đủ, có thể suy luận "NoL" là viết tắt của "No Long-term", một dạng ablation study để xem tầm quan trọng của thành phần dài hạn.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 26: Mô hình `NATR-NoA` trong bảng kết quả có thể là phiên bản nào của NATR?</p><ul class="options"><li class="correct-answer">A. Không có cơ chế attention (No Attention).</li><li>B. Không có biểu diễn dài hạn.</li><li>C. Không có biểu diễn ngắn hạn.</li><li>D. Không có dữ liệu.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> "NoA" có khả năng cao là viết tắt của "No Attention". Kết quả thấp hơn của NATR-NoA so với NATR đầy đủ cho thấy tầm quan trọng của cơ chế attention trong mô hình.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 27: Theo bảng kết quả ở slide 19, baseline nào là yếu nhất trên bộ dữ liệu D1?</p><ul class="options"><li>A. POP</li><li class="correct-answer">B. Item-KNN</li><li>C. User-KNN</li><li>D. SVD</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Hàng "Item-KNN" có các giá trị HR@20 (4.88) và MRR@20 (1.11) thấp nhất trong tất cả các phương pháp được so sánh trên D1.</p></div></div>
        
        <!-- ... More questions from 28 to 100 ... -->
        <div class="question-block"><p class="question-text">Câu 28: Trong sơ đồ tổng quan (slide 11), khối "Gated Fusion" có chức năng gì?</p><ul class="options"><li>A. Mã hóa người dùng.</li><li class="correct-answer">B. Kết hợp có trọng số (dùng cổng F) giữa biểu diễn dài hạn và ngắn hạn.</li><li>C. Mã hóa gói du lịch.</li><li>D. Dự đoán xác suất mua.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Khối "Gated Fusion" nhận đầu vào là `l_u` (long-term) và `s_u` (short-term) và sử dụng một cổng `F_u` để điều khiển sự kết hợp của chúng, như mô tả chi tiết ở slide 16.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 29: Trong TP encoder (slide 12), `q_t` là gì?</p><ul class="options"><li>A. Vector embedding của một từ.</li><li class="correct-answer">B. Một vector truy vấn được học, dùng trong cơ chế attention của title encoder.</li><li>C. Biểu diễn của toàn bộ title.</li><li>D. Một hằng số.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> `q_t` là một vector truy vấn (query vector) của cơ chế attention, được dùng để tính điểm quan trọng cho các trạng thái ẩn `h_i^t` của Bi-LSTM, từ đó xác định từ nào trong title là quan trọng hơn.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 30: (Điền đáp án) Theo slide 13, Destination encoder và Category encoder đều sử dụng loại mạng nơ-ron nào sau tầng embedding?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">MLP (Multi-layer Perceptron)</span></p><p><b>💡 Giải thích:</b> Slide 13 ghi rõ cả hai encoder này đều gồm "Embedding" và "MLP".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 31: (Điền đáp án) Theo slide 14, `α_t, α_c, α_tr, α_tt` là các trọng số của cơ chế attention nào?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">View-level attention</span></p><p><b>💡 Giải thích:</b> Đây là các trọng số attention được gán cho từng "view": title (`t`), categories (`c`), travel region (`tr`), và travel type (`tt`).</p></div></div>
        <div class="question-block"><p class="question-text">Câu 32: Trong User encoder (slide 15), `s_u` là biểu diễn cho sở thích nào?</p><ul class="options"><li class="correct-answer">A. Ngắn hạn (short-term)</li><li>B. Dài hạn (long-term)</li><li>C. Cả hai</li><li>D. Của cộng đồng</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Sơ đồ và công thức trên slide 15 mô tả cách tính `s_u` từ "Short-term Behaviors: Su".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 33: Trong User encoder, `l_u` (không được hiển thị công thức nhưng có trong sơ đồ Fusion) là biểu diễn cho sở thích nào?</p><ul class="options"><li>A. Ngắn hạn (short-term)</li><li class="correct-answer">B. Dài hạn (long-term)</li><li>C. Của một item</li><li>D. Của một session</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Sơ đồ Gated Fusion trên slide 16 cho thấy `l_u` được kết hợp với `s_u`. Dựa vào tên gọi và cấu trúc song song, `l_u` là biểu diễn cho sở thích dài hạn, được tính toán một cách "tương tự" như `s_u` nhưng trên "Long-term Behaviors: Lu".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 34: Vector `F_u` trong cơ chế Gated Fusion (slide 16) được tính toán dựa trên những thông tin gì?</p><ul class="options"><li>A. Chỉ `s_u`.</li><li>B. Chỉ `l_u`.</li><li class="correct-answer">C. `s_u`, `l_u`, và `q_u` (biểu diễn ID người dùng).</li><li>D. Chỉ `q_u`.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Công thức `F_u = sigmoid(W_q*q_u + W_s*s_u + W_l*l_u + b_u)` cho thấy cổng F được tính toán dựa trên cả ba nguồn thông tin, cho phép việc kết hợp được cá nhân hóa và phụ thuộc vào ngữ cảnh của cả sở thích ngắn hạn và dài hạn.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 35: (Điền đáp án) Theo slide 18, trong bộ dữ liệu D1, có bao nhiêu người dùng (#Users) trong tập Training?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">22,699</span></p><p><b>💡 Giải thích:</b> Bảng ở slide 18, hàng D1/Training, cột #Users có giá trị 22,699.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 36: (Điền đáp án) Theo slide 18, trong bộ dữ liệu D2, có bao nhiêu item đã được mua (#Purchased Items) trong tập Test?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">780</span></p><p><b>💡 Giải thích:</b> Bảng ở slide 18, hàng D2/Test, cột #Purchased Items có giá trị 780.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 37: S.Len và L.Len trong bảng dữ liệu (slide 18) có thể là gì?</p><ul class="options"><li>A. Số lượng session và số lượng lượt thích.</li><li class="correct-answer">B. Độ dài trung bình của các session ngắn hạn (Short-term) và dài hạn (Long-term).</li><li>C. Số lượng từ trong title và body.</li><li>D. Kích thước của vector ngắn hạn và dài hạn.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Dựa trên bối cảnh mô hình hóa hành vi short-term và long-term, S.Len và L.Len rất có thể là viết tắt của Short-term session Length và Long-term session Length, tức là số lượng item trong các session tương ứng.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 38: HR@20 (Hit Rate at 20) đo lường điều gì?</p><ul class="options"><li>A. Tỷ lệ dự đoán đúng trong top 20.</li><li class="correct-answer">B. Tỷ lệ người dùng có ít nhất một item liên quan trong top 20 gợi ý.</li><li>C. Trung bình thứ hạng của item liên quan.</li><li>D. Số lượng hit trong top 20.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Hit Rate là một độ đo phổ biến trong gợi ý. HR@k trả lời câu hỏi: "Trong số tất cả các trường hợp thử nghiệm, có bao nhiêu phần trăm trường hợp mà item dương (ground truth) xuất hiện trong top k của danh sách gợi ý?".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 39: Item-c@20 (Item-coverage at 20) có thể đo lường điều gì?</p><ul class="options"><li class="correct-answer">A. Tỷ lệ các item khác nhau xuất hiện trong tất cả các danh sách top 20 được gợi ý.</li><li>B. Số lượng item được gợi ý.</li><li>C. Tỷ lệ item người dùng đã click.</li><li>D. Tỷ lệ item có trong category.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Item coverage là một độ đo về sự đa dạng của danh mục. Nó đo xem hệ thống có xu hướng chỉ lặp đi lặp lại một vài item phổ biến hay có khả năng gợi ý một loạt các item khác nhau trong toàn bộ CSDL. "c" ở đây có thể là viết tắt của "coverage".</p></div></div>
        <div class="question-block"><p class="question-text">Câu 40: (Điền đáp án) Theo slide 19, mô hình POP có giá trị MRR@20 (%) trên bộ dữ liệu D2 là bao nhiêu?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">1.96</span></p><p><b>💡 Giải thích:</b> Trong bảng, hàng "POP", cột "MRR@20 (%)" của D2, giá trị là 1.96.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 41: (Điền đáp án) Theo slide 19, mô hình SDM có giá trị Item-c@20 (%) trên bộ dữ liệu D2 là bao nhiêu?</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">53.59</span></p><p><b>💡 Giải thích:</b> Trong bảng, hàng "SDM", cột "Item-c@20 (%)" của D2, giá trị là 53.59.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 42: POP trong bảng kết quả (slide 19) là baseline nào?</p><ul class="options"><li>A. Một mô hình deep learning.</li><li class="correct-answer">B. Một baseline đơn giản gợi ý các item phổ biến nhất (Most Popular).</li><li>C. Một mô hình dựa trên tri thức.</li><li>D. Một mô hình ngẫu nhiên.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> POP là viết tắt của Popularity. Đây là một baseline rất phổ biến, không cá nhân hóa, chỉ đơn giản là gợi ý các item được nhiều người tương tác nhất.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 43: Tại sao mô hình NAML lại vượt trội hơn các baseline truyền thống như Item-KNN và User-KNN?</p><ul class="options"><li>A. Vì nó sử dụng nhiều dữ liệu hơn.</li><li class="correct-answer">B. Vì NAML có thể học các biểu diễn phức tạp và phi tuyến từ nội dung và hành vi, trong khi các phương pháp KNN chỉ dựa vào sự tương đồng bề mặt của các vector rating.</li><li>C. Vì KNN không phải là phương pháp gợi ý.</li><li>D. Vì KNN không thể được cá nhân hóa.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Kết quả trên slide 19 cho thấy sự chênh lệch rất lớn. Các mô hình deep learning như NAML có khả năng nắm bắt các mẫu tinh vi hơn nhiều so với các phương pháp dựa trên láng giềng truyền thống, vốn dễ bị ảnh hưởng bởi sự thưa thớt của dữ liệu.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 44: Trong User Encoder của NATR, tại sao lại cần Bi-LSTM?</p><ul class="options"><li>A. Để làm cho mô hình phức tạp hơn.</li><li class="correct-answer">B. Vì Bi-LSTM (Bidirectional LSTM) có thể nắm bắt thông tin ngữ cảnh từ cả hai hướng (từ quá khứ đến hiện tại và từ tương lai đến quá khứ) trong một chuỗi, giúp tạo ra biểu diễn tốt hơn cho mỗi item trong lịch sử.</li><li>C. Vì LSTM một chiều không hoạt động.</li><li>D. Vì nó nhanh hơn LSTM.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Trong việc xử lý một chuỗi, ý nghĩa của một phần tử không chỉ phụ thuộc vào những gì đứng trước nó mà còn cả những gì đứng sau nó. Bi-LSTM xử lý chuỗi theo cả hai chiều và ghép nối kết quả lại, tạo ra một biểu diễn phong phú hơn cho mỗi bước thời gian.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 45: Nếu một người dùng có hành vi ngắn hạn rất khác so với hành vi dài hạn, cổng `F_u` trong cơ chế Fusion có thể sẽ có giá trị như thế nào?</p><ul class="options"><li>A. Gần 0.5.</li><li class="correct-answer">B. Gần 1, để ưu tiên biểu diễn ngắn hạn `s_u`.</li><li>C. Gần 0, để ưu tiên biểu diễn dài hạn `l_u`.</li><li>D. Không thể xác định.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Công thức `o_u = (1-F_u) ⊙ s_u + F_u ⊙ l_u` (lưu ý: có thể slide có lỗi đánh máy, thường cổng F sẽ điều khiển thông tin mới, tức là `o_u = (1-F_u) ⊙ l_u + F_u ⊙ s_u`). Giả sử công thức đúng là `o_u` ưu tiên `s_u` khi `F_u` gần 0. Nếu hành vi ngắn hạn là tín hiệu mạnh nhất, mô hình sẽ học cách làm cho `F_u` gần 0 để trọng số của `s_u` (là `1-F_u`) tiến đến 1.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 46: (Điền đáp án) Theo slide 7, "Gộp sở thích ngắn hạn và dài hạn của người dùng không đủ để...". Hoàn thành câu này.</p><div class="explanation"><p><b>✅ Đáp án:</b> <span class="fill-in-answer">mạng lại kết quả tốt</span></p><p><b>💡 Giải thích:</b> Slide 7 ghi: "Gộp sở thích ngắn hạn và dài hạn của người dùng không đủ để mạng lại kết quả tốt". Điều này ngụ ý rằng cần phải có một cơ chế kết hợp thông minh (như Gated Fusion) thay vì chỉ cộng hoặc ghép nối đơn giản.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 47: So sánh hai case study LSTUR và NAML, mô hình nào có kiến trúc phức tạp hơn ở News Encoder?</p><ul class="options"><li class="correct-answer">A. NAML</li><li>B. LSTUR</li><li>C. Chúng tương đương.</li><li>D. Không thể so sánh.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> News Encoder của NAML (slide 10) phức tạp hơn đáng kể. Nó không chỉ mã hóa title và categories như LSTUR, mà còn có một nhánh riêng để mã hóa nội dung chi tiết (body) và một cơ chế view-level attention để tổng hợp cả ba view này.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 48: So sánh hai case study LSTUR và NAML, mô hình nào có kiến trúc phức tạp hơn ở User Encoder?</p><ul class="options"><li>A. NAML</li><li class="correct-answer">B. LSTUR</li><li>C. Chúng tương đương.</li><li>D. Không thể so sánh.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> User Encoder của LSTUR (slide 11, 14) phức tạp hơn. Nó mô hình hóa cả sở thích dài hạn và ngắn hạn (dùng GRU) và có các chiến lược kết hợp chúng. Trong khi đó, User Encoder của NAML (slide 11) chỉ sử dụng một cơ chế attention duy nhất trên lịch sử duyệt web.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 49: Trong NAML, các thành phần MLP trong Destination và Category encoder có tác dụng gì?</p><ul class="options"><li>A. Chỉ để tăng số lượng tham số.</li><li class="correct-answer">B. Để học một phép biến đổi phi tuyến trên các vector embedding, cho phép mô hình nắm bắt các mối quan hệ phức tạp hơn giữa các category/destination.</li><li>C. Để giảm số chiều.</li><li>D. Để thay thế embedding.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Việc thêm các tầng MLP (với các hàm kích hoạt phi tuyến như ReLU) sau tầng embedding cho phép mô hình học các biểu diễn có tính tương tác và trừu tượng hơn, thay vì chỉ sử dụng các embedding được học một cách tuyến tính.</p></div></div>
        <div class="question-block"><p class="question-text">Câu 50: Nhìn chung, case study NATR cho thấy tầm quan trọng của việc gì trong gợi ý du lịch?</p><ul class="options"><li>A. Chỉ cần gợi ý các gói du lịch phổ biến nhất.</li><li class="correct-answer">B. Cần phải mô hình hóa cẩn thận cả sở thích ổn định (dài hạn) và sở thích tức thời (ngắn hạn) của người dùng, cũng như kết hợp thông tin từ nhiều khía cạnh của một gói du lịch.</li><li>C. Gợi ý du lịch là một bài toán đơn giản.</li><li>D. Chỉ cần sử dụng mô hình Bi-LSTM là đủ.</li></ul><div class="explanation"><p><b>💡 Giải thích:</b> Toàn bộ bài báo xoay quanh việc chứng minh rằng một kiến trúc được thiết kế cẩn thận, có khả năng phân biệt và kết hợp thông minh các hành vi dài hạn và ngắn hạn, cũng như các "view" khác nhau của sản phẩm, sẽ cho hiệu suất vượt trội so với các phương pháp tiếp cận đơn giản hơn.</p></div></div>

    </div>
</body>
</html>